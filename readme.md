# áƒ¡áƒáƒ®áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ›áƒ”áƒ¢áƒ§áƒ•áƒ”áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒáƒ›áƒáƒªáƒœáƒáƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ¬áƒ•áƒ”áƒ•áƒ

áƒ”áƒ¡ áƒ áƒ”áƒáƒáƒ–áƒ˜áƒ¢áƒáƒ áƒ˜áƒ áƒ›áƒáƒ˜áƒªáƒáƒ•áƒ¡ áƒ©áƒ”áƒ›áƒ¡ áƒ˜áƒ›áƒáƒšáƒ”áƒ›áƒ”áƒœáƒ¢áƒáƒªáƒ˜áƒáƒ¡ Kaggle-áƒ˜áƒ¡ [Challenges in Representation Learning: Facial Expression Recognition Challenge](https://www.kaggle.com/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge) áƒ™áƒáƒœáƒ™áƒ£áƒ áƒ¡áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡. áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡ áƒ›áƒ˜áƒ–áƒáƒœáƒ˜áƒ áƒ¦áƒ áƒ›áƒ áƒ¡áƒ¬áƒáƒ•áƒšáƒ˜áƒ¡ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ¨áƒ”áƒ¥áƒ›áƒœáƒ áƒ“áƒ áƒ¨áƒ”áƒ¤áƒáƒ¡áƒ”áƒ‘áƒ, áƒ áƒáƒ›áƒšáƒ”áƒ‘áƒ˜áƒª áƒ™áƒšáƒáƒ¡áƒ˜áƒ¤áƒ˜áƒªáƒ˜áƒ áƒ”áƒ‘áƒ”áƒœ áƒ¡áƒáƒ®áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ›áƒ”áƒ¢áƒ§áƒ•áƒ”áƒšáƒ”áƒ‘áƒ”áƒ‘áƒ¡ áƒ¨áƒ•áƒ˜áƒ“áƒ˜ áƒ¡áƒ®áƒ•áƒáƒ“áƒáƒ¡áƒ®áƒ•áƒ áƒ”áƒ›áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ™áƒáƒ¢áƒ”áƒ’áƒáƒ áƒ˜áƒáƒ“.

## ğŸ“‹ áƒ¨áƒ˜áƒœáƒáƒáƒ áƒ¡áƒ˜

* [áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡ áƒ›áƒ˜áƒ›áƒáƒ®áƒ˜áƒšáƒ•áƒ](#-áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡-áƒ›áƒ˜áƒ›áƒáƒ®áƒ˜áƒšáƒ•áƒ)
* [áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ˜](#-áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ-áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ˜)
* [áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ áƒ“áƒ áƒ˜áƒœáƒ¡áƒ¢áƒáƒšáƒáƒªáƒ˜áƒ](#-áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ-áƒ“áƒ-áƒ˜áƒœáƒ¡áƒ¢áƒáƒšáƒáƒªáƒ˜áƒ)
* [áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡ áƒ¡áƒ¢áƒ áƒ£áƒ¥áƒ¢áƒ£áƒ áƒ](#-áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡-áƒ¡áƒ¢áƒ áƒ£áƒ¥áƒ¢áƒ£áƒ áƒ)
* [áƒ›áƒ”áƒ—áƒáƒ“áƒáƒšáƒáƒ’áƒ˜áƒ](#-áƒ›áƒ”áƒ—áƒáƒ“áƒáƒšáƒáƒ’áƒ˜áƒ)
* [áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜](#-áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜-áƒ“áƒ-áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜)
* [Weights & Biases áƒ˜áƒœáƒ¢áƒ”áƒ’áƒ áƒáƒªáƒ˜áƒ](#-weights--biases-áƒ˜áƒœáƒ¢áƒ”áƒ’áƒ áƒáƒªáƒ˜áƒ)
* [áƒ›áƒ˜áƒ’áƒœáƒ”áƒ‘áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒáƒœáƒáƒšáƒ˜áƒ–áƒ˜](#-áƒ›áƒ˜áƒ’áƒœáƒ”áƒ‘áƒ”áƒ‘áƒ˜-áƒ“áƒ-áƒáƒœáƒáƒšáƒ˜áƒ–áƒ˜)
* [áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ](#-áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ)
* [áƒ¨áƒ”áƒ£áƒ”áƒ áƒ—áƒ“áƒ˜ áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ¡](#-áƒ¨áƒ”áƒ£áƒ”áƒ áƒ—áƒ“áƒ˜-áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ¡)
* [áƒšáƒ˜áƒªáƒ”áƒœáƒ–áƒ˜áƒ](#-áƒšáƒ˜áƒªáƒ”áƒœáƒ–áƒ˜áƒ)

## ğŸŒŸ áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡ áƒ›áƒ˜áƒ›áƒáƒ®áƒ˜áƒšáƒ•áƒ

áƒ”áƒ¡ áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜ áƒ˜áƒ™áƒ•áƒšáƒ”áƒ•áƒ¡ áƒ¡áƒ®áƒ•áƒáƒ“áƒáƒ¡áƒ®áƒ•áƒ áƒœáƒ”áƒ˜áƒ áƒáƒœáƒ£áƒš áƒ¥áƒ¡áƒ”áƒšáƒ˜áƒ¡ áƒáƒ áƒ¥áƒ˜áƒ¢áƒ”áƒ¥áƒ¢áƒ£áƒ áƒáƒ¡ áƒ¡áƒáƒ®áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ›áƒ”áƒ¢áƒ§áƒ•áƒ”áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒáƒ›áƒáƒ¡áƒáƒªáƒœáƒáƒ‘áƒáƒ“, áƒ§áƒ£áƒ áƒáƒ“áƒ¦áƒ”áƒ‘áƒ áƒ’áƒáƒ›áƒáƒ®áƒ•áƒ˜áƒšáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ°áƒ˜áƒáƒ”áƒ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜áƒ¡áƒ áƒ“áƒ áƒáƒ áƒ¥áƒ˜áƒ¢áƒ”áƒ¥áƒ¢áƒ£áƒ áƒ£áƒšáƒ˜ áƒ’áƒáƒ“áƒáƒ¬áƒ§áƒ•áƒ”áƒ¢áƒ˜áƒšáƒ”áƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ•áƒšáƒ”áƒœáƒáƒ–áƒ” áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ›áƒ£áƒ¨áƒáƒáƒ‘áƒáƒ–áƒ”. áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜ áƒáƒ’áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ PyTorch-áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ˜áƒ—, áƒ®áƒáƒšáƒ áƒ§áƒ•áƒ”áƒšáƒ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒšáƒáƒ’áƒ˜áƒ áƒ“áƒ”áƒ‘áƒ Weights & Biases áƒáƒšáƒáƒ¢áƒ¤áƒáƒ áƒ›áƒáƒ–áƒ” áƒ¡áƒ áƒ£áƒšáƒ˜ áƒáƒœáƒáƒšáƒ˜áƒ–áƒ˜áƒ¡áƒ áƒ“áƒ áƒ•áƒ˜áƒ–áƒ£áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.

## ğŸ“Š áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ˜

áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ˜ áƒ¨áƒ”áƒ“áƒ’áƒ”áƒ‘áƒ 48x48 áƒáƒ˜áƒ¥áƒ¡áƒ”áƒšáƒ˜áƒ¡ áƒ’áƒ áƒ”áƒ˜áƒ¡áƒ™áƒ”áƒ˜áƒš áƒ¡áƒáƒ®áƒ”áƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ¡áƒáƒ®áƒ£áƒšáƒ”áƒ‘áƒ”áƒ‘áƒ˜áƒ¡áƒ’áƒáƒœ, áƒ—áƒ˜áƒ—áƒáƒ”áƒ£áƒšáƒ˜ áƒšáƒ”áƒ˜áƒ‘áƒšáƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ”áƒ áƒ—-áƒ”áƒ áƒ—áƒ˜ áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒ”áƒ›áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ™áƒáƒ¢áƒ”áƒ’áƒáƒ áƒ˜áƒ˜áƒ—:

* 0: áƒ’áƒáƒ‘áƒ áƒáƒ–áƒ”áƒ‘áƒ (Angry)
* 1: áƒ–áƒ˜áƒ–áƒ¦áƒ˜ (Disgust)
* 2: áƒ¨áƒ˜áƒ¨áƒ˜ (Fear)
* 3: áƒ¡áƒ˜áƒ®áƒáƒ áƒ£áƒšáƒ˜ (Happy)
* 4: áƒ¡áƒ”áƒ•áƒ“áƒ (Sad)
* 5: áƒ’áƒáƒáƒªáƒ”áƒ‘áƒ (Surprise)
* 6: áƒœáƒ”áƒ˜áƒ¢áƒ áƒáƒšáƒ£áƒ áƒ˜ (Neutral)



## ğŸ“ áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜áƒ¡ áƒ¡áƒ¢áƒ áƒ£áƒ¥áƒ¢áƒ£áƒ áƒ

```
Facial-Expression-Recognition/
â”œâ”€â”€ notebooks/               # Jupyter áƒœáƒáƒ£áƒ—áƒ‘áƒ£áƒ¥áƒ”áƒ‘áƒ˜ áƒ”áƒ¥áƒ¡áƒáƒšáƒáƒ áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_baseline_cnn.ipynb
â”‚   â”œâ”€â”€ 03_deeper_cnn.ipynb
â”‚   â”œâ”€â”€ 04_attention_cnn.ipynb
â”‚   â”œâ”€â”€ 05_resnet.ipynb
â”‚   â”œâ”€â”€ 06_ensemble.ipynb
â”‚   â””â”€â”€ 07_final_model.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ§  áƒ›áƒ”áƒ—áƒáƒ“áƒáƒšáƒáƒ’áƒ˜áƒ

áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜ áƒ›áƒ˜áƒ°áƒ§áƒ•áƒ”áƒ‘áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ’áƒáƒœáƒ•áƒ˜áƒ—áƒáƒ áƒ”áƒ‘áƒáƒ¡ áƒ”áƒ¢áƒáƒáƒáƒ‘áƒ áƒ˜áƒ•áƒáƒ“:

1. **áƒ¡áƒáƒ¬áƒ§áƒ˜áƒ¡áƒ˜ áƒ›áƒáƒ“áƒ”áƒšáƒ˜**: áƒ›áƒáƒ áƒ¢áƒ˜áƒ•áƒ˜ CNN áƒáƒ áƒ¥áƒ˜áƒ¢áƒ”áƒ¥áƒ¢áƒ£áƒ áƒ
2. **áƒ›áƒáƒ¬áƒ˜áƒœáƒáƒ•áƒ” áƒ™áƒáƒ›áƒáƒšáƒ”áƒ¥áƒ¡áƒ£áƒ áƒáƒ‘áƒ**: áƒ”áƒ¢áƒáƒáƒáƒ‘áƒ áƒ˜áƒ•áƒáƒ“ áƒ•áƒ–áƒ áƒ“áƒ˜áƒ— áƒáƒ áƒ¥áƒ˜áƒ¢áƒ”áƒ¥áƒ¢áƒ£áƒ áƒ˜áƒ¡ áƒ¡áƒ˜áƒ áƒ—áƒ£áƒšáƒ”áƒ¡
3. **áƒ áƒ”áƒ’áƒ£áƒšáƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ**: áƒ¡áƒ®áƒ•áƒáƒ“áƒáƒ¡áƒ®áƒ•áƒ áƒ¢áƒ”áƒ¥áƒœáƒ˜áƒ™áƒ áƒ’áƒáƒ“áƒáƒ›áƒ”áƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ›áƒáƒ áƒ’áƒ”áƒ‘áƒ˜áƒ¡ áƒ—áƒáƒ•áƒ˜áƒ“áƒáƒœ áƒáƒ¡áƒáƒªáƒ˜áƒšáƒ”áƒ‘áƒšáƒáƒ“
4. **áƒ¢áƒ áƒáƒœáƒ¡áƒ¤áƒ”áƒ áƒ£áƒšáƒ˜ áƒ¡áƒ¬áƒáƒ•áƒšáƒ”áƒ‘áƒ**: áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ  áƒ’áƒáƒ¬áƒ•áƒ áƒ—áƒœáƒ˜áƒšáƒ˜ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ
5. **áƒ”áƒœáƒ˜áƒ¡áƒ”áƒ›áƒ‘áƒšáƒ˜**: áƒ›áƒ áƒáƒ•áƒáƒš áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ’áƒáƒ”áƒ áƒ—áƒ˜áƒáƒœáƒ”áƒ‘áƒ áƒ£áƒ™áƒ”áƒ—áƒ”áƒ¡áƒ˜ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡

## ğŸ“ˆ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜

áƒ§áƒ•áƒ”áƒšáƒ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒšáƒáƒ’áƒ˜áƒ áƒ“áƒ”áƒ‘áƒ Weights & Biases-áƒ¨áƒ˜. áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜ áƒ›áƒáƒ˜áƒªáƒáƒ•áƒ¡:

* áƒ¡áƒ¬áƒáƒ•áƒšáƒ”áƒ‘áƒ˜áƒ¡áƒ áƒ“áƒ áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ“áƒáƒœáƒáƒ™áƒáƒ áƒ’áƒ˜ áƒ“áƒ áƒ¡áƒ˜áƒ–áƒ£áƒ¡áƒ¢áƒ”
* áƒ¡áƒáƒ¡áƒ¬áƒáƒ•áƒšáƒ áƒ¡áƒ˜áƒ©áƒ¥áƒáƒ áƒ˜áƒ¡ áƒªáƒ•áƒšáƒáƒ“áƒáƒ‘áƒ
* áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ°áƒ˜áƒáƒ”áƒ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜
* áƒ™áƒáƒœáƒ¤áƒ£áƒ–áƒ˜áƒ˜áƒ¡ áƒ›áƒáƒ¢áƒ áƒ˜áƒªáƒ”áƒ‘áƒ˜
* áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ”áƒ‘áƒ˜áƒ¡ áƒáƒ áƒáƒ’áƒœáƒáƒ–áƒ”áƒ‘áƒ˜


# Notebook 01_data_exploration.ipynb
## Data Exploration Results

### Dataset Overview
- **Size**: 28,709 training samples, 7,178 test samples
- **Classes**: 7 facial expressions (Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral)
- **Image Format**: 48x48 grayscale images
- **Data Quality**: 0 missing values, 1236 duplicates

### Key Findings
1. **Class Imbalance**: Significant imbalance with ratio 16.55:1 (most:least common)
   - Most common: Happy 
   - Least common: Disgust

2. **Data Characteristics**:
   - Pixel values: 0-255 range
   - Mean pixel value: 131.0 Â± 64.3
   - Consistent image dimensions

3. **Challenges Identified**:
   - Class imbalance will require balanced sampling or weighted loss
   - Low resolution (48x48) limits feature complexity
   - Grayscale only - no color information

### Data Split Strategy
- Training: 22,967 samples (80%)
- Validation: 5,742 samples (20%)  
- Stratified split to maintain class distribution

# Training
## 02_simple_cnn.ipynb **Simple CNN**

Simple Convolutional Neural Network for facial expression recognition. Serves as an initial model to establish performance baselines.

### ğŸ”¹ Version 1

#### ğŸ— Architecture

```
Input (1, 48, 48)
â”œâ”€ Conv2d(1, 32, kernel_size=5, padding=2)
â”œâ”€ ReLU()
â”œâ”€ MaxPool2d(kernel_size=2, stride=2)
â”œâ”€ Conv2d(32, 64, kernel_size=5, padding=2)
â”œâ”€ ReLU()
â”œâ”€ MaxPool2d(kernel_size=2, stride=2)
â”œâ”€ Flatten()
â”œâ”€ Dropout(0.3)
â”œâ”€ Linear(64 * 12 * 12, 128)
â”œâ”€ ReLU()
â”œâ”€ Dropout(0.3)
â””â”€ Linear(128, 7)
```

#### âš™ï¸ Training Configuration
- **Optimizer**: Adam (lr=0.001)
- **Loss**: Cross-entropy
- **Batch Size**: 64
- **Epochs**: 30 (with early stopping)
- **Regularization**:
  - Dropout (0.5)
- **Early Stopping**: 5 epochs

#### ğŸ“Š Results
```
Train Loss: 0.4371, Train Acc: 83.87%
Val Loss: 1.5326, Val Acc: 57.66%
Time: 22.21s
--------------------------------------------------
Early stopping at epoch 12

```
![alt text](media/image.png)

[Simple_cnn_v1](https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/i6k9h806?nw=nwuserellekvirikashvili)

---



### ğŸ”¹ Version 2 (Improved)

#### ğŸ›  Architecture Improvements
ADDED:

   - Data Augmentation: This is a powerful technique that artificially increases the size of your training dataset by applying random transformations to your images (e.g., rotations, flips, shifts). This helps the model see more variations of the training data and makes it more robust.
   - Batch Normalization: Add Batch Normalization layers after each convolutional layer (and before the activation function). This helps stabilize the training process and acts as a form of regularization.




#### âš™ï¸ Training Configuration
- **Learning Rate**: 0.0005 (reduced from 0.001)
- **Weight Decay**: 1e-4 (L2 regularization)
- **Early Stopping** with patience=7   
- **Learning Rate Scheduling**: Reduce on plateau
- **Batch Size**: 64 (unchanged)
- **Epochs**: 20, so that training is faster and early stopping is more effective and overfitting is reduced

#### ğŸ“Š Expected Improvements
- Better generalization
- Reduced overfitting
- More stable training

#### ğŸ“Š Results
```
Train Loss: 1.1825, Train Acc: 55.08%
Val Loss: 1.1020, Val Acc: 57.89%
Time: 36.64s
--------------------------------------------------

Training completed in 762.90s
Best validation accuracy: 59.11%
```
áƒáƒ¡áƒ” áƒ•áƒ£áƒ¨áƒ•áƒ”áƒšáƒ”áƒ— áƒáƒ•áƒ”áƒ áƒ¤áƒ˜áƒ¢áƒ¡:
![alt text](media/image-1.png)


áƒ›áƒáƒ’áƒ áƒáƒ› áƒªáƒ£áƒ“áƒ˜ áƒ áƒáƒ¦áƒáƒª áƒ›áƒáƒ®áƒ“áƒ, áƒáƒ› áƒ›áƒáƒ“áƒ”áƒšáƒ›áƒ áƒ¡áƒáƒ”áƒ áƒ—áƒáƒ“ áƒ•áƒ”áƒ  áƒ˜áƒ¡áƒ¬áƒáƒ•áƒšáƒ disgust áƒ”áƒ›áƒáƒªáƒ˜áƒ.
![alt text](media/Untitled.png)


áƒáƒ›áƒ˜áƒ¢áƒáƒ› áƒ’áƒáƒ“áƒáƒ•áƒ¬áƒ§áƒ•áƒ˜áƒ¢áƒ” class imbalance áƒáƒ áƒáƒ‘áƒšáƒ”áƒ›áƒ áƒ’áƒáƒ“áƒáƒ›áƒ”áƒ­áƒ áƒ.

[simple_cnn_v2](https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/uxblb7xc?nw=nwuserellekvirikashvili)

### ğŸ”¹ Version 3 weighted loss

#### âš™ï¸ Training Configuration
- Weighted Loss Function because of class imbalance
      criterion = nn.CrossEntropyLoss(weight=class_weights)
- Oversampling the Minority Classes
      WeightedRandomSampler
- different optimizer AdamW optimizer

#### ğŸ“Š Results
```
Train Loss: 1.7487, Train Acc: 14.08%
Val Loss: 2.0037, Val Acc: 1.76%
Time: 47.32s
--------------------------------------------------
Early stopping at epoch 8
```

áƒ›áƒ’áƒáƒœáƒ˜ áƒáƒ áƒ˜áƒ•áƒ” áƒ”áƒ áƒ—áƒáƒ“ áƒáƒ  áƒ£áƒœáƒ“áƒ áƒ’áƒáƒ›áƒáƒ›áƒ”áƒ§áƒ”áƒœáƒ”áƒ‘áƒ˜áƒœáƒ áƒ“áƒ áƒ¡áƒáƒœáƒáƒ› áƒáƒ  áƒ’áƒáƒ©áƒ”áƒ áƒ“áƒ áƒ˜áƒ¥áƒáƒ›áƒ“áƒ” áƒ•áƒ”áƒ  áƒ“áƒáƒ•áƒ˜áƒœáƒáƒ®áƒ”, áƒ áƒáƒ› áƒ áƒáƒ¢áƒáƒ›áƒ¦áƒáƒª áƒ›áƒáƒ áƒ¢áƒ disgust áƒ˜áƒ¡áƒ¬áƒáƒ•áƒšáƒ áƒáƒ› áƒ›áƒáƒ“áƒ”áƒšáƒ›áƒ (áƒ–áƒ£áƒ¡áƒ¢áƒáƒ“ disgusted áƒ¡áƒáƒ®áƒ” áƒ›áƒ¥áƒáƒœáƒ“áƒ conf matrix áƒ áƒáƒ› áƒ“áƒáƒ•áƒ˜áƒœáƒáƒ®áƒ”), áƒáƒ›áƒ˜áƒ¢áƒáƒ› áƒ™áƒ˜áƒ“áƒ”áƒ• áƒ”áƒ áƒ—áƒ®áƒ”áƒš áƒ’áƒáƒ•áƒ˜áƒ¨áƒ•áƒ˜ áƒ›áƒ®áƒáƒšáƒáƒ“ weighted_loss -áƒ˜áƒ—.
![alt text](media/Untitled-1.png)


[Simple_cnn_v3](https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/sptprk6t?nw=nwuserellekvirikashvili)





## ğŸ“ `03_deeper_cnn.ipynb`

### ğŸ§  Deeper CNN with Batch Normalization

---

## ğŸ”¹ Version 1 (Deep\_CNN\_V1)

### ğŸ— Architecture

* 7-áƒ¨áƒ áƒ˜áƒáƒœáƒ˜ Convolutional áƒœáƒ”áƒ áƒ•áƒ£áƒšáƒ˜ áƒ¥áƒ¡áƒ”áƒšáƒ˜ (CNN)
* **4 Convolutional áƒ‘áƒšáƒáƒ™áƒ˜**, áƒ§áƒáƒ•áƒ”áƒšáƒ˜ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ MaxPooling-áƒ˜áƒ—
* áƒ§áƒáƒ•áƒ”áƒšáƒ˜ Conv-áƒ¨áƒ áƒ˜áƒ¡ áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ **Batch Normalization**
* **Global Average Pooling** áƒ¡áƒ áƒ£áƒšáƒ“áƒ”áƒ‘áƒ FC áƒ¤áƒ”áƒœáƒ”áƒ‘áƒáƒ›áƒ“áƒ”
* Dropout (0.5) áƒ áƒ”áƒ’áƒ£áƒšáƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡
* **Batch Normalization** áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ áƒ áƒáƒ’áƒáƒ áƒª Convolutional, áƒ˜áƒ¡áƒ” Fully Connected áƒ¤áƒ”áƒœáƒ”áƒ‘áƒ¨áƒ˜

### âš™ï¸ áƒ°áƒ˜áƒáƒ”áƒ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜

* Filters: `32 â†’ 64 â†’ 128 â†’ 256`
* Optimizer: **Adam**, learning rate = `0.001`
* L2 weight decay: `1e-4`
* Epochs: `40` (Early stopping áƒ¨áƒ”áƒ¡áƒáƒ«áƒšáƒ”áƒ‘áƒ”áƒšáƒ˜)
* Dropout rate: `0.5`
* Tracking: Weights & Biases áƒ˜áƒœáƒ¢áƒ”áƒ’áƒ áƒáƒªáƒ˜áƒ (`wandb`)

### ğŸ“‰ Performance

* **Train Loss**: `0.1689`, **Train Accuracy**: `93.93%`
* **Val Loss**: `2.3061`, **Val Accuracy**: `57.72%`
* **Early Stopping**: áƒ’áƒáƒœáƒ®áƒáƒ áƒªáƒ˜áƒ”áƒšáƒ“áƒ **24-áƒ” áƒ”áƒáƒáƒ¥áƒáƒ–áƒ”**
* **Observation**: áƒ›áƒáƒ“áƒ”áƒšáƒ›áƒ áƒ’áƒáƒ“áƒáƒ­áƒáƒ áƒ‘áƒ”áƒ‘áƒ£áƒšáƒáƒ“ áƒ›áƒáƒ”áƒ áƒ’áƒ áƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ¡ â€” **overfitting**

ğŸ“Š [Deep\_cnn\_v1 Run on W\&B](https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/f1pw8dnp?nw=nwuserellekvirikashvili)

---

## ğŸ”¹ Version 2 (Deep\_CNN\_V2)

### âš™ï¸ Key Changes from V1

* **Epochs áƒ¨áƒ”áƒ›áƒªáƒ˜áƒ áƒ“áƒ**: `40 â†’ 30`
* **Dropout áƒ’áƒáƒ˜áƒ–áƒáƒ áƒ“áƒ**: `0.5 â†’ 0.7`
* **Spatial Dropout áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ**:
  `self.dropout1 = nn.Dropout2d(0.1)` â€” áƒáƒ“áƒ áƒ”áƒ£áƒš áƒšáƒ”áƒ˜áƒ”áƒ áƒ”áƒ‘áƒ¡ áƒ¨áƒáƒ áƒ˜áƒ¡, feature-level áƒ áƒ”áƒ’áƒ£áƒšáƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡
* **Channel áƒ™áƒáƒ›áƒáƒ áƒ”áƒ¡áƒ˜áƒ”áƒ‘áƒ˜ áƒ‘áƒáƒšáƒ Conv áƒ¤áƒ”áƒœáƒ”áƒ‘áƒ¨áƒ˜**: `256 â†’ 192`
* **FC áƒ¤áƒ”áƒœáƒ”áƒ‘áƒ˜ áƒ’áƒáƒ›áƒáƒ áƒ¢áƒ˜áƒ•áƒ“áƒ**: `512 â†’ 256`
* **Early Stopping áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜ áƒ’áƒáƒ›áƒ™áƒáƒªáƒ áƒ“áƒ**:

  ```python
  'early_stop_patience': 7,  # More aggressive early stopping
  'lr_patience': 3,          # Reduce LR sooner
  ```

### ğŸ¯ Goal

* **Overfitting-áƒ˜áƒ¡ áƒ¨áƒ”áƒ›áƒªáƒ˜áƒ áƒ”áƒ‘áƒ**
* **áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ’áƒ”áƒœáƒ”áƒ áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ’áƒáƒ£áƒ›áƒ¯áƒáƒ‘áƒ”áƒ¡áƒ”áƒ‘áƒ**
* **áƒ›áƒ”áƒ¢áƒáƒ“ áƒ¡áƒ¬áƒ áƒáƒ¤áƒ˜ áƒ“áƒ áƒáƒ’áƒ áƒ”áƒ¡áƒ˜áƒ£áƒšáƒ˜ áƒáƒ“áƒáƒáƒ¢áƒáƒªáƒ˜áƒ validation performance-áƒ–áƒ”**

### â³ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒáƒšáƒáƒ“áƒ˜áƒœáƒ˜

* áƒ£áƒ™áƒ”áƒ—áƒ”áƒ¡áƒ˜ generalization-validation áƒ‘áƒáƒšáƒáƒœáƒ¡áƒ˜
* áƒœáƒáƒ™áƒšáƒ”áƒ‘áƒ˜ variance epochs-áƒ¡ áƒ¨áƒáƒ áƒ˜áƒ¡
* áƒœáƒáƒ™áƒšáƒ”áƒ‘áƒ˜ training-validation gap


#### ğŸ“Š Results

* **Train Loss**: `0.1689`, **Train Accuracy**: `93.93%`
* **Val Loss**: `2.3061`, **Val Accuracy**: `57.72%`
* **Early Stopping**: áƒ’áƒáƒœáƒ®áƒáƒ áƒªáƒ˜áƒ”áƒšáƒ“áƒ **24-áƒ” áƒ”áƒáƒáƒ¥áƒáƒ–áƒ”**


[Deeper_cnn_v2](https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/ql1dpugq?nw=nwuserellekvirikashvili)


### V3
áƒáƒ› áƒ“áƒ áƒáƒ›áƒ“áƒ” áƒ áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ”áƒ‘áƒ˜áƒª áƒ’áƒáƒ•áƒ¢áƒ”áƒ¡áƒ¢áƒ”, áƒáƒ¨áƒ™áƒáƒ áƒ áƒ˜áƒ§áƒ áƒ áƒáƒ› áƒ§áƒ•áƒ”áƒšáƒáƒ¤áƒ”áƒ áƒ¡ áƒ°áƒ¥áƒáƒœáƒ“áƒ class imbalance áƒáƒ áƒáƒ‘áƒšáƒ”áƒ›áƒ, áƒ’áƒáƒœáƒ¡áƒáƒ™áƒ£áƒ—áƒ áƒ”áƒ‘áƒ˜áƒ— áƒ áƒáƒ’áƒáƒ áƒª data exploration-áƒ¨áƒ˜áƒª áƒ’áƒáƒ›áƒáƒ©áƒœáƒ“áƒ, áƒ«áƒáƒšáƒ˜áƒáƒœ áƒªáƒáƒ¢áƒ áƒ’áƒ•áƒáƒ¥áƒ•áƒ¡ áƒ›áƒáƒ’áƒáƒšáƒ˜áƒ—áƒáƒ“ Disgust áƒ™áƒšáƒáƒ¡áƒ˜.

áƒáƒ› áƒ¨áƒ”áƒ›áƒ—áƒ®áƒ•áƒ”áƒ•áƒáƒ¨áƒ˜ áƒ’áƒáƒ•áƒ¢áƒ”áƒ¡áƒ¢áƒ” áƒ˜áƒ’áƒ˜áƒ•áƒ” áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ£áƒ áƒáƒªáƒ˜áƒ, áƒ áƒáƒª áƒ›áƒ”áƒáƒ áƒ” áƒ•áƒ”áƒ áƒ¡áƒ˜áƒáƒ¨áƒ˜, áƒ£áƒ‘áƒ áƒáƒšáƒáƒ“ áƒáƒ£áƒ’áƒ›áƒ”áƒœáƒ¢áƒáƒªáƒ˜áƒ, áƒ™áƒ”áƒ áƒ«áƒáƒ“:
#### Basic Flow for Augmented Training:
`Tensor (from dataset) â†’ ToPILImage() â†’ PIL Augmentations â†’ ToTensor() â†’ Tensor Augmentations â†’ Normalize`


#### áƒ©áƒ”áƒ›áƒ˜ áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ features:

- Â±15Â° random rotation
- 50% horizontal flip probability
- Random translation (Â±10% of image size)
- Random scaling (90%-110%)
- Random shear transformation
- Brightness/contrast jitter
- Random erasing (10% probability)


#### ğŸ“Š Results


[Deep CNN V3 (with Augmentation)](https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/mv3b6zp2?nw=nwuserellekvirikashvili)
---

## âœ… áƒ“áƒáƒ¡áƒ™áƒ•áƒœáƒ

> áƒáƒ˜áƒ áƒ•áƒ”áƒšáƒ˜ áƒ•áƒ”áƒ áƒ¡áƒ˜áƒ áƒ—áƒáƒ•áƒ˜áƒ“áƒáƒœ áƒ™áƒáƒ áƒ’áƒáƒ“ áƒ›áƒ˜áƒ“áƒ˜áƒáƒ“áƒ training áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ–áƒ”, áƒ›áƒáƒ’áƒ áƒáƒ› áƒ¬áƒáƒ•áƒ˜áƒ“áƒ overfitting-áƒ¨áƒ˜ áƒ“áƒ early stopping-áƒ›áƒ áƒ’áƒáƒáƒ©áƒ”áƒ áƒ. áƒ“áƒ áƒ¡áƒáƒ­áƒ˜áƒ áƒ áƒ’áƒáƒ®áƒ“áƒ áƒ£áƒ™áƒ”áƒ—áƒ”áƒ¡áƒ˜ áƒ áƒ”áƒ’áƒ£áƒšáƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒ“áƒ áƒáƒ“áƒ áƒ”áƒ£áƒšáƒ˜ learning rate decay. 
> áƒ›áƒ”áƒáƒ áƒ” áƒ•áƒ”áƒ áƒ¡áƒ˜áƒ áƒ›áƒ˜áƒ“áƒ˜áƒ¡ **leaner architecture + smarter regularization** áƒ¡áƒ¢áƒ áƒáƒ¢áƒ”áƒ’áƒ˜áƒ˜áƒ—, áƒ áƒáƒ—áƒ áƒ“áƒáƒ˜áƒ‘áƒáƒšáƒáƒœáƒ¡áƒáƒ¡ áƒ¡áƒ˜áƒ¡áƒ¬áƒ áƒáƒ¤áƒ”, áƒ¡áƒ˜áƒ–áƒ£áƒ¡áƒ¢áƒ” áƒ“áƒ áƒ¡áƒ¢áƒáƒ‘áƒ˜áƒšáƒ£áƒ áƒáƒ‘áƒ.
> áƒ›áƒ”áƒ¡áƒáƒ›áƒ” áƒ•áƒ”áƒ áƒ¡áƒ˜áƒáƒ¨áƒ˜ áƒ•áƒªáƒáƒ“áƒ” transform-áƒ”áƒ‘áƒ˜, áƒ¡áƒ¬áƒáƒ•áƒšáƒ áƒ’áƒáƒ£áƒ­áƒ˜áƒ áƒ“áƒ, áƒ¡áƒáƒ™áƒ›áƒáƒáƒ“ áƒ“áƒ˜áƒ“áƒ˜ áƒ“áƒ áƒ áƒ“áƒáƒ¡áƒ­áƒ˜áƒ áƒ“áƒ 40% áƒáƒ™áƒ£áƒ áƒáƒ¢áƒ£áƒšáƒáƒ‘áƒáƒ–áƒ” áƒáƒ¡áƒ£áƒšáƒ˜áƒ§áƒ.


## 04_attention_cnn.ipynb

### ğŸ§  Attention-based CNN Architecture

#### ğŸ” Overview
A Convolutional Neural Network enhanced with Convolutional Block Attention Module (CBAM) that learns to focus on the most discriminative facial regions for expression recognition.

#### ğŸ— Core Architecture

```
Input (1, 48, 48)
â”œâ”€ Conv2d(1, 32) â†’ BatchNorm â†’ ReLU
â”œâ”€ Conv2d(32, 32) â†’ BatchNorm â†’ ReLU â†’ MaxPool2d(2)
â””â”€ CBAM(32)  # First attention block

â”œâ”€ Conv2d(32, 64) â†’ BatchNorm â†’ ReLU
â”œâ”€ Conv2d(64, 64) â†’ BatchNorm â†’ ReLU â†’ MaxPool2d(2)
â””â”€ CBAM(64)  # Second attention block

â”œâ”€ Conv2d(64, 128) â†’ BatchNorm â†’ ReLU
â”œâ”€ Conv2d(128, 128) â†’ BatchNorm â†’ ReLU â†’ MaxPool2d(2)
â””â”€ CBAM(128)  # Third attention block

â”œâ”€ AdaptiveAvgPool2d(1)
â”œâ”€ Flatten
â”œâ”€ Linear(128, 256) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.5)
â””â”€ Linear(256, 7)  # 7 emotion classes
```

#### ğŸ¯ Attention Mechanism (CBAM)

**Convolutional Block Attention Module** combines:

1. **Channel Attention**
   - Captures 'what' to focus on in the feature maps
   - Uses both average and max pooling paths
   - Learns channel-wise feature importance

2. **Spatial Attention**
   - Determines 'where' to focus in the spatial dimensions
   - Applies 1x1 convolutions to create spatial attention maps
   - Highlights important facial regions for expression recognition

#### âš™ï¸ Training Configuration
- **Optimizer**: AdamW with weight decay (1e-4)
- **Learning Rate**: 0.001 with ReduceLROnPlateau scheduling
- **Regularization**:
  - Dropout (0.5) in fully connected layers
  - L2 weight decay
  - Data augmentation (random horizontal flip, rotation)
- **Batch Size**: 64
- **Epochs**: 50 with early stopping

#### ğŸ“Š Performance Features
- **Visual Attention Maps**: Visualize which facial regions the model focuses on
- **Class Activation Mapping**: Understand model decisions
- **W&B Integration**: Track experiments and compare runs
- **Confusion Matrix**: Detailed performance analysis

#### ğŸš€ Key Benefits
1. **Improved Accuracy**: Focuses on relevant facial features
2. **Better Generalization**: Attention acts as a form of regularization
3. **Interpretability**: Visual explanations of model decisions
4. **Efficiency**: Lightweight attention modules with minimal computational overhead

#### ğŸ›  Implementation Details
- Uses PyTorch for model implementation
- Integrates with Weights & Biases for experiment tracking
- Includes comprehensive data augmentation
- Implements learning rate scheduling and early stopping

#### ğŸ“ˆ Expected Performance
- Training Accuracy: ~85-90%
- Validation Accuracy: ~60-65%
- Focuses on eyes, mouth, and eyebrow regions for expression recognition

## ğŸ” Weights & Biases áƒ˜áƒœáƒ¢áƒ”áƒ’áƒ áƒáƒªáƒ˜áƒ

áƒ§áƒ•áƒ”áƒšáƒ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒšáƒáƒ’áƒ˜áƒ áƒ“áƒ”áƒ‘áƒ Weights & Biases-áƒ¨áƒ˜ áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’áƒ˜ áƒ¡áƒ¢áƒ áƒ£áƒ¥áƒ¢áƒ£áƒ áƒ˜áƒ—:

* áƒáƒ áƒáƒ”áƒ¥áƒ¢áƒ˜: `facial-expression-recognition`
* áƒ¢áƒ”áƒ’áƒ”áƒ‘áƒ˜: `[model_type, dataset_version, experiment_type]`
* áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ˜: áƒ°áƒ˜áƒáƒ”áƒ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒáƒ áƒ¥áƒ˜áƒ¢áƒ”áƒ¥áƒ¢áƒ£áƒ áƒ
* áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜: áƒ¡áƒ¬áƒáƒ•áƒšáƒ”áƒ‘áƒ˜áƒ¡/áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜
* áƒáƒ áƒ¢áƒ˜áƒ¤áƒáƒ¥áƒ¢áƒ”áƒ‘áƒ˜: áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒœáƒáƒ®áƒ£áƒšáƒ˜ áƒ¬áƒáƒœáƒ”áƒ‘áƒ˜

## ğŸ“ áƒ›áƒ˜áƒ’áƒœáƒ”áƒ‘áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒáƒœáƒáƒšáƒ˜áƒ–áƒ˜

áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒ«áƒ˜áƒ áƒ˜áƒ—áƒáƒ“áƒ˜ áƒ›áƒ˜áƒ’áƒœáƒ”áƒ‘áƒ”áƒ‘áƒ˜:

1. **áƒ’áƒáƒ“áƒáƒ›áƒ”áƒ¢áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ›áƒáƒ áƒ’áƒ”áƒ‘áƒ**: áƒ›áƒáƒ’áƒ•áƒáƒ áƒ“áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒáƒ£áƒ’áƒ›áƒ”áƒœáƒ¢áƒáƒªáƒ˜áƒ˜áƒ—áƒ áƒ“áƒ dropout-áƒ˜áƒ—
2. **áƒ™áƒšáƒáƒ¡áƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒ˜áƒ¡áƒ‘áƒáƒšáƒáƒœáƒ¡áƒ˜**: áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ¬áƒáƒœáƒ˜áƒáƒœáƒ˜ áƒ“áƒáƒœáƒáƒ™áƒáƒ áƒ’áƒ˜áƒ¡ áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ”áƒ‘áƒ˜
3. **áƒ¡áƒáƒ¡áƒ¬áƒáƒ•áƒšáƒ áƒ¡áƒ˜áƒ©áƒ¥áƒáƒ áƒ˜áƒ¡ áƒªáƒ•áƒšáƒ**: áƒ“áƒ˜áƒ“áƒ˜ áƒ’áƒáƒ•áƒšáƒ”áƒœáƒ áƒáƒ¥áƒ•áƒ¡ áƒ™áƒáƒœáƒ•áƒ”áƒ áƒ’áƒ”áƒœáƒªáƒ˜áƒáƒ–áƒ”
4. **áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ¡áƒ˜áƒ¦áƒ áƒ›áƒ”**: áƒ‘áƒáƒšáƒáƒœáƒ¡áƒ˜ áƒ¡áƒ˜áƒ áƒ—áƒ£áƒšáƒ”áƒ¡áƒ áƒ“áƒ áƒ”áƒ¤áƒ”áƒ¥áƒ¢áƒ£áƒ áƒáƒ‘áƒáƒ¡ áƒ¨áƒáƒ áƒ˜áƒ¡


