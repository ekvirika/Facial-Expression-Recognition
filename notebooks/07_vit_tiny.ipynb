{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install wandb torch torchvision timm pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# Set up Kaggle API\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8808e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Config\n",
    "CONFIG = {\n",
    "    'epochs': 10,\n",
    "    'batch_size': 64,\n",
    "    'lr': 1e-4,\n",
    "    'img_size': 224,\n",
    "    'num_classes': 7,\n",
    "    'project': 'emotion-recognition',\n",
    "    'run_name': 'vit-tiny-experiment'\n",
    "}\n",
    "\n",
    "# WandB init\n",
    "wandb.init(project=CONFIG['project'], name=CONFIG['run_name'], config=CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder('data/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder('data/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# Model\n",
    "model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=CONFIG['num_classes'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'])\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = 100. * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "        wandb.log({\"train_loss\": epoch_loss, \"train_accuracy\": accuracy})\n",
    "        \n",
    "        evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbca588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "\n",
    "    class_report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    wandb.log({\"classification_report\": class_report})\n",
    "\n",
    "    # Log a few example predictions\n",
    "    class_names = data_loader.dataset.classes\n",
    "    rand_indices = random.sample(range(len(all_preds)), 5)\n",
    "    for i in rand_indices:\n",
    "        img, label = data_loader.dataset[i]\n",
    "        img_np = img.permute(1,2,0).numpy() * 0.5 + 0.5\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"True: {class_names[label]} | Pred: {class_names[all_preds[i]]}\")\n",
    "        plt.axis('off')\n",
    "        wandb.log({f\"sample_prediction_{i}\": wandb.Image(plt)})\n",
    "        plt.close()\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Train\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, CONFIG['epochs'])\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'vit_tiny_final.pth')\n",
    "wandb.save('vit_tiny_final.pth')\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
