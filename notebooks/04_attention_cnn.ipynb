{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9e1a13",
   "metadata": {},
   "source": [
    "# Attention-based CNN for Facial Expression Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa4609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install wandb torch torchvision pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# Set up Kaggle API\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your kaggle.json to Colab and run:\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90914d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
    "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b9a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'attention_cnn',\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 50,\n",
    "    'image_size': 48,\n",
    "    'num_classes': 7,\n",
    "    'random_seed': 42,\n",
    "    'weight_decay': 1e-4,\n",
    "    'dropout_rate': 0.5,\n",
    "    'attention_heads': 4  # Number of attention heads\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "np.random.seed(CONFIG['random_seed'])\n",
    "\n",
    "# Initialize Weights & Biases for experiment tracking\n",
    "wandb.init(\n",
    "    project=\"facial-expression-recognition\",\n",
    "    name=f\"{CONFIG['model_name']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "    config=CONFIG,\n",
    "    job_type=\"training\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c4994",
   "metadata": {},
   "source": [
    "## Dataset and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FERDataset(Dataset):\n",
    "    def __init__(self, dataframe, indices, transform=None):\n",
    "        self.data = dataframe.iloc[indices].reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pixels = self.data.iloc[idx]['pixels']\n",
    "        image = np.array(pixels.split(), dtype=np.uint8).reshape(48, 48)\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # Add channel dimension\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = int(self.data.iloc[idx]['emotion'])\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b7bd3",
   "metadata": {},
   "source": [
    "## Attention Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=8):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return x * out\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
    "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
    "        out = (avg_out + max_out).view(b, c, 1, 1)\n",
    "        return x * out\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolutional Block Attention Module\"\"\"\n",
    "    def __init__(self, in_channels, reduction_ratio=8):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_att = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.spatial_att = SpatialAttention(in_channels, reduction_ratio)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttentionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7, dropout_rate=0.5):\n",
    "        super(AttentionCNN, self).__init__()\n",
    "        \n",
    "        # Initial conv block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Attention after first block\n",
    "        self.att1 = CBAM(32)\n",
    "        \n",
    "        # Second conv block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Attention after second block\n",
    "        self.att2 = CBAM(64)\n",
    "        \n",
    "        # Third conv block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Attention after third block\n",
    "        self.att3 = CBAM(128)\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First block\n",
    "        x = self.conv1(x)\n",
    "        x = self.att1(x)\n",
    "        \n",
    "        # Second block\n",
    "        x = self.conv2(x)\n",
    "        x = self.att2(x)\n",
    "        \n",
    "        # Third block\n",
    "        x = self.conv3(x)\n",
    "        x = self.att3(x)\n",
    "        \n",
    "        # Global average pooling and flatten\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for inputs, labels in train_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix({\n",
    "                'loss': running_loss / total,\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "        \n",
    "        # Log training metrics\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = 100. * correct / len(train_loader.dataset)\n",
    "        \n",
    "        wandb.log({\n",
    "            'train/loss': epoch_loss,\n",
    "            'train/accuracy': epoch_acc,\n",
    "            'epoch': epoch\n",
    "        })\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        # Log validation metrics\n",
    "        wandb.log({\n",
    "            'val/loss': val_loss,\n",
    "            'val/accuracy': val_acc,\n",
    "            'epoch': epoch\n",
    "        })\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_attention_cnn.pth')\n",
    "            print(f'Model saved with validation accuracy: {val_acc:.2f}%')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffa1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc='Evaluating'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = 100. * correct / len(data_loader.dataset)\n",
    "    \n",
    "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    # Log confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
    "    plt.close()\n",
    "    \n",
    "    # Log classification report\n",
    "    class_report = classification_report(all_labels, all_preds, output_dict=True)\n",
    "    wandb.log({\"classification_report\": class_report})\n",
    "    \n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194598e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('../train.csv')\n",
    "\n",
    "# Load train/val indices (assuming they're saved from previous experiments)\n",
    "try:\n",
    "    train_indices = np.load('../train_indices.npy')\n",
    "    val_indices = np.load('../val_indices.npy')\n",
    "except FileNotFoundError:\n",
    "    # If indices files don't exist, create them\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(len(train_df)), \n",
    "        test_size=0.2, \n",
    "        random_state=CONFIG['random_seed'],\n",
    "        stratify=train_df['emotion']\n",
    "    )\n",
    "    np.save('../train_indices.npy', train_indices)\n",
    "    np.save('../val_indices.npy', val_indices)\n",
    "\n",
    "# Create datasets\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset = FERDataset(train_df, train_indices, transform=train_transform)\n",
    "val_dataset = FERDataset(train_df, val_indices, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                        shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], \n",
    "                        shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315fad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = AttentionCNN(num_classes=CONFIG['num_classes'], \n",
    "                    dropout_rate=CONFIG['dropout_rate']).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                        lr=CONFIG['learning_rate'],\n",
    "                        weight_decay=CONFIG['weight_decay'])\n",
    "\n",
    "# Log model architecture to wandb\n",
    "wandb.watch(model, log='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                    num_epochs=CONFIG['epochs'])\n",
    "\n",
    "# Final evaluation\n",
    "print(\"Final evaluation...\")\n",
    "evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "# Save the final model\n",
    "torch.save(model.state_dict(), 'final_attention_cnn.pth')\n",
    "wandb.save('*.pth')\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
