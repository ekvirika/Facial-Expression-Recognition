{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d9e1a13",
      "metadata": {
        "id": "8d9e1a13"
      },
      "source": [
        "# Attention-based CNN for Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6aa4609d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aa4609d",
        "outputId": "5923b00c-5f32-449e-8c50-468ccec50476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c436a8a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c436a8a7",
        "outputId": "10f7ee9d-d101-4f57-f69d-1c3066c84840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install wandb torch torchvision pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "# Set up Kaggle API\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e30fbb46",
      "metadata": {
        "id": "e30fbb46"
      },
      "outputs": [],
      "source": [
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "90914d2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90914d2d",
        "outputId": "245c8f10-8411-49f0-b5ff-a27f1c66e2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 86% 246M/285M [00:00<00:00, 445MB/s]\n",
            "100% 285M/285M [00:00<00:00, 475MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "91b9a71e",
      "metadata": {
        "id": "91b9a71e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a95c118b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a95c118b",
        "outputId": "91fbb44a-2b93-4b80-cc9e-5977699a59e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-87a88fb088a7>:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'model_name': 'attention_cnn_v3',\n",
        "    'batch_size': 64,\n",
        "    'learning_rate': 0.0005,\n",
        "    'epochs': 40,\n",
        "    'image_size': 48,\n",
        "    'num_classes': 7,\n",
        "    'random_seed': 42,\n",
        "    'weight_decay': 1e-4,\n",
        "    'dropout_rate': 0.5,\n",
        "    'attention_heads': 4  # Number of attention heads\n",
        "}\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(CONFIG['random_seed'])\n",
        "np.random.seed(CONFIG['random_seed'])\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Use mixed precision training\n",
        "scaler = torch.cuda.amp.GradScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Weights & Biases for experiment tracking\n",
        "wandb.init(\n",
        "    project=\"facial-expression-recognition\",\n",
        "    name=f\"{CONFIG['model_name']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "    config=CONFIG,\n",
        "    job_type=\"training\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "NpYb-R1LrQCR",
        "outputId": "d0478cdc-f30d-4a46-8cb0-cc76fa36af37"
      },
      "id": "NpYb-R1LrQCR",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250530_153100-4a37ougz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/4a37ougz' target=\"_blank\">attention_cnn_20250530_153100</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/4a37ougz' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/4a37ougz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/4a37ougz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7c6c614f2bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6c4994",
      "metadata": {
        "id": "eb6c4994"
      },
      "source": [
        "## Dataset and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b6bc88c4",
      "metadata": {
        "id": "b6bc88c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe, indices, transform=None):\n",
        "        self.data = dataframe.iloc[indices].reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        image = np.array(pixels.split(), dtype=np.uint8).reshape(48, 48)\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        image = torch.from_numpy(image).unsqueeze(0)  # Add channel dimension\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = int(self.data.iloc[idx]['emotion'])\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca8b7bd3",
      "metadata": {
        "id": "ca8b7bd3"
      },
      "source": [
        "## Attention Mechanisms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "56ef9047",
      "metadata": {
        "id": "56ef9047"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=8):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return x * out\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=8):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
        "        max_out = self.fc(self.max_pool(x).view(b, c))\n",
        "        out = (avg_out + max_out).view(b, c, 1, 1)\n",
        "        return x * out\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    \"\"\"Convolutional Block Attention Module\"\"\"\n",
        "    def __init__(self, in_channels, reduction_ratio=8):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_att = ChannelAttention(in_channels, reduction_ratio)\n",
        "        self.spatial_att = SpatialAttention(in_channels, reduction_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_att(x)\n",
        "        x = self.spatial_att(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5433b85c",
      "metadata": {
        "id": "5433b85c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AttentionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout_rate=0.5):\n",
        "        super(AttentionCNN, self).__init__()\n",
        "\n",
        "        # Initial conv block\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Attention after first block\n",
        "        self.att1 = CBAM(32)\n",
        "\n",
        "        # Second conv block\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Attention after second block\n",
        "        self.att2 = CBAM(64)\n",
        "\n",
        "        # Third conv block\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Attention after third block\n",
        "        self.att3 = CBAM(128)\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First block\n",
        "        x = self.conv1(x)\n",
        "        x = self.att1(x)\n",
        "\n",
        "        # Second block\n",
        "        x = self.conv2(x)\n",
        "        x = self.att2(x)\n",
        "\n",
        "        # Third block\n",
        "        x = self.conv3(x)\n",
        "        x = self.att3(x)\n",
        "\n",
        "        # Global average pooling and flatten\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LightAttentionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        # Initial conv block\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Attention after first block\n",
        "        self.att1 = CBAM(16)\n",
        "\n",
        "        # Second conv block\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Attention after second block\n",
        "        self.att2 = CBAM(32)\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First convolutional block + attention\n",
        "        x = self.conv1(x)\n",
        "        x = self.att1(x)\n",
        "\n",
        "        # Second convolutional block + attention\n",
        "        x = self.conv2(x)\n",
        "        x = self.att2(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)  # Flatten to (batch_size, 32)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mGPXu8zqoxr9"
      },
      "id": "mGPXu8zqoxr9",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4c4b319e",
      "metadata": {
        "id": "4c4b319e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
        "    best_val_acc = 0.1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
        "\n",
        "        for inputs, labels in train_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Update progress bar\n",
        "            train_bar.set_postfix({\n",
        "                'loss': running_loss / total,\n",
        "                'acc': 100. * correct / total\n",
        "            })\n",
        "\n",
        "            # In your training loop:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        # Log training metrics\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "        wandb.log({\n",
        "            'train/loss': epoch_loss,\n",
        "            'train/accuracy': epoch_acc,\n",
        "            'epoch': epoch\n",
        "        })\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n",
        "\n",
        "        # Log validation metrics\n",
        "        wandb.log({\n",
        "            'val/loss': val_loss,\n",
        "            'val/accuracy': val_acc,\n",
        "            'epoch': epoch\n",
        "        })\n",
        "\n",
        "        # Save the best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_attention_cnn.pth')\n",
        "            print(f'Model saved with validation accuracy: {val_acc:.2f}%')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2dffa1f9",
      "metadata": {
        "id": "2dffa1f9"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc='Evaluating'):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_images.extend(inputs.cpu())  # Keep the actual image tensors\n",
        "\n",
        "    avg_loss = running_loss / len(data_loader.dataset)\n",
        "    accuracy = 100. * correct / len(data_loader.dataset)\n",
        "\n",
        "    print(f'Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    # ðŸ§© Log confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    # ðŸ“œ Log classification report\n",
        "    class_report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    wandb.log({\"classification_report\": class_report})\n",
        "\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "194598e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "194598e7",
        "outputId": "e747e1b0-0f32-4b60-b69e-922e96265b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "train_df = pd.read_csv('train.csv')\n",
        "\n",
        "# Load train/val indices (assuming they're saved from previous experiments)\n",
        "try:\n",
        "    train_indices = np.load('../train_indices.npy')\n",
        "    val_indices = np.load('../val_indices.npy')\n",
        "except FileNotFoundError:\n",
        "    # If indices files don't exist, create them\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        np.arange(len(train_df)),\n",
        "        test_size=0.2,\n",
        "        random_state=CONFIG['random_seed'],\n",
        "        stratify=train_df['emotion']\n",
        "    )\n",
        "    np.save('../train_indices.npy', train_indices)\n",
        "    np.save('../val_indices.npy', val_indices)\n",
        "\n",
        "# Create datasets\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_dataset = FERDataset(train_df, train_indices, transform=train_transform)\n",
        "val_dataset = FERDataset(train_df, val_indices, transform=val_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'],\n",
        "                        shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'],\n",
        "                        shuffle=False, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "315fad84",
      "metadata": {
        "id": "315fad84"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = AttentionCNN(num_classes=CONFIG['num_classes'],\n",
        "                    dropout_rate=CONFIG['dropout_rate']).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                        lr=CONFIG['learning_rate'],\n",
        "                        weight_decay=CONFIG['weight_decay'])\n",
        "\n",
        "# Log model architecture to wandb\n",
        "wandb.watch(model, log='all')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "46ad2794",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "46ad2794",
        "outputId": "6ff678b6-7c4a-4b71-e68e-9f7a4c0124e6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/40 [Train]:   0%|          | 0/359 [00:01<?, ?it/s, loss=2.09, acc=14.1]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:39<00:00,  9.13it/s, loss=1.7, acc=31.8]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 20.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.4710, Accuracy: 42.89%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved with validation accuracy: 42.89%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 2/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.32, acc=51.6]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 2/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.23it/s, loss=1.34, acc=48.3]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 15.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.3240, Accuracy: 49.22%\n",
            "Model saved with validation accuracy: 49.22%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 3/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.2, acc=59.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 3/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.17it/s, loss=1.22, acc=53.7]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1751, Accuracy: 54.84%\n",
            "Model saved with validation accuracy: 54.84%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 4/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.2, acc=57.8]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 4/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.71it/s, loss=1.16, acc=56]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 21.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1320, Accuracy: 57.54%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved with validation accuracy: 57.54%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 5/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.13, acc=54.7]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 5/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.96it/s, loss=1.1, acc=58.3]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 17.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0988, Accuracy: 57.87%\n",
            "Model saved with validation accuracy: 57.87%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 6/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.18, acc=54.7]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 6/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.09it/s, loss=1.08, acc=58.8]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0827, Accuracy: 58.90%\n",
            "Model saved with validation accuracy: 58.90%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 7/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.04, acc=60.9]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 7/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.87it/s, loss=1.05, acc=60.1]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 18.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0760, Accuracy: 58.81%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 8/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.04, acc=60.9]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 8/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.18it/s, loss=1.02, acc=61.6]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 22.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0081, Accuracy: 61.32%\n",
            "Model saved with validation accuracy: 61.32%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 9/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.894, acc=70.3]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 9/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:37<00:00,  9.69it/s, loss=1, acc=62.4]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.78it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0847, Accuracy: 59.80%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 10/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.14, acc=54.7]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 10/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.08it/s, loss=0.986, acc=63]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 15.26it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0106, Accuracy: 61.95%\n",
            "Model saved with validation accuracy: 61.95%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 11/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.958, acc=62.5]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 11/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00,  9.97it/s, loss=0.963, acc=63.5]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1128, Accuracy: 59.93%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 12/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=1.07, acc=60.9]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 12/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:37<00:00,  9.49it/s, loss=0.948, acc=64.5]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1117, Accuracy: 58.83%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 13/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.708, acc=73.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 13/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.91it/s, loss=0.932, acc=64.8]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 16.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0307, Accuracy: 61.79%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 14/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.785, acc=75]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 14/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.09it/s, loss=0.913, acc=65.7]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.70it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9828, Accuracy: 63.44%\n",
            "Model saved with validation accuracy: 63.44%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 15/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.873, acc=71.9]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 15/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:37<00:00,  9.60it/s, loss=0.898, acc=66.3]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.61it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0156, Accuracy: 62.16%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 16/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.951, acc=62.5]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 16/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.25it/s, loss=0.884, acc=67]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 19.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0857, Accuracy: 60.19%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 17/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.667, acc=76.6]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 17/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.92it/s, loss=0.872, acc=67.2]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 24.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9842, Accuracy: 63.44%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 18/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.763, acc=70.3]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 18/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.20it/s, loss=0.859, acc=68]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 15.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0448, Accuracy: 62.52%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 19/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.909, acc=70.3]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 19/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.20it/s, loss=0.845, acc=68.1]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0365, Accuracy: 62.63%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 20/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.878, acc=67.2]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 20/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.94it/s, loss=0.825, acc=69.2]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 18.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0453, Accuracy: 62.49%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 21/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.84, acc=65.6]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 21/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.19it/s, loss=0.824, acc=69.1]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0316, Accuracy: 61.89%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 22/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.731, acc=73.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 22/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.77it/s, loss=0.803, acc=69.8]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 24.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0470, Accuracy: 63.86%\n",
            "Model saved with validation accuracy: 63.86%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 23/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.893, acc=67.2]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 23/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.20it/s, loss=0.792, acc=70.4]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 16.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0541, Accuracy: 62.33%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 24/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.629, acc=79.7]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 24/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.13it/s, loss=0.785, acc=70.9]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 24.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0242, Accuracy: 63.57%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 25/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.573, acc=75]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 25/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.78it/s, loss=0.774, acc=71.4]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 21.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0360, Accuracy: 63.20%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 26/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.572, acc=79.7]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 26/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:34<00:00, 10.28it/s, loss=0.758, acc=71.5]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 18.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1016, Accuracy: 61.93%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 27/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.632, acc=76.6]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 27/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.94it/s, loss=0.751, acc=71.6]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 24.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0348, Accuracy: 64.26%\n",
            "Model saved with validation accuracy: 64.26%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 28/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.955, acc=68.8]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 28/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.11it/s, loss=0.746, acc=72.2]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 16.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0340, Accuracy: 64.59%\n",
            "Model saved with validation accuracy: 64.59%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 29/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.736, acc=65.6]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 29/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.17it/s, loss=0.73, acc=72.6]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 24.05it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1444, Accuracy: 62.31%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 30/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.668, acc=73.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 30/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.72it/s, loss=0.715, acc=73.4]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.12it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.2187, Accuracy: 59.93%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 31/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.644, acc=76.6]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 31/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.20it/s, loss=0.714, acc=73.3]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 18.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0875, Accuracy: 62.64%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 32/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.572, acc=79.7]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 32/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.07it/s, loss=0.693, acc=74]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0599, Accuracy: 63.93%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 33/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.551, acc=82.8]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 33/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00, 10.24it/s, loss=0.689, acc=74.3]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 15.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0764, Accuracy: 63.38%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 34/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.682, acc=73.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 34/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:37<00:00,  9.51it/s, loss=0.678, acc=74.6]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 19.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0912, Accuracy: 64.51%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 35/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.443, acc=85.9]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 35/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.79it/s, loss=0.668, acc=75.1]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:03<00:00, 23.63it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1303, Accuracy: 63.34%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 36/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.74, acc=73.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 36/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:35<00:00,  9.98it/s, loss=0.66, acc=75.2]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 16.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1516, Accuracy: 62.78%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 37/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.462, acc=84.4]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 37/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:38<00:00,  9.43it/s, loss=0.652, acc=75.9]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 18.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0699, Accuracy: 64.82%\n",
            "Model saved with validation accuracy: 64.82%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 38/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.515, acc=78.1]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 38/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:39<00:00,  9.14it/s, loss=0.644, acc=76.2]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 22.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1225, Accuracy: 64.44%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 39/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.496, acc=81.2]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 39/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:38<00:00,  9.21it/s, loss=0.632, acc=76.6]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 22.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1336, Accuracy: 64.11%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 40/40 [Train]:   0%|          | 0/359 [00:00<?, ?it/s, loss=0.713, acc=70.3]<ipython-input-12-aa2d96ed0114>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 40/40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:36<00:00,  9.89it/s, loss=0.627, acc=76.5]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:05<00:00, 15.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1649, Accuracy: 63.62%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                    num_epochs=CONFIG['epochs'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation\n",
        "print(\"Final evaluation...\")\n",
        "evaluate_model(model, val_loader, criterion)\n",
        "\n",
        "# Save the final model\n",
        "torch.save(model.state_dict(), 'final_attention_cnn.pth')\n",
        "wandb.save('*.pth')\n",
        "\n",
        "print(\"Training completed!\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x0oedvvuwynD",
        "outputId": "d9bd9475-e110-4505-adb4-17fc3f6c0d0b"
      },
      "id": "x0oedvvuwynD",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating:   0%|          | 0/90 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:04<00:00, 21.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1649, Accuracy: 63.62%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "You must call wandb.init() before wandb.log()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b747bcf1a9da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Final evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final evaluation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save the final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-b994cf085d04>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader, criterion)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"confusion_matrix\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/preinit.py\u001b[0m in \u001b[0;36mpreinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Callable:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must call wandb.init() before {name}()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpreinit_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}