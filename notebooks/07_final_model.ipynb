{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "krOeI7KHUyH-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krOeI7KHUyH-",
        "outputId": "f098ae8c-6d70-4327-9e76-fd07f0ba877f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "s3WEaEbYU1f-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3WEaEbYU1f-",
        "outputId": "d8143bdf-40c7-4bb2-936b-889eb798ec84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install wandb torch torchvision pandas numpy matplotlib seaborn\n",
        "\n",
        "# Set up Kaggle API\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3zP3UP6UU2Lw",
      "metadata": {
        "id": "3zP3UP6UU2Lw"
      },
      "outputs": [],
      "source": [
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "iG29BQNbU7fy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG29BQNbU7fy",
        "outputId": "ea613c81-adaa-4496-a977-662c5ac23b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 91% 259M/285M [00:00<00:00, 469MB/s]\n",
            "100% 285M/285M [00:00<00:00, 476MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14297082",
      "metadata": {},
      "source": [
        "# Download artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "81d6750a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "81d6750a",
        "outputId": "d5181796-f107-4a83-9b4b-534f635709dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">good-sponge-3</strong> at: <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0</a><br> View project at: <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_182753-a73kggk0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_183201-1s6pzasm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/1s6pzasm' target=\"_blank\">earthy-thunder-149</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/1s6pzasm' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/1s6pzasm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Login to wandb\n",
        "wandb.login()\n",
        "\n",
        "# Init run\n",
        "run = wandb.init(project=\"facial-expression-recognition\")\n",
        "\n",
        "# Download artifacts\n",
        "cnn_artifact = run.use_artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/run-30aso492-history:v0')\n",
        "cnn_dir = cnn_artifact.download()\n",
        "\n",
        "vit_artifact = run.use_artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/vit-fer2013-final-model:v0')\n",
        "vit_dir = vit_artifact.download()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "J9ICah_VXTgU",
      "metadata": {
        "id": "J9ICah_VXTgU"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        image = np.array(pixels.split(), dtype='uint8')\n",
        "        image = image.reshape(48, 48, 1).astype('float32') / 255.0\n",
        "        image = np.repeat(image, 3, axis=-1)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1CeV8-NYXW5Y",
      "metadata": {
        "id": "1CeV8-NYXW5Y"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),  # for ViT — you can skip or change for CNN\n",
        "])\n",
        "\n",
        "test_dataset = TestDataset(test_df, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8HGEVoEXTNoa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "8HGEVoEXTNoa",
        "outputId": "32d30daa-2803-41ec-a028-0700d3ea27ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellekvirikashvili\u001b[0m (\u001b[33mellekvirikashvili-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_182753-a73kggk0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0' target=\"_blank\">good-sponge-3</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/vit-fer2013-final-model:v0', type='model')\n",
        "artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42416c06",
      "metadata": {},
      "source": [
        "# Download model from wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1I_pWQFvTamt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "1I_pWQFvTamt",
        "outputId": "736a1cb8-f54e-40f3-92f7-eede2cba7cd3"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ByobNet:\n\tMissing key(s) in state_dict: \"stem.conv.weight\", \"stem.bn.weight\", \"stem.bn.bias\", \"stem.bn.running_mean\", \"stem.bn.running_var\", \"stages.0.0.conv1_1x1.conv.weight\", \"stages.0.0.conv1_1x1.bn.weight\", \"stages.0.0.conv1_1x1.bn.bias\", \"stages.0.0.conv1_1x1.bn.running_mean\", \"stages.0.0.conv1_1x1.bn.running_var\", \"stages.0.0.conv2_kxk.conv.weight\", \"stages.0.0.conv2_kxk.bn.weight\", \"stages.0.0.conv2_kxk.bn.bias\", \"stages.0.0.conv2_kxk.bn.running_mean\", \"stages.0.0.conv2_kxk.bn.running_var\", \"stages.0.0.conv3_1x1.conv.weight\", \"stages.0.0.conv3_1x1.bn.weight\", \"stages.0.0.conv3_1x1.bn.bias\", \"stages.0.0.conv3_1x1.bn.running_mean\", \"stages.0.0.conv3_1x1.bn.running_var\", \"stages.1.0.conv1_1x1.conv.weight\", \"stages.1.0.conv1_1x1.bn.weight\", \"stages.1.0.conv1_1x1.bn.bias\", \"stages.1.0.conv1_1x1.bn.running_mean\", \"stages.1.0.conv1_1x1.bn.running_var\", \"stages.1.0.conv2_kxk.conv.weight\", \"stages.1.0.conv2_kxk.bn.weight\", \"stages.1.0.conv2_kxk.bn.bias\", \"stages.1.0.conv2_kxk.bn.running_mean\", \"stages.1.0.conv2_kxk.bn.running_var\", \"stages.1.0.conv3_1x1.conv.weight\", \"stages.1.0.conv3_1x1.bn.weight\", \"stages.1.0.conv3_1x1.bn.bias\", \"stages.1.0.conv3_1x1.bn.running_mean\", \"stages.1.0.conv3_1x1.bn.running_var\", \"stages.1.1.conv1_1x1.conv.weight\", \"stages.1.1.conv1_1x1.bn.weight\", \"stages.1.1.conv1_1x1.bn.bias\", \"stages.1.1.conv1_1x1.bn.running_mean\", \"stages.1.1.conv1_1x1.bn.running_var\", \"stages.1.1.conv2_kxk.conv.weight\", \"stages.1.1.conv2_kxk.bn.weight\", \"stages.1.1.conv2_kxk.bn.bias\", \"stages.1.1.conv2_kxk.bn.running_mean\", \"stages.1.1.conv2_kxk.bn.running_var\", \"stages.1.1.conv3_1x1.conv.weight\", \"stages.1.1.conv3_1x1.bn.weight\", \"stages.1.1.conv3_1x1.bn.bias\", \"stages.1.1.conv3_1x1.bn.running_mean\", \"stages.1.1.conv3_1x1.bn.running_var\", \"stages.1.2.conv1_1x1.conv.weight\", \"stages.1.2.conv1_1x1.bn.weight\", \"stages.1.2.conv1_1x1.bn.bias\", \"stages.1.2.conv1_1x1.bn.running_mean\", \"stages.1.2.conv1_1x1.bn.running_var\", \"stages.1.2.conv2_kxk.conv.weight\", \"stages.1.2.conv2_kxk.bn.weight\", \"stages.1.2.conv2_kxk.bn.bias\", \"stages.1.2.conv2_kxk.bn.running_mean\", \"stages.1.2.conv2_kxk.bn.running_var\", \"stages.1.2.conv3_1x1.conv.weight\", \"stages.1.2.conv3_1x1.bn.weight\", \"stages.1.2.conv3_1x1.bn.bias\", \"stages.1.2.conv3_1x1.bn.running_mean\", \"stages.1.2.conv3_1x1.bn.running_var\", \"stages.2.0.conv1_1x1.conv.weight\", \"stages.2.0.conv1_1x1.bn.weight\", \"stages.2.0.conv1_1x1.bn.bias\", \"stages.2.0.conv1_1x1.bn.running_mean\", \"stages.2.0.conv1_1x1.bn.running_var\", \"stages.2.0.conv2_kxk.conv.weight\", \"stages.2.0.conv2_kxk.bn.weight\", \"stages.2.0.conv2_kxk.bn.bias\", \"stages.2.0.conv2_kxk.bn.running_mean\", \"stages.2.0.conv2_kxk.bn.running_var\", \"stages.2.0.conv3_1x1.conv.weight\", \"stages.2.0.conv3_1x1.bn.weight\", \"stages.2.0.conv3_1x1.bn.bias\", \"stages.2.0.conv3_1x1.bn.running_mean\", \"stages.2.0.conv3_1x1.bn.running_var\", \"stages.2.1.conv_kxk.conv.weight\", \"stages.2.1.conv_kxk.bn.weight\", \"stages.2.1.conv_kxk.bn.bias\", \"stages.2.1.conv_kxk.bn.running_mean\", \"stages.2.1.conv_kxk.bn.running_var\", \"stages.2.1.conv_1x1.weight\", \"stages.2.1.transformer.0.norm1.weight\", \"stages.2.1.transformer.0.norm1.bias\", \"stages.2.1.transformer.0.attn.qkv.weight\", \"stages.2.1.transformer.0.attn.qkv.bias\", \"stages.2.1.transformer.0.attn.proj.weight\", \"stages.2.1.transformer.0.attn.proj.bias\", \"stages.2.1.transformer.0.norm2.weight\", \"stages.2.1.transformer.0.norm2.bias\", \"stages.2.1.transformer.0.mlp.fc1.weight\", \"stages.2.1.transformer.0.mlp.fc1.bias\", \"stages.2.1.transformer.0.mlp.fc2.weight\", \"stages.2.1.transformer.0.mlp.fc2.bias\", \"stages.2.1.transformer.1.norm1.weight\", \"stages.2.1.transformer.1.norm1.bias\", \"stages.2.1.transformer.1.attn.qkv.weight\", \"stages.2.1.transformer.1.attn.qkv.bias\", \"stages.2.1.transformer.1.attn.proj.weight\", \"stages.2.1.transformer.1.attn.proj.bias\", \"stages.2.1.transformer.1.norm2.weight\", \"stages.2.1.transformer.1.norm2.bias\", \"stages.2.1.transformer.1.mlp.fc1.weight\", \"stages.2.1.transformer.1.mlp.fc1.bias\", \"stages.2.1.transformer.1.mlp.fc2.weight\", \"stages.2.1.transformer.1.mlp.fc2.bias\", \"stages.2.1.norm.weight\", \"stages.2.1.norm.bias\", \"stages.2.1.conv_proj.conv.weight\", \"stages.2.1.conv_proj.bn.weight\", \"stages.2.1.conv_proj.bn.bias\", \"stages.2.1.conv_proj.bn.running_mean\", \"stages.2.1.conv_proj.bn.running_var\", \"stages.2.1.conv_fusion.conv.weight\", \"stages.2.1.conv_fusion.bn.weight\", \"stages.2.1.conv_fusion.bn.bias\", \"stages.2.1.conv_fusion.bn.running_mean\", \"stages.2.1.conv_fusion.bn.running_var\", \"stages.3.0.conv1_1x1.conv.weight\", \"stages.3.0.conv1_1x1.bn.weight\", \"stages.3.0.conv1_1x1.bn.bias\", \"stages.3.0.conv1_1x1.bn.running_mean\", \"stages.3.0.conv1_1x1.bn.running_var\", \"stages.3.0.conv2_kxk.conv.weight\", \"stages.3.0.conv2_kxk.bn.weight\", \"stages.3.0.conv2_kxk.bn.bias\", \"stages.3.0.conv2_kxk.bn.running_mean\", \"stages.3.0.conv2_kxk.bn.running_var\", \"stages.3.0.conv3_1x1.conv.weight\", \"stages.3.0.conv3_1x1.bn.weight\", \"stages.3.0.conv3_1x1.bn.bias\", \"stages.3.0.conv3_1x1.bn.running_mean\", \"stages.3.0.conv3_1x1.bn.running_var\", \"stages.3.1.conv_kxk.conv.weight\", \"stages.3.1.conv_kxk.bn.weight\", \"stages.3.1.conv_kxk.bn.bias\", \"stages.3.1.conv_kxk.bn.running_mean\", \"stages.3.1.conv_kxk.bn.running_var\", \"stages.3.1.conv_1x1.weight\", \"stages.3.1.transformer.0.norm1.weight\", \"stages.3.1.transformer.0.norm1.bias\", \"stages.3.1.transformer.0.attn.qkv.weight\", \"stages.3.1.transformer.0.attn.qkv.bias\", \"stages.3.1.transformer.0.attn.proj.weight\", \"stages.3.1.transformer.0.attn.proj.bias\", \"stages.3.1.transformer.0.norm2.weight\", \"stages.3.1.transformer.0.norm2.bias\", \"stages.3.1.transformer.0.mlp.fc1.weight\", \"stages.3.1.transformer.0.mlp.fc1.bias\", \"stages.3.1.transformer.0.mlp.fc2.weight\", \"stages.3.1.transformer.0.mlp.fc2.bias\", \"stages.3.1.transformer.1.norm1.weight\", \"stages.3.1.transformer.1.norm1.bias\", \"stages.3.1.transformer.1.attn.qkv.weight\", \"stages.3.1.transformer.1.attn.qkv.bias\", \"stages.3.1.transformer.1.attn.proj.weight\", \"stages.3.1.transformer.1.attn.proj.bias\", \"stages.3.1.transformer.1.norm2.weight\", \"stages.3.1.transformer.1.norm2.bias\", \"stages.3.1.transformer.1.mlp.fc1.weight\", \"stages.3.1.transformer.1.mlp.fc1.bias\", \"stages.3.1.transformer.1.mlp.fc2.weight\", \"stages.3.1.transformer.1.mlp.fc2.bias\", \"stages.3.1.transformer.2.norm1.weight\", \"stages.3.1.transformer.2.norm1.bias\", \"stages.3.1.transformer.2.attn.qkv.weight\", \"stages.3.1.transformer.2.attn.qkv.bias\", \"stages.3.1.transformer.2.attn.proj.weight\", \"stages.3.1.transformer.2.attn.proj.bias\", \"stages.3.1.transformer.2.norm2.weight\", \"stages.3.1.transformer.2.norm2.bias\", \"stages.3.1.transformer.2.mlp.fc1.weight\", \"stages.3.1.transformer.2.mlp.fc1.bias\", \"stages.3.1.transformer.2.mlp.fc2.weight\", \"stages.3.1.transformer.2.mlp.fc2.bias\", \"stages.3.1.transformer.3.norm1.weight\", \"stages.3.1.transformer.3.norm1.bias\", \"stages.3.1.transformer.3.attn.qkv.weight\", \"stages.3.1.transformer.3.attn.qkv.bias\", \"stages.3.1.transformer.3.attn.proj.weight\", \"stages.3.1.transformer.3.attn.proj.bias\", \"stages.3.1.transformer.3.norm2.weight\", \"stages.3.1.transformer.3.norm2.bias\", \"stages.3.1.transformer.3.mlp.fc1.weight\", \"stages.3.1.transformer.3.mlp.fc1.bias\", \"stages.3.1.transformer.3.mlp.fc2.weight\", \"stages.3.1.transformer.3.mlp.fc2.bias\", \"stages.3.1.norm.weight\", \"stages.3.1.norm.bias\", \"stages.3.1.conv_proj.conv.weight\", \"stages.3.1.conv_proj.bn.weight\", \"stages.3.1.conv_proj.bn.bias\", \"stages.3.1.conv_proj.bn.running_mean\", \"stages.3.1.conv_proj.bn.running_var\", \"stages.3.1.conv_fusion.conv.weight\", \"stages.3.1.conv_fusion.bn.weight\", \"stages.3.1.conv_fusion.bn.bias\", \"stages.3.1.conv_fusion.bn.running_mean\", \"stages.3.1.conv_fusion.bn.running_var\", \"stages.4.0.conv1_1x1.conv.weight\", \"stages.4.0.conv1_1x1.bn.weight\", \"stages.4.0.conv1_1x1.bn.bias\", \"stages.4.0.conv1_1x1.bn.running_mean\", \"stages.4.0.conv1_1x1.bn.running_var\", \"stages.4.0.conv2_kxk.conv.weight\", \"stages.4.0.conv2_kxk.bn.weight\", \"stages.4.0.conv2_kxk.bn.bias\", \"stages.4.0.conv2_kxk.bn.running_mean\", \"stages.4.0.conv2_kxk.bn.running_var\", \"stages.4.0.conv3_1x1.conv.weight\", \"stages.4.0.conv3_1x1.bn.weight\", \"stages.4.0.conv3_1x1.bn.bias\", \"stages.4.0.conv3_1x1.bn.running_mean\", \"stages.4.0.conv3_1x1.bn.running_var\", \"stages.4.1.conv_kxk.conv.weight\", \"stages.4.1.conv_kxk.bn.weight\", \"stages.4.1.conv_kxk.bn.bias\", \"stages.4.1.conv_kxk.bn.running_mean\", \"stages.4.1.conv_kxk.bn.running_var\", \"stages.4.1.conv_1x1.weight\", \"stages.4.1.transformer.0.norm1.weight\", \"stages.4.1.transformer.0.norm1.bias\", \"stages.4.1.transformer.0.attn.qkv.weight\", \"stages.4.1.transformer.0.attn.qkv.bias\", \"stages.4.1.transformer.0.attn.proj.weight\", \"stages.4.1.transformer.0.attn.proj.bias\", \"stages.4.1.transformer.0.norm2.weight\", \"stages.4.1.transformer.0.norm2.bias\", \"stages.4.1.transformer.0.mlp.fc1.weight\", \"stages.4.1.transformer.0.mlp.fc1.bias\", \"stages.4.1.transformer.0.mlp.fc2.weight\", \"stages.4.1.transformer.0.mlp.fc2.bias\", \"stages.4.1.transformer.1.norm1.weight\", \"stages.4.1.transformer.1.norm1.bias\", \"stages.4.1.transformer.1.attn.qkv.weight\", \"stages.4.1.transformer.1.attn.qkv.bias\", \"stages.4.1.transformer.1.attn.proj.weight\", \"stages.4.1.transformer.1.attn.proj.bias\", \"stages.4.1.transformer.1.norm2.weight\", \"stages.4.1.transformer.1.norm2.bias\", \"stages.4.1.transformer.1.mlp.fc1.weight\", \"stages.4.1.transformer.1.mlp.fc1.bias\", \"stages.4.1.transformer.1.mlp.fc2.weight\", \"stages.4.1.transformer.1.mlp.fc2.bias\", \"stages.4.1.transformer.2.norm1.weight\", \"stages.4.1.transformer.2.norm1.bias\", \"stages.4.1.transformer.2.attn.qkv.weight\", \"stages.4.1.transformer.2.attn.qkv.bias\", \"stages.4.1.transformer.2.attn.proj.weight\", \"stages.4.1.transformer.2.attn.proj.bias\", \"stages.4.1.transformer.2.norm2.weight\", \"stages.4.1.transformer.2.norm2.bias\", \"stages.4.1.transformer.2.mlp.fc1.weight\", \"stages.4.1.transformer.2.mlp.fc1.bias\", \"stages.4.1.transformer.2.mlp.fc2.weight\", \"stages.4.1.transformer.2.mlp.fc2.bias\", \"stages.4.1.norm.weight\", \"stages.4.1.norm.bias\", \"stages.4.1.conv_proj.conv.weight\", \"stages.4.1.conv_proj.bn.weight\", \"stages.4.1.conv_proj.bn.bias\", \"stages.4.1.conv_proj.bn.running_mean\", \"stages.4.1.conv_proj.bn.running_var\", \"stages.4.1.conv_fusion.conv.weight\", \"stages.4.1.conv_fusion.bn.weight\", \"stages.4.1.conv_fusion.bn.bias\", \"stages.4.1.conv_fusion.bn.running_mean\", \"stages.4.1.conv_fusion.bn.running_var\", \"final_conv.conv.weight\", \"final_conv.bn.weight\", \"final_conv.bn.bias\", \"final_conv.bn.running_mean\", \"final_conv.bn.running_var\", \"head.fc.weight\", \"head.fc.bias\". \n\tUnexpected key(s) in state_dict: \"model.stem.conv.weight\", \"model.stem.bn.weight\", \"model.stem.bn.bias\", \"model.stem.bn.running_mean\", \"model.stem.bn.running_var\", \"model.stem.bn.num_batches_tracked\", \"model.stages.0.0.conv1_1x1.conv.weight\", \"model.stages.0.0.conv1_1x1.bn.weight\", \"model.stages.0.0.conv1_1x1.bn.bias\", \"model.stages.0.0.conv1_1x1.bn.running_mean\", \"model.stages.0.0.conv1_1x1.bn.running_var\", \"model.stages.0.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.0.0.conv2_kxk.conv.weight\", \"model.stages.0.0.conv2_kxk.bn.weight\", \"model.stages.0.0.conv2_kxk.bn.bias\", \"model.stages.0.0.conv2_kxk.bn.running_mean\", \"model.stages.0.0.conv2_kxk.bn.running_var\", \"model.stages.0.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.0.0.conv3_1x1.conv.weight\", \"model.stages.0.0.conv3_1x1.bn.weight\", \"model.stages.0.0.conv3_1x1.bn.bias\", \"model.stages.0.0.conv3_1x1.bn.running_mean\", \"model.stages.0.0.conv3_1x1.bn.running_var\", \"model.stages.0.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv1_1x1.conv.weight\", \"model.stages.1.0.conv1_1x1.bn.weight\", \"model.stages.1.0.conv1_1x1.bn.bias\", \"model.stages.1.0.conv1_1x1.bn.running_mean\", \"model.stages.1.0.conv1_1x1.bn.running_var\", \"model.stages.1.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv2_kxk.conv.weight\", \"model.stages.1.0.conv2_kxk.bn.weight\", \"model.stages.1.0.conv2_kxk.bn.bias\", \"model.stages.1.0.conv2_kxk.bn.running_mean\", \"model.stages.1.0.conv2_kxk.bn.running_var\", \"model.stages.1.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.1.0.conv3_1x1.conv.weight\", \"model.stages.1.0.conv3_1x1.bn.weight\", \"model.stages.1.0.conv3_1x1.bn.bias\", \"model.stages.1.0.conv3_1x1.bn.running_mean\", \"model.stages.1.0.conv3_1x1.bn.running_var\", \"model.stages.1.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.1.conv1_1x1.conv.weight\", \"model.stages.1.1.conv1_1x1.bn.weight\", \"model.stages.1.1.conv1_1x1.bn.bias\", \"model.stages.1.1.conv1_1x1.bn.running_mean\", \"model.stages.1.1.conv1_1x1.bn.running_var\", \"model.stages.1.1.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.1.conv2_kxk.conv.weight\", \"model.stages.1.1.conv2_kxk.bn.weight\", \"model.stages.1.1.conv2_kxk.bn.bias\", \"model.stages.1.1.conv2_kxk.bn.running_mean\", \"model.stages.1.1.conv2_kxk.bn.running_var\", \"model.stages.1.1.conv2_kxk.bn.num_batches_tracked\", \"model.stages.1.1.conv3_1x1.conv.weight\", \"model.stages.1.1.conv3_1x1.bn.weight\", \"model.stages.1.1.conv3_1x1.bn.bias\", \"model.stages.1.1.conv3_1x1.bn.running_mean\", \"model.stages.1.1.conv3_1x1.bn.running_var\", \"model.stages.1.1.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.2.conv1_1x1.conv.weight\", \"model.stages.1.2.conv1_1x1.bn.weight\", \"model.stages.1.2.conv1_1x1.bn.bias\", \"model.stages.1.2.conv1_1x1.bn.running_mean\", \"model.stages.1.2.conv1_1x1.bn.running_var\", \"model.stages.1.2.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.2.conv2_kxk.conv.weight\", \"model.stages.1.2.conv2_kxk.bn.weight\", \"model.stages.1.2.conv2_kxk.bn.bias\", \"model.stages.1.2.conv2_kxk.bn.running_mean\", \"model.stages.1.2.conv2_kxk.bn.running_var\", \"model.stages.1.2.conv2_kxk.bn.num_batches_tracked\", \"model.stages.1.2.conv3_1x1.conv.weight\", \"model.stages.1.2.conv3_1x1.bn.weight\", \"model.stages.1.2.conv3_1x1.bn.bias\", \"model.stages.1.2.conv3_1x1.bn.running_mean\", \"model.stages.1.2.conv3_1x1.bn.running_var\", \"model.stages.1.2.conv3_1x1.bn.num_batches_tracked\", \"model.stages.2.0.conv1_1x1.conv.weight\", \"model.stages.2.0.conv1_1x1.bn.weight\", \"model.stages.2.0.conv1_1x1.bn.bias\", \"model.stages.2.0.conv1_1x1.bn.running_mean\", \"model.stages.2.0.conv1_1x1.bn.running_var\", \"model.stages.2.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.2.0.conv2_kxk.conv.weight\", \"model.stages.2.0.conv2_kxk.bn.weight\", \"model.stages.2.0.conv2_kxk.bn.bias\", \"model.stages.2.0.conv2_kxk.bn.running_mean\", \"model.stages.2.0.conv2_kxk.bn.running_var\", \"model.stages.2.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.2.0.conv3_1x1.conv.weight\", \"model.stages.2.0.conv3_1x1.bn.weight\", \"model.stages.2.0.conv3_1x1.bn.bias\", \"model.stages.2.0.conv3_1x1.bn.running_mean\", \"model.stages.2.0.conv3_1x1.bn.running_var\", \"model.stages.2.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.2.1.conv_kxk.conv.weight\", \"model.stages.2.1.conv_kxk.bn.weight\", \"model.stages.2.1.conv_kxk.bn.bias\", \"model.stages.2.1.conv_kxk.bn.running_mean\", \"model.stages.2.1.conv_kxk.bn.running_var\", \"model.stages.2.1.conv_kxk.bn.num_batches_tracked\", \"model.stages.2.1.conv_1x1.weight\", \"model.stages.2.1.transformer.0.norm1.weight\", \"model.stages.2.1.transformer.0.norm1.bias\", \"model.stages.2.1.transformer.0.attn.qkv.weight\", \"model.stages.2.1.transformer.0.attn.qkv.bias\", \"model.stages.2.1.transformer.0.attn.proj.weight\", \"model.stages.2.1.transformer.0.attn.proj.bias\", \"model.stages.2.1.transformer.0.norm2.weight\", \"model.stages.2.1.transformer.0.norm2.bias\", \"model.stages.2.1.transformer.0.mlp.fc1.weight\", \"model.stages.2.1.transformer.0.mlp.fc1.bias\", \"model.stages.2.1.transformer.0.mlp.fc2.weight\", \"model.stages.2.1.transformer.0.mlp.fc2.bias\", \"model.stages.2.1.transformer.1.norm1.weight\", \"model.stages.2.1.transformer.1.norm1.bias\", \"model.stages.2.1.transformer.1.attn.qkv.weight\", \"model.stages.2.1.transformer.1.attn.qkv.bias\", \"model.stages.2.1.transformer.1.attn.proj.weight\", \"model.stages.2.1.transformer.1.attn.proj.bias\", \"model.stages.2.1.transformer.1.norm2.weight\", \"model.stages.2.1.transformer.1.norm2.bias\", \"model.stages.2.1.transformer.1.mlp.fc1.weight\", \"model.stages.2.1.transformer.1.mlp.fc1.bias\", \"model.stages.2.1.transformer.1.mlp.fc2.weight\", \"model.stages.2.1.transformer.1.mlp.fc2.bias\", \"model.stages.2.1.norm.weight\", \"model.stages.2.1.norm.bias\", \"model.stages.2.1.conv_proj.conv.weight\", \"model.stages.2.1.conv_proj.bn.weight\", \"model.stages.2.1.conv_proj.bn.bias\", \"model.stages.2.1.conv_proj.bn.running_mean\", \"model.stages.2.1.conv_proj.bn.running_var\", \"model.stages.2.1.conv_proj.bn.num_batches_tracked\", \"model.stages.2.1.conv_fusion.conv.weight\", \"model.stages.2.1.conv_fusion.bn.weight\", \"model.stages.2.1.conv_fusion.bn.bias\", \"model.stages.2.1.conv_fusion.bn.running_mean\", \"model.stages.2.1.conv_fusion.bn.running_var\", \"model.stages.2.1.conv_fusion.bn.num_batches_tracked\", \"model.stages.3.0.conv1_1x1.conv.weight\", \"model.stages.3.0.conv1_1x1.bn.weight\", \"model.stages.3.0.conv1_1x1.bn.bias\", \"model.stages.3.0.conv1_1x1.bn.running_mean\", \"model.stages.3.0.conv1_1x1.bn.running_var\", \"model.stages.3.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.3.0.conv2_kxk.conv.weight\", \"model.stages.3.0.conv2_kxk.bn.weight\", \"model.stages.3.0.conv2_kxk.bn.bias\", \"model.stages.3.0.conv2_kxk.bn.running_mean\", \"model.stages.3.0.conv2_kxk.bn.running_var\", \"model.stages.3.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.3.0.conv3_1x1.conv.weight\", \"model.stages.3.0.conv3_1x1.bn.weight\", \"model.stages.3.0.conv3_1x1.bn.bias\", \"model.stages.3.0.conv3_1x1.bn.running_mean\", \"model.stages.3.0.conv3_1x1.bn.running_var\", \"model.stages.3.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.3.1.conv_kxk.conv.weight\", \"model.stages.3.1.conv_kxk.bn.weight\", \"model.stages.3.1.conv_kxk.bn.bias\", \"model.stages.3.1.conv_kxk.bn.running_mean\", \"model.stages.3.1.conv_kxk.bn.running_var\", \"model.stages.3.1.conv_kxk.bn.num_batches_tracked\", \"model.stages.3.1.conv_1x1.weight\", \"model.stages.3.1.transformer.0.norm1.weight\", \"model.stages.3.1.transformer.0.norm1.bias\", \"model.stages.3.1.transformer.0.attn.qkv.weight\", \"model.stages.3.1.transformer.0.attn.qkv.bias\", \"model.stages.3.1.transformer.0.attn.proj.weight\", \"model.stages.3.1.transformer.0.attn.proj.bias\", \"model.stages.3.1.transformer.0.norm2.weight\", \"model.stages.3.1.transformer.0.norm2.bias\", \"model.stages.3.1.transformer.0.mlp.fc1.weight\", \"model.stages.3.1.transformer.0.mlp.fc1.bias\", \"model.stages.3.1.transformer.0.mlp.fc2.weight\", \"model.stages.3.1.transformer.0.mlp.fc2.bias\", \"model.stages.3.1.transformer.1.norm1.weight\", \"model.stages.3.1.transformer.1.norm1.bias\", \"model.stages.3.1.transformer.1.attn.qkv.weight\", \"model.stages.3.1.transformer.1.attn.qkv.bias\", \"model.stages.3.1.transformer.1.attn.proj.weight\", \"model.stages.3.1.transformer.1.attn.proj.bias\", \"model.stages.3.1.transformer.1.norm2.weight\", \"model.stages.3.1.transformer.1.norm2.bias\", \"model.stages.3.1.transformer.1.mlp.fc1.weight\", \"model.stages.3.1.transformer.1.mlp.fc1.bias\", \"model.stages.3.1.transformer.1.mlp.fc2.weight\", \"model.stages.3.1.transformer.1.mlp.fc2.bias\", \"model.stages.3.1.transformer.2.norm1.weight\", \"model.stages.3.1.transformer.2.norm1.bias\", \"model.stages.3.1.transformer.2.attn.qkv.weight\", \"model.stages.3.1.transformer.2.attn.qkv.bias\", \"model.stages.3.1.transformer.2.attn.proj.weight\", \"model.stages.3.1.transformer.2.attn.proj.bias\", \"model.stages.3.1.transformer.2.norm2.weight\", \"model.stages.3.1.transformer.2.norm2.bias\", \"model.stages.3.1.transformer.2.mlp.fc1.weight\", \"model.stages.3.1.transformer.2.mlp.fc1.bias\", \"model.stages.3.1.transformer.2.mlp.fc2.weight\", \"model.stages.3.1.transformer.2.mlp.fc2.bias\", \"model.stages.3.1.transformer.3.norm1.weight\", \"model.stages.3.1.transformer.3.norm1.bias\", \"model.stages.3.1.transformer.3.attn.qkv.weight\", \"model.stages.3.1.transformer.3.attn.qkv.bias\", \"model.stages.3.1.transformer.3.attn.proj.weight\", \"model.stages.3.1.transformer.3.attn.proj.bias\", \"model.stages.3.1.transformer.3.norm2.weight\", \"model.stages.3.1.transformer.3.norm2.bias\", \"model.stages.3.1.transformer.3.mlp.fc1.weight\", \"model.stages.3.1.transformer.3.mlp.fc1.bias\", \"model.stages.3.1.transformer.3.mlp.fc2.weight\", \"model.stages.3.1.transformer.3.mlp.fc2.bias\", \"model.stages.3.1.norm.weight\", \"model.stages.3.1.norm.bias\", \"model.stages.3.1.conv_proj.conv.weight\", \"model.stages.3.1.conv_proj.bn.weight\", \"model.stages.3.1.conv_proj.bn.bias\", \"model.stages.3.1.conv_proj.bn.running_mean\", \"model.stages.3.1.conv_proj.bn.running_var\", \"model.stages.3.1.conv_proj.bn.num_batches_tracked\", \"model.stages.3.1.conv_fusion.conv.weight\", \"model.stages.3.1.conv_fusion.bn.weight\", \"model.stages.3.1.conv_fusion.bn.bias\", \"model.stages.3.1.conv_fusion.bn.running_mean\", \"model.stages.3.1.conv_fusion.bn.running_var\", \"model.stages.3.1.conv_fusion.bn.num_batches_tracked\", \"model.stages.4.0.conv1_1x1.conv.weight\", \"model.stages.4.0.conv1_1x1.bn.weight\", \"model.stages.4.0.conv1_1x1.bn.bias\", \"model.stages.4.0.conv1_1x1.bn.running_mean\", \"model.stages.4.0.conv1_1x1.bn.running_var\", \"model.stages.4.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.4.0.conv2_kxk.conv.weight\", \"model.stages.4.0.conv2_kxk.bn.weight\", \"model.stages.4.0.conv2_kxk.bn.bias\", \"model.stages.4.0.conv2_kxk.bn.running_mean\", \"model.stages.4.0.conv2_kxk.bn.running_var\", \"model.stages.4.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.4.0.conv3_1x1.conv.weight\", \"model.stages.4.0.conv3_1x1.bn.weight\", \"model.stages.4.0.conv3_1x1.bn.bias\", \"model.stages.4.0.conv3_1x1.bn.running_mean\", \"model.stages.4.0.conv3_1x1.bn.running_var\", \"model.stages.4.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.4.1.conv_kxk.conv.weight\", \"model.stages.4.1.conv_kxk.bn.weight\", \"model.stages.4.1.conv_kxk.bn.bias\", \"model.stages.4.1.conv_kxk.bn.running_mean\", \"model.stages.4.1.conv_kxk.bn.running_var\", \"model.stages.4.1.conv_kxk.bn.num_batches_tracked\", \"model.stages.4.1.conv_1x1.weight\", \"model.stages.4.1.transformer.0.norm1.weight\", \"model.stages.4.1.transformer.0.norm1.bias\", \"model.stages.4.1.transformer.0.attn.qkv.weight\", \"model.stages.4.1.transformer.0.attn.qkv.bias\", \"model.stages.4.1.transformer.0.attn.proj.weight\", \"model.stages.4.1.transformer.0.attn.proj.bias\", \"model.stages.4.1.transformer.0.norm2.weight\", \"model.stages.4.1.transformer.0.norm2.bias\", \"model.stages.4.1.transformer.0.mlp.fc1.weight\", \"model.stages.4.1.transformer.0.mlp.fc1.bias\", \"model.stages.4.1.transformer.0.mlp.fc2.weight\", \"model.stages.4.1.transformer.0.mlp.fc2.bias\", \"model.stages.4.1.transformer.1.norm1.weight\", \"model.stages.4.1.transformer.1.norm1.bias\", \"model.stages.4.1.transformer.1.attn.qkv.weight\", \"model.stages.4.1.transformer.1.attn.qkv.bias\", \"model.stages.4.1.transformer.1.attn.proj.weight\", \"model.stages.4.1.transformer.1.attn.proj.bias\", \"model.stages.4.1.transformer.1.norm2.weight\", \"model.stages.4.1.transformer.1.norm2.bias\", \"model.stages.4.1.transformer.1.mlp.fc1.weight\", \"model.stages.4.1.transformer.1.mlp.fc1.bias\", \"model.stages.4.1.transformer.1.mlp.fc2.weight\", \"model.stages.4.1.transformer.1.mlp.fc2.bias\", \"model.stages.4.1.transformer.2.norm1.weight\", \"model.stages.4.1.transformer.2.norm1.bias\", \"model.stages.4.1.transformer.2.attn.qkv.weight\", \"model.stages.4.1.transformer.2.attn.qkv.bias\", \"model.stages.4.1.transformer.2.attn.proj.weight\", \"model.stages.4.1.transformer.2.attn.proj.bias\", \"model.stages.4.1.transformer.2.norm2.weight\", \"model.stages.4.1.transformer.2.norm2.bias\", \"model.stages.4.1.transformer.2.mlp.fc1.weight\", \"model.stages.4.1.transformer.2.mlp.fc1.bias\", \"model.stages.4.1.transformer.2.mlp.fc2.weight\", \"model.stages.4.1.transformer.2.mlp.fc2.bias\", \"model.stages.4.1.norm.weight\", \"model.stages.4.1.norm.bias\", \"model.stages.4.1.conv_proj.conv.weight\", \"model.stages.4.1.conv_proj.bn.weight\", \"model.stages.4.1.conv_proj.bn.bias\", \"model.stages.4.1.conv_proj.bn.running_mean\", \"model.stages.4.1.conv_proj.bn.running_var\", \"model.stages.4.1.conv_proj.bn.num_batches_tracked\", \"model.stages.4.1.conv_fusion.conv.weight\", \"model.stages.4.1.conv_fusion.bn.weight\", \"model.stages.4.1.conv_fusion.bn.bias\", \"model.stages.4.1.conv_fusion.bn.running_mean\", \"model.stages.4.1.conv_fusion.bn.running_var\", \"model.stages.4.1.conv_fusion.bn.num_batches_tracked\", \"model.final_conv.conv.weight\", \"model.final_conv.bn.weight\", \"model.final_conv.bn.bias\", \"model.final_conv.bn.running_mean\", \"model.final_conv.bn.running_var\", \"model.final_conv.bn.num_batches_tracked\", \"model.head.fc.weight\", \"model.head.fc.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2b26c40707d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the weights from the 'model_state_dict' key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ByobNet:\n\tMissing key(s) in state_dict: \"stem.conv.weight\", \"stem.bn.weight\", \"stem.bn.bias\", \"stem.bn.running_mean\", \"stem.bn.running_var\", \"stages.0.0.conv1_1x1.conv.weight\", \"stages.0.0.conv1_1x1.bn.weight\", \"stages.0.0.conv1_1x1.bn.bias\", \"stages.0.0.conv1_1x1.bn.running_mean\", \"stages.0.0.conv1_1x1.bn.running_var\", \"stages.0.0.conv2_kxk.conv.weight\", \"stages.0.0.conv2_kxk.bn.weight\", \"stages.0.0.conv2_kxk.bn.bias\", \"stages.0.0.conv2_kxk.bn.running_mean\", \"stages.0.0.conv2_kxk.bn.running_var\", \"stages.0.0.conv3_1x1.conv.weight\", \"stages.0.0.conv3_1x1.bn.weight\", \"stages.0.0.conv3_1x1.bn.bias\", \"stages.0.0.conv3_1x1.bn.running_mean\", \"stages.0.0.conv3_1x1.bn.running_var\", \"stages.1.0.conv1_1x1.conv.weight\", \"stages.1.0.conv1_1x1.bn.weight\", \"stages.1.0.conv1_1x1.bn.bias\", \"stages.1.0.conv1_1x1.bn.running_mean\", \"stages.1.0.conv1_1x1.bn.running_var\", \"stages.1.0.conv2_kxk.conv.weight\", \"stages.1.0.conv2_kxk.bn.weight\", \"stages.1.0.conv2_kxk.bn.bias\", \"stages.1.0.conv2_kxk.bn.running_mean\", \"stages.1.0.conv2_kxk.bn.running_var\", \"stages.1.0.conv3_1x1.conv.weight\", \"stages.1.0.conv3_1x1.bn.weight\", \"stages.1.0.conv3_1x1.bn.bias\", \"stages.1.0.conv3_1x1.bn.running_mean\", \"stages.1.0.conv3_1x1.bn.running_var\", \"stages.1.1.conv1_1x1.conv.weight\", \"stages.1.1.conv1_1x1.bn.weight\", \"stages.1.1.conv1_1x1.bn.bias\", \"stages.1.1.conv1_1x1.bn.running_mean\", \"stages.1.1.conv1_1x1.bn.running_var\", \"stages.1.1.conv2_kxk.conv.weight\", \"stages.1.1.conv2_kxk.bn.weight\", \"stages.1.1.conv2_kxk.bn.bia...\n\tUnexpected key(s) in state_dict: \"model.stem.conv.weight\", \"model.stem.bn.weight\", \"model.stem.bn.bias\", \"model.stem.bn.running_mean\", \"model.stem.bn.running_var\", \"model.stem.bn.num_batches_tracked\", \"model.stages.0.0.conv1_1x1.conv.weight\", \"model.stages.0.0.conv1_1x1.bn.weight\", \"model.stages.0.0.conv1_1x1.bn.bias\", \"model.stages.0.0.conv1_1x1.bn.running_mean\", \"model.stages.0.0.conv1_1x1.bn.running_var\", \"model.stages.0.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.0.0.conv2_kxk.conv.weight\", \"model.stages.0.0.conv2_kxk.bn.weight\", \"model.stages.0.0.conv2_kxk.bn.bias\", \"model.stages.0.0.conv2_kxk.bn.running_mean\", \"model.stages.0.0.conv2_kxk.bn.running_var\", \"model.stages.0.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.0.0.conv3_1x1.conv.weight\", \"model.stages.0.0.conv3_1x1.bn.weight\", \"model.stages.0.0.conv3_1x1.bn.bias\", \"model.stages.0.0.conv3_1x1.bn.running_mean\", \"model.stages.0.0.conv3_1x1.bn.running_var\", \"model.stages.0.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv1_1x1.conv.weight\", \"model.stages.1.0.conv1_1x1.bn.weight\", \"model.stages.1.0.conv1_1x1.bn.bias\", \"model.stages.1.0.conv1_1x1.bn.running_mean\", \"model.stages.1.0.conv1_1x1.bn.running_var\", \"model.stages.1.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv2_kxk.conv.weight\", \"model.stages.1.0.conv2_kxk.bn.weight\", \"model.stages.1.0.conv2_kxk.bn.bias\", \"model.stages.1.0.conv2_kxk.bn.running_mean\", \"model.stages.1.0.conv2_kxk.bn.running_var\", \"model.stages.1.0.conv2_kxk...."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from timm import create_model\n",
        "\n",
        "# Load the full checkpoint dictionary\n",
        "checkpoint = torch.load(f\"{artifact_dir}/final_vit_model.pth\")\n",
        "\n",
        "# Recreate the architecture\n",
        "model = create_model('mobilevit_xxs', pretrained=False, num_classes=7)\n",
        "\n",
        "# Load the weights from the 'model_state_dict' key\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"Checkpoint loaded successfully ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53d32c52",
      "metadata": {},
      "source": [
        "# Display Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "A2CpbXfYT8MJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2CpbXfYT8MJ",
        "outputId": "d041bb00-6f53-4e17-b8a6-da098df930ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ByobNet(\n",
            "  (stem): ConvNormAct(\n",
            "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNormAct2d(\n",
            "      16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "      (drop): Identity()\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (stages): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Identity()\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (shortcut): Identity()\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (shortcut): Identity()\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): MobileVitBlock(\n",
            "        (conv_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (transformer): Sequential(\n",
            "          (0): Block(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (1): Block(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (conv_proj): ConvNormAct(\n",
            "          (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_fusion): ConvNormAct(\n",
            "          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): MobileVitBlock(\n",
            "        (conv_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_1x1): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (transformer): Sequential(\n",
            "          (0): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (1): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (2): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (3): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "        (conv_proj): ConvNormAct(\n",
            "          (conv): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_fusion): ConvNormAct(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): MobileVitBlock(\n",
            "        (conv_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_1x1): Conv2d(80, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (transformer): Sequential(\n",
            "          (0): Block(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (1): Block(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (2): Block(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (conv_proj): ConvNormAct(\n",
            "          (conv): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_fusion): ConvNormAct(\n",
            "          (conv): Conv2d(160, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final_conv): ConvNormAct(\n",
            "    (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNormAct2d(\n",
            "      320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "      (drop): Identity()\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (head): ClassifierHead(\n",
            "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (fc): Linear(in_features=320, out_features=7, bias=True)\n",
            "    (flatten): Identity()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "nb1GA0r5UYi6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb1GA0r5UYi6",
        "outputId": "14d2a97d-06ad-4ba2-af30-64ba9dc3e8c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['model_state_dict', 'optimizer_state_dict', 'test_accuracy', 'config'])\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load(f\"{artifact_dir}/final_vit_model.pth\")\n",
        "print(checkpoint.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "avAaIsTAUhH2",
      "metadata": {
        "id": "avAaIsTAUhH2"
      },
      "outputs": [],
      "source": [
        "state_dict = checkpoint['model_state_dict']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Ph3SJWfUUmd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph3SJWfUUmd0",
        "outputId": "3ff245da-f5ed-4874-f173-40995425661b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.stem.conv.weight\n",
            "model.stem.bn.weight\n",
            "model.stem.bn.bias\n",
            "model.stem.bn.running_mean\n",
            "model.stem.bn.running_var\n",
            "model.stem.bn.num_batches_tracked\n",
            "model.stages.0.0.conv1_1x1.conv.weight\n",
            "model.stages.0.0.conv1_1x1.bn.weight\n",
            "model.stages.0.0.conv1_1x1.bn.bias\n",
            "model.stages.0.0.conv1_1x1.bn.running_mean\n"
          ]
        }
      ],
      "source": [
        "state_dict = checkpoint['model_state_dict']\n",
        "for key in list(state_dict.keys())[:10]:  # just first 10 keys to peek\n",
        "    print(key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "xY8vGQ_9Uqa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY8vGQ_9Uqa7",
        "outputId": "fa7de7cf-a911-4029-aa6b-d810173c4fc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# Fix the keys\n",
        "fixed_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    new_k = k.replace(\"model.\", \"\", 1)  # Remove only the first 'model.'\n",
        "    fixed_state_dict[new_k] = v\n",
        "\n",
        "# Load it\n",
        "model.load_state_dict(fixed_state_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fHigAC8ZU9sk",
      "metadata": {
        "id": "fHigAC8ZU9sk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "U95wBX9AV3I_",
      "metadata": {
        "id": "U95wBX9AV3I_"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "easUYH7VVZP_",
      "metadata": {
        "id": "easUYH7VVZP_"
      },
      "outputs": [],
      "source": [
        "test_dataset = TestDataset(test_df, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ZinWozsTVoOi",
      "metadata": {
        "id": "ZinWozsTVoOi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend(preds.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc6d7d3",
      "metadata": {},
      "source": [
        "# Generate Submissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "dJJRRulxX-F_",
      "metadata": {
        "id": "dJJRRulxX-F_"
      },
      "outputs": [],
      "source": [
        "submission_df = test_df.copy()\n",
        "submission_df['emotion'] = predictions  # or vit_preds or your own blend\n",
        "submission_df = submission_df[['emotion']]  # make sure the format matches what's required\n",
        "\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9d498a",
      "metadata": {},
      "source": [
        "ეს არის მოდელები, რაც არ გავუშვი იდეაში, მაგრამ არტიფაქტად შენახული გვაქვს. ამ კოდში ვხედავთ როგორ შეგვიძლია ნებისმიერი მოდელიდან არქიტექტურის ამოღება."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d21e3a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "def inspect_model_directory():\n",
        "    \"\"\"Inspect the downloaded models directory structure\"\"\"\n",
        "    print(\"Inspecting models directory...\")\n",
        "    \n",
        "    models_dir = Path(\"models\")\n",
        "    if not models_dir.exists():\n",
        "        print(\"Models directory doesn't exist!\")\n",
        "        return\n",
        "    \n",
        "    # List all files and subdirectories\n",
        "    for root, dirs, files in os.walk(models_dir):\n",
        "        level = root.replace(str(models_dir), '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        \n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
        "            print(f\"{subindent}{file} ({file_size:.2f} MB)\")\n",
        "\n",
        "def inspect_model_structure(model_path):\n",
        "    \"\"\"Inspect the structure of a saved PyTorch model\"\"\"\n",
        "    print(f\"\\nInspecting model: {model_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Load the model state dict\n",
        "        checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        \n",
        "        # Check if it's a full checkpoint or just state_dict\n",
        "        if isinstance(checkpoint, dict):\n",
        "            if 'model_state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['model_state_dict']\n",
        "                print(\"Found model_state_dict in checkpoint\")\n",
        "                if 'epoch' in checkpoint:\n",
        "                    print(f\"Epoch: {checkpoint['epoch']}\")\n",
        "                if 'best_acc' in checkpoint:\n",
        "                    print(f\"Best accuracy: {checkpoint['best_acc']}\")\n",
        "            elif 'state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict']\n",
        "                print(\"Found state_dict in checkpoint\")\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "                print(\"Checkpoint appears to be direct state_dict\")\n",
        "        else:\n",
        "            state_dict = checkpoint\n",
        "            print(\"Model appears to be direct state_dict\")\n",
        "        \n",
        "        print(f\"\\nModel layers ({len(state_dict)} total):\")\n",
        "        for i, (key, tensor) in enumerate(state_dict.items()):\n",
        "            if i < 20:  # Show first 20 layers\n",
        "                print(f\"  {key}: {tensor.shape}\")\n",
        "            elif i == 20:\n",
        "                print(f\"  ... and {len(state_dict) - 20} more layers\")\n",
        "                break\n",
        "        \n",
        "        return state_dict\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_and_inspect_wandb_models():\n",
        "    \"\"\"Download models from wandb and inspect their structure\"\"\"\n",
        "    \n",
        "    # Initialize wandb\n",
        "    wandb.login()\n",
        "    api = wandb.Api()\n",
        "    \n",
        "    # Model run information\n",
        "    models_info = [\n",
        "        {\"run_id\": \"30aso492\", \"version\": \"attention_cnn_v2\"},\n",
        "        {\"run_id\": \"j96barvg\", \"version\": \"attention_cnn_v3\"}, \n",
        "        {\"run_id\": \"940fei4e\", \"version\": \"attention_cnn_v4\"},\n",
        "        {\"run_id\": \"4a37ougz\", \"version\": \"attention_cnn_v1\"}\n",
        "    ]\n",
        "    \n",
        "    model_files = {}\n",
        "    \n",
        "    print(\"Downloading and inspecting CNN models...\")\n",
        "    for model_info in models_info:\n",
        "        try:\n",
        "            run = api.run(f\"ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/{model_info['run_id']}\")\n",
        "            \n",
        "            # Create directory\n",
        "            model_dir = f\"models/{model_info['version']}\"\n",
        "            os.makedirs(model_dir, exist_ok=True)\n",
        "            \n",
        "            # Download files\n",
        "            for file_name in ['best_attention_cnn.pth', 'final_attention_cnn.pth']:\n",
        "                try:\n",
        "                    file_path = run.file(file_name).download(root=model_dir, replace=True)\n",
        "                    full_path = os.path.join(model_dir, file_name)\n",
        "                    model_files[f\"{model_info['version']}_{file_name.replace('.pth', '')}\"] = full_path\n",
        "                    print(f\"Downloaded: {full_path}\")\n",
        "                    \n",
        "                    # Inspect the model structure\n",
        "                    inspect_model_structure(full_path)\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to download {file_name}: {e}\")\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print(f\"Failed to access run {model_info['run_id']}: {e}\")\n",
        "    \n",
        "    # Download ViT model\n",
        "    print(\"\\nDownloading and inspecting ViT model...\")\n",
        "    try:\n",
        "        artifact = api.artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/vit-fer2013-final-model:v0')\n",
        "        vit_dir = \"models/vit_model\"\n",
        "        os.makedirs(vit_dir, exist_ok=True)\n",
        "        artifact.download(root=vit_dir, replace=True)\n",
        "        \n",
        "        # Find all files in ViT directory\n",
        "        vit_files = glob.glob(f\"{vit_dir}/**/*\", recursive=True)\n",
        "        for file_path in vit_files:\n",
        "            if os.path.isfile(file_path):\n",
        "                print(f\"ViT file: {file_path}\")\n",
        "                if file_path.endswith('.pth') or file_path.endswith('.bin'):\n",
        "                    inspect_model_structure(file_path)\n",
        "                    \n",
        "        model_files[\"vit_model\"] = vit_dir\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download ViT model: {e}\")\n",
        "    \n",
        "    return model_files\n",
        "\n",
        "def load_model_from_checkpoint(model_path):\n",
        "    \"\"\"Load model from checkpoint without defining architecture first\"\"\"\n",
        "    print(f\"\\nLoading model from: {model_path}\")\n",
        "    \n",
        "    try:\n",
        "        checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        \n",
        "        # Extract state_dict\n",
        "        if isinstance(checkpoint, dict):\n",
        "            if 'model_state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['model_state_dict']\n",
        "            elif 'state_dict' in checkpoint:\n",
        "                state_dict = checkpoint['state_dict']\n",
        "            else:\n",
        "                state_dict = checkpoint\n",
        "        else:\n",
        "            state_dict = checkpoint\n",
        "        \n",
        "        # Try to infer model structure from state_dict keys\n",
        "        print(\"Model structure inferred from state_dict:\")\n",
        "        conv_blocks = []\n",
        "        att_blocks = []\n",
        "        fc_layers = []\n",
        "        \n",
        "        for key in state_dict.keys():\n",
        "            if key.startswith('conv'):\n",
        "                block_name = key.split('.')[0]\n",
        "                if block_name not in conv_blocks:\n",
        "                    conv_blocks.append(block_name)\n",
        "            elif key.startswith('att'):\n",
        "                block_name = key.split('.')[0]\n",
        "                if block_name not in att_blocks:\n",
        "                    att_blocks.append(block_name)\n",
        "            elif key.startswith('fc'):\n",
        "                fc_layers.append(key)\n",
        "        \n",
        "        print(f\"Conv blocks: {conv_blocks}\")\n",
        "        print(f\"Attention blocks: {att_blocks}\")\n",
        "        print(f\"FC layers: {fc_layers[:10]}...\")  # First 10 FC layer keys\n",
        "        \n",
        "        return state_dict, checkpoint\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error loading checkpoint: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def make_predictions_with_loaded_model(state_dict, test_data):\n",
        "    \"\"\"Make predictions using loaded state_dict (you'll need to reconstruct model)\"\"\"\n",
        "    # This is where you'd need to reconstruct the exact model architecture\n",
        "    # based on the state_dict structure we discovered above\n",
        "    print(\"To make predictions, you need to reconstruct the model architecture\")\n",
        "    print(\"based on the state_dict structure shown above.\")\n",
        "    \n",
        "    # Example of what you'd need to do:\n",
        "    # model = YourActualModelClass()\n",
        "    # model.load_state_dict(state_dict)\n",
        "    # model.eval()\n",
        "    # return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808595c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"Main inspection function\"\"\"\n",
        "print(\"=\"*60)\n",
        "print(\"WANDB MODEL INSPECTOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# First check if models directory already exists\n",
        "inspect_model_directory()\n",
        "\n",
        "# Download and inspect models\n",
        "model_files = download_and_inspect_wandb_models()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY OF DOWNLOADED MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for model_name, path in model_files.items():\n",
        "    print(f\"{model_name}: {path}\")\n",
        "    if path.endswith('.pth'):\n",
        "        state_dict, checkpoint = load_model_from_checkpoint(path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NEXT STEPS\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. Use the model structure information above to recreate your model classes\")\n",
        "print(\"2. Load the state_dict into your model\")\n",
        "print(\"3. Run predictions on your test set\")\n",
        "print(\"\\nExample:\")\n",
        "print(\"model = YourModelClass()\")\n",
        "print(\"model.load_state_dict(torch.load('path_to_model.pth'))\")\n",
        "print(\"model.eval()\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
