{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krOeI7KHUyH-",
        "outputId": "f098ae8c-6d70-4327-9e76-fd07f0ba877f"
      },
      "id": "krOeI7KHUyH-",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install wandb torch torchvision pandas numpy matplotlib seaborn\n",
        "\n",
        "# Set up Kaggle API\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3WEaEbYU1f-",
        "outputId": "d8143bdf-40c7-4bb2-936b-889eb798ec84"
      },
      "id": "s3WEaEbYU1f-",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3zP3UP6UU2Lw"
      },
      "id": "3zP3UP6UU2Lw",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG29BQNbU7fy",
        "outputId": "ea613c81-adaa-4496-a977-662c5ac23b99"
      },
      "id": "iG29BQNbU7fy",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 91% 259M/285M [00:00<00:00, 469MB/s]\n",
            "100% 285M/285M [00:00<00:00, 476MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "81d6750a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "81d6750a",
        "outputId": "d5181796-f107-4a83-9b4b-534f635709dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">good-sponge-3</strong> at: <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0</a><br> View project at: <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_182753-a73kggk0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_183201-1s6pzasm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/1s6pzasm' target=\"_blank\">earthy-thunder-149</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/1s6pzasm' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/1s6pzasm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Login to wandb\n",
        "wandb.login()\n",
        "\n",
        "# Init run\n",
        "run = wandb.init(project=\"facial-expression-recognition\")\n",
        "\n",
        "# Download artifacts\n",
        "cnn_artifact = run.use_artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/run-30aso492-history:v0')\n",
        "cnn_dir = cnn_artifact.download()\n",
        "\n",
        "vit_artifact = run.use_artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/vit-fer2013-final-model:v0')\n",
        "vit_dir = vit_artifact.download()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        image = np.array(pixels.split(), dtype='uint8')\n",
        "        image = image.reshape(48, 48, 1).astype('float32') / 255.0\n",
        "        image = np.repeat(image, 3, axis=-1)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "J9ICah_VXTgU"
      },
      "id": "J9ICah_VXTgU",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),  # for ViT — you can skip or change for CNN\n",
        "])\n",
        "\n",
        "test_dataset = TestDataset(test_df, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "1CeV8-NYXW5Y"
      },
      "id": "1CeV8-NYXW5Y",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79768b6b",
      "metadata": {
        "id": "79768b6b"
      },
      "outputs": [],
      "source": [
        "# Load your models (adjust based on how you saved them)\n",
        "cnn_model = torch.load(f\"{cnn_dir}/model.pth\")  # or however you saved it\n",
        "vit_model = torch.load(f\"{vit_dir}/model.pth\")\n",
        "\n",
        "# Set to evaluation mode\n",
        "cnn_model.eval()\n",
        "vit_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9d9050",
      "metadata": {
        "id": "7b9d9050"
      },
      "outputs": [],
      "source": [
        "def ensemble_predict(cnn_model, vit_model, x, weights=[0.5, 0.5]):\n",
        "    \"\"\"\n",
        "    Ensemble prediction combining CNN and ViT models\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        # Get predictions from both models\n",
        "        cnn_pred = torch.softmax(cnn_model(x), dim=1)\n",
        "        vit_pred = torch.softmax(vit_model(x), dim=1)\n",
        "\n",
        "        # Weighted average\n",
        "        ensemble_pred = weights[0] * cnn_pred + weights[1] * vit_pred\n",
        "\n",
        "    return ensemble_pred, cnn_pred, vit_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c8627e",
      "metadata": {
        "id": "f4c8627e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def find_optimal_weights(cnn_preds, vit_preds, true_labels):\n",
        "    \"\"\"Find optimal weights for ensemble\"\"\"\n",
        "    best_acc = 0\n",
        "    best_weights = [0.5, 0.5]\n",
        "\n",
        "    for w1 in np.arange(0.1, 1.0, 0.1):\n",
        "        w2 = 1 - w1\n",
        "        ensemble_pred = w1 * cnn_preds + w2 * vit_preds\n",
        "        pred_labels = torch.argmax(ensemble_pred, dim=1)\n",
        "        acc = accuracy_score(true_labels, pred_labels)\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_weights = [w1, w2]\n",
        "\n",
        "    return best_weights, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ca60f690",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "ca60f690",
        "outputId": "55b77101-1c7d-4cb7-e827-ed120c506930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading models from W&B...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellekvirikashvili\u001b[0m (\u001b[33mellekvirikashvili-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_181208-upuee3mo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/upuee3mo' target=\"_blank\">icy-butterfly-148</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/upuee3mo' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/upuee3mo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CNN model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ViT model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models on cpu...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/artifacts/run-30aso492-history:v0/model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-257b97ec77c8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-257b97ec77c8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mvit_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{vit_dir}/model.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvit_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Assuming you have your dataloaders ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-257b97ec77c8>\u001b[0m in \u001b[0;36mload_models\u001b[0;34m(self, cnn_path, vit_path, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Load CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/artifacts/run-30aso492-history:v0/model.pth'"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class FERensemble:\n",
        "    def __init__(self, project_name=\"facial-expression-recognition\"):\n",
        "        self.project_name = project_name\n",
        "        self.cnn_model = None\n",
        "        self.vit_model = None\n",
        "        self.weights = [0.5, 0.5]  # Default equal weights\n",
        "\n",
        "    def download_models(self):\n",
        "        \"\"\"Download both models from W&B\"\"\"\n",
        "        print(\"Downloading models from W&B...\")\n",
        "\n",
        "        # Initialize wandb\n",
        "        run = wandb.init(project=self.project_name)\n",
        "\n",
        "        # Download CNN model\n",
        "        print(\"Downloading CNN model...\")\n",
        "        cnn_artifact = run.use_artifact(\n",
        "            'ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/run-30aso492-history:v0'\n",
        "        )\n",
        "        cnn_dir = cnn_artifact.download()\n",
        "\n",
        "        # Download ViT model\n",
        "        print(\"Downloading ViT model...\")\n",
        "        vit_artifact = run.use_artifact(\n",
        "            'ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/vit-fer2013-final-model:v0',\n",
        "            type='model'\n",
        "        )\n",
        "        vit_dir = vit_artifact.download()\n",
        "\n",
        "        return cnn_dir, vit_dir\n",
        "\n",
        "    def load_models(self, cnn_path, vit_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        \"\"\"Load the downloaded models\"\"\"\n",
        "        print(f\"Loading models on {device}...\")\n",
        "\n",
        "        # Load CNN model\n",
        "        self.cnn_model = torch.load(cnn_path, map_location=device)\n",
        "        self.cnn_model.eval()\n",
        "\n",
        "        # Load ViT model\n",
        "        self.vit_model = torch.load(vit_path, map_location=device)\n",
        "        self.vit_model.eval()\n",
        "\n",
        "        print(\"Models loaded successfully!\")\n",
        "\n",
        "    def predict_single(self, x, return_individual=False):\n",
        "        \"\"\"Make prediction on a single batch\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Get predictions from both models\n",
        "            cnn_logits = self.cnn_model(x)\n",
        "            vit_logits = self.vit_model(x)\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            cnn_probs = F.softmax(cnn_logits, dim=1)\n",
        "            vit_probs = F.softmax(vit_logits, dim=1)\n",
        "\n",
        "            # Ensemble prediction (weighted average)\n",
        "            ensemble_probs = self.weights[0] * cnn_probs + self.weights[1] * vit_probs\n",
        "\n",
        "            if return_individual:\n",
        "                return ensemble_probs, cnn_probs, vit_probs\n",
        "            return ensemble_probs\n",
        "\n",
        "    def evaluate_on_dataset(self, dataloader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        \"\"\"Evaluate ensemble on a dataset\"\"\"\n",
        "        all_ensemble_preds = []\n",
        "        all_cnn_preds = []\n",
        "        all_vit_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        print(\"Evaluating on dataset...\")\n",
        "\n",
        "        for batch_idx, (data, labels) in enumerate(dataloader):\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            ensemble_probs, cnn_probs, vit_probs = self.predict_single(data, return_individual=True)\n",
        "\n",
        "            # Store predictions\n",
        "            all_ensemble_preds.append(ensemble_probs.cpu())\n",
        "            all_cnn_preds.append(cnn_probs.cpu())\n",
        "            all_vit_preds.append(vit_probs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"Processed {batch_idx} batches...\")\n",
        "\n",
        "        # Concatenate all predictions\n",
        "        all_ensemble_preds = torch.cat(all_ensemble_preds, dim=0)\n",
        "        all_cnn_preds = torch.cat(all_cnn_preds, dim=0)\n",
        "        all_vit_preds = torch.cat(all_vit_preds, dim=0)\n",
        "        all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "        return all_ensemble_preds, all_cnn_preds, all_vit_preds, all_labels\n",
        "\n",
        "    def optimize_weights(self, val_dataloader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        \"\"\"Find optimal ensemble weights using validation set\"\"\"\n",
        "        print(\"Finding optimal ensemble weights...\")\n",
        "\n",
        "        # Get predictions on validation set\n",
        "        _, cnn_preds, vit_preds, true_labels = self.evaluate_on_dataset(val_dataloader, device)\n",
        "\n",
        "        best_acc = 0\n",
        "        best_weights = [0.5, 0.5]\n",
        "\n",
        "        # Grid search for optimal weights\n",
        "        for w1 in np.arange(0.1, 1.0, 0.1):\n",
        "            w2 = 1 - w1\n",
        "\n",
        "            # Calculate ensemble predictions with these weights\n",
        "            ensemble_pred = w1 * cnn_preds + w2 * vit_preds\n",
        "            pred_labels = torch.argmax(ensemble_pred, dim=1)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            acc = accuracy_score(true_labels.numpy(), pred_labels.numpy())\n",
        "\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_weights = [w1, w2]\n",
        "\n",
        "        self.weights = best_weights\n",
        "        print(f\"Optimal weights found: CNN={best_weights[0]:.2f}, ViT={best_weights[1]:.2f}\")\n",
        "        print(f\"Best validation accuracy: {best_acc:.4f}\")\n",
        "\n",
        "        return best_weights, best_acc\n",
        "\n",
        "    def get_metrics(self, predictions, true_labels, class_names=None):\n",
        "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "        pred_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "        # Basic accuracy\n",
        "        accuracy = accuracy_score(true_labels.numpy(), pred_labels.numpy())\n",
        "\n",
        "        # Classification report\n",
        "        if class_names is None:\n",
        "            class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "        report = classification_report(\n",
        "            true_labels.numpy(),\n",
        "            pred_labels.numpy(),\n",
        "            target_names=class_names,\n",
        "            output_dict=True\n",
        "        )\n",
        "\n",
        "        return accuracy, report\n",
        "\n",
        "    def compare_models(self, test_dataloader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        \"\"\"Compare individual models vs ensemble\"\"\"\n",
        "        print(\"Comparing model performances...\")\n",
        "\n",
        "        ensemble_preds, cnn_preds, vit_preds, true_labels = self.evaluate_on_dataset(test_dataloader, device)\n",
        "\n",
        "        # Calculate accuracies\n",
        "        ensemble_acc, ensemble_report = self.get_metrics(ensemble_preds, true_labels)\n",
        "        cnn_acc, cnn_report = self.get_metrics(cnn_preds, true_labels)\n",
        "        vit_acc, vit_report = self.get_metrics(vit_preds, true_labels)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"MODEL COMPARISON RESULTS\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"CNN Accuracy:      {cnn_acc:.4f}\")\n",
        "        print(f\"ViT Accuracy:      {vit_acc:.4f}\")\n",
        "        print(f\"Ensemble Accuracy: {ensemble_acc:.4f}\")\n",
        "        print(f\"Improvement:       {ensemble_acc - max(cnn_acc, vit_acc):.4f}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Log to W&B\n",
        "        wandb.log({\n",
        "            \"cnn_accuracy\": cnn_acc,\n",
        "            \"vit_accuracy\": vit_acc,\n",
        "            \"ensemble_accuracy\": ensemble_acc,\n",
        "            \"ensemble_improvement\": ensemble_acc - max(cnn_acc, vit_acc),\n",
        "            \"optimal_cnn_weight\": self.weights[0],\n",
        "            \"optimal_vit_weight\": self.weights[1]\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'ensemble': {'accuracy': ensemble_acc, 'report': ensemble_report},\n",
        "            'cnn': {'accuracy': cnn_acc, 'report': cnn_report},\n",
        "            'vit': {'accuracy': vit_acc, 'report': vit_report}\n",
        "        }\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Initialize ensemble\n",
        "    ensemble = FERensemble()\n",
        "\n",
        "    # Download models\n",
        "    cnn_dir, vit_dir = ensemble.download_models()\n",
        "\n",
        "    # Load models (adjust paths based on your saved model structure)\n",
        "    cnn_model_path = f\"{cnn_dir}/model.pth\"  # or wherever your .pth file is\n",
        "    vit_model_path = f\"{vit_dir}/model.pth\"\n",
        "\n",
        "    ensemble.load_models(cnn_model_path, vit_model_path)\n",
        "\n",
        "    # Assuming you have your dataloaders ready\n",
        "    # val_dataloader = your_validation_dataloader\n",
        "    # test_dataloader = your_test_dataloader\n",
        "\n",
        "    # Optimize ensemble weights on validation set\n",
        "    # ensemble.optimize_weights(val_dataloader)\n",
        "\n",
        "    # Compare models on test set\n",
        "    # results = ensemble.compare_models(test_dataloader)\n",
        "\n",
        "    print(\"Ensemble setup complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/vit-fer2013-final-model:v0', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "8HGEVoEXTNoa",
        "outputId": "32d30daa-2803-41ec-a028-0700d3ea27ab"
      },
      "id": "8HGEVoEXTNoa",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellekvirikashvili\u001b[0m (\u001b[33mellekvirikashvili-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_182753-a73kggk0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0' target=\"_blank\">good-sponge-3</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/uncategorized/runs/a73kggk0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from timm import create_model\n",
        "\n",
        "# Load the full checkpoint dictionary\n",
        "checkpoint = torch.load(f\"{artifact_dir}/final_vit_model.pth\")\n",
        "\n",
        "# Recreate the architecture\n",
        "model = create_model('mobilevit_xxs', pretrained=False, num_classes=7)\n",
        "\n",
        "# Load the weights from the 'model_state_dict' key\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"Checkpoint loaded successfully ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "1I_pWQFvTamt",
        "outputId": "736a1cb8-f54e-40f3-92f7-eede2cba7cd3"
      },
      "id": "1I_pWQFvTamt",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ByobNet:\n\tMissing key(s) in state_dict: \"stem.conv.weight\", \"stem.bn.weight\", \"stem.bn.bias\", \"stem.bn.running_mean\", \"stem.bn.running_var\", \"stages.0.0.conv1_1x1.conv.weight\", \"stages.0.0.conv1_1x1.bn.weight\", \"stages.0.0.conv1_1x1.bn.bias\", \"stages.0.0.conv1_1x1.bn.running_mean\", \"stages.0.0.conv1_1x1.bn.running_var\", \"stages.0.0.conv2_kxk.conv.weight\", \"stages.0.0.conv2_kxk.bn.weight\", \"stages.0.0.conv2_kxk.bn.bias\", \"stages.0.0.conv2_kxk.bn.running_mean\", \"stages.0.0.conv2_kxk.bn.running_var\", \"stages.0.0.conv3_1x1.conv.weight\", \"stages.0.0.conv3_1x1.bn.weight\", \"stages.0.0.conv3_1x1.bn.bias\", \"stages.0.0.conv3_1x1.bn.running_mean\", \"stages.0.0.conv3_1x1.bn.running_var\", \"stages.1.0.conv1_1x1.conv.weight\", \"stages.1.0.conv1_1x1.bn.weight\", \"stages.1.0.conv1_1x1.bn.bias\", \"stages.1.0.conv1_1x1.bn.running_mean\", \"stages.1.0.conv1_1x1.bn.running_var\", \"stages.1.0.conv2_kxk.conv.weight\", \"stages.1.0.conv2_kxk.bn.weight\", \"stages.1.0.conv2_kxk.bn.bias\", \"stages.1.0.conv2_kxk.bn.running_mean\", \"stages.1.0.conv2_kxk.bn.running_var\", \"stages.1.0.conv3_1x1.conv.weight\", \"stages.1.0.conv3_1x1.bn.weight\", \"stages.1.0.conv3_1x1.bn.bias\", \"stages.1.0.conv3_1x1.bn.running_mean\", \"stages.1.0.conv3_1x1.bn.running_var\", \"stages.1.1.conv1_1x1.conv.weight\", \"stages.1.1.conv1_1x1.bn.weight\", \"stages.1.1.conv1_1x1.bn.bias\", \"stages.1.1.conv1_1x1.bn.running_mean\", \"stages.1.1.conv1_1x1.bn.running_var\", \"stages.1.1.conv2_kxk.conv.weight\", \"stages.1.1.conv2_kxk.bn.weight\", \"stages.1.1.conv2_kxk.bn.bias\", \"stages.1.1.conv2_kxk.bn.running_mean\", \"stages.1.1.conv2_kxk.bn.running_var\", \"stages.1.1.conv3_1x1.conv.weight\", \"stages.1.1.conv3_1x1.bn.weight\", \"stages.1.1.conv3_1x1.bn.bias\", \"stages.1.1.conv3_1x1.bn.running_mean\", \"stages.1.1.conv3_1x1.bn.running_var\", \"stages.1.2.conv1_1x1.conv.weight\", \"stages.1.2.conv1_1x1.bn.weight\", \"stages.1.2.conv1_1x1.bn.bias\", \"stages.1.2.conv1_1x1.bn.running_mean\", \"stages.1.2.conv1_1x1.bn.running_var\", \"stages.1.2.conv2_kxk.conv.weight\", \"stages.1.2.conv2_kxk.bn.weight\", \"stages.1.2.conv2_kxk.bn.bias\", \"stages.1.2.conv2_kxk.bn.running_mean\", \"stages.1.2.conv2_kxk.bn.running_var\", \"stages.1.2.conv3_1x1.conv.weight\", \"stages.1.2.conv3_1x1.bn.weight\", \"stages.1.2.conv3_1x1.bn.bias\", \"stages.1.2.conv3_1x1.bn.running_mean\", \"stages.1.2.conv3_1x1.bn.running_var\", \"stages.2.0.conv1_1x1.conv.weight\", \"stages.2.0.conv1_1x1.bn.weight\", \"stages.2.0.conv1_1x1.bn.bias\", \"stages.2.0.conv1_1x1.bn.running_mean\", \"stages.2.0.conv1_1x1.bn.running_var\", \"stages.2.0.conv2_kxk.conv.weight\", \"stages.2.0.conv2_kxk.bn.weight\", \"stages.2.0.conv2_kxk.bn.bias\", \"stages.2.0.conv2_kxk.bn.running_mean\", \"stages.2.0.conv2_kxk.bn.running_var\", \"stages.2.0.conv3_1x1.conv.weight\", \"stages.2.0.conv3_1x1.bn.weight\", \"stages.2.0.conv3_1x1.bn.bias\", \"stages.2.0.conv3_1x1.bn.running_mean\", \"stages.2.0.conv3_1x1.bn.running_var\", \"stages.2.1.conv_kxk.conv.weight\", \"stages.2.1.conv_kxk.bn.weight\", \"stages.2.1.conv_kxk.bn.bias\", \"stages.2.1.conv_kxk.bn.running_mean\", \"stages.2.1.conv_kxk.bn.running_var\", \"stages.2.1.conv_1x1.weight\", \"stages.2.1.transformer.0.norm1.weight\", \"stages.2.1.transformer.0.norm1.bias\", \"stages.2.1.transformer.0.attn.qkv.weight\", \"stages.2.1.transformer.0.attn.qkv.bias\", \"stages.2.1.transformer.0.attn.proj.weight\", \"stages.2.1.transformer.0.attn.proj.bias\", \"stages.2.1.transformer.0.norm2.weight\", \"stages.2.1.transformer.0.norm2.bias\", \"stages.2.1.transformer.0.mlp.fc1.weight\", \"stages.2.1.transformer.0.mlp.fc1.bias\", \"stages.2.1.transformer.0.mlp.fc2.weight\", \"stages.2.1.transformer.0.mlp.fc2.bias\", \"stages.2.1.transformer.1.norm1.weight\", \"stages.2.1.transformer.1.norm1.bias\", \"stages.2.1.transformer.1.attn.qkv.weight\", \"stages.2.1.transformer.1.attn.qkv.bias\", \"stages.2.1.transformer.1.attn.proj.weight\", \"stages.2.1.transformer.1.attn.proj.bias\", \"stages.2.1.transformer.1.norm2.weight\", \"stages.2.1.transformer.1.norm2.bias\", \"stages.2.1.transformer.1.mlp.fc1.weight\", \"stages.2.1.transformer.1.mlp.fc1.bias\", \"stages.2.1.transformer.1.mlp.fc2.weight\", \"stages.2.1.transformer.1.mlp.fc2.bias\", \"stages.2.1.norm.weight\", \"stages.2.1.norm.bias\", \"stages.2.1.conv_proj.conv.weight\", \"stages.2.1.conv_proj.bn.weight\", \"stages.2.1.conv_proj.bn.bias\", \"stages.2.1.conv_proj.bn.running_mean\", \"stages.2.1.conv_proj.bn.running_var\", \"stages.2.1.conv_fusion.conv.weight\", \"stages.2.1.conv_fusion.bn.weight\", \"stages.2.1.conv_fusion.bn.bias\", \"stages.2.1.conv_fusion.bn.running_mean\", \"stages.2.1.conv_fusion.bn.running_var\", \"stages.3.0.conv1_1x1.conv.weight\", \"stages.3.0.conv1_1x1.bn.weight\", \"stages.3.0.conv1_1x1.bn.bias\", \"stages.3.0.conv1_1x1.bn.running_mean\", \"stages.3.0.conv1_1x1.bn.running_var\", \"stages.3.0.conv2_kxk.conv.weight\", \"stages.3.0.conv2_kxk.bn.weight\", \"stages.3.0.conv2_kxk.bn.bias\", \"stages.3.0.conv2_kxk.bn.running_mean\", \"stages.3.0.conv2_kxk.bn.running_var\", \"stages.3.0.conv3_1x1.conv.weight\", \"stages.3.0.conv3_1x1.bn.weight\", \"stages.3.0.conv3_1x1.bn.bias\", \"stages.3.0.conv3_1x1.bn.running_mean\", \"stages.3.0.conv3_1x1.bn.running_var\", \"stages.3.1.conv_kxk.conv.weight\", \"stages.3.1.conv_kxk.bn.weight\", \"stages.3.1.conv_kxk.bn.bias\", \"stages.3.1.conv_kxk.bn.running_mean\", \"stages.3.1.conv_kxk.bn.running_var\", \"stages.3.1.conv_1x1.weight\", \"stages.3.1.transformer.0.norm1.weight\", \"stages.3.1.transformer.0.norm1.bias\", \"stages.3.1.transformer.0.attn.qkv.weight\", \"stages.3.1.transformer.0.attn.qkv.bias\", \"stages.3.1.transformer.0.attn.proj.weight\", \"stages.3.1.transformer.0.attn.proj.bias\", \"stages.3.1.transformer.0.norm2.weight\", \"stages.3.1.transformer.0.norm2.bias\", \"stages.3.1.transformer.0.mlp.fc1.weight\", \"stages.3.1.transformer.0.mlp.fc1.bias\", \"stages.3.1.transformer.0.mlp.fc2.weight\", \"stages.3.1.transformer.0.mlp.fc2.bias\", \"stages.3.1.transformer.1.norm1.weight\", \"stages.3.1.transformer.1.norm1.bias\", \"stages.3.1.transformer.1.attn.qkv.weight\", \"stages.3.1.transformer.1.attn.qkv.bias\", \"stages.3.1.transformer.1.attn.proj.weight\", \"stages.3.1.transformer.1.attn.proj.bias\", \"stages.3.1.transformer.1.norm2.weight\", \"stages.3.1.transformer.1.norm2.bias\", \"stages.3.1.transformer.1.mlp.fc1.weight\", \"stages.3.1.transformer.1.mlp.fc1.bias\", \"stages.3.1.transformer.1.mlp.fc2.weight\", \"stages.3.1.transformer.1.mlp.fc2.bias\", \"stages.3.1.transformer.2.norm1.weight\", \"stages.3.1.transformer.2.norm1.bias\", \"stages.3.1.transformer.2.attn.qkv.weight\", \"stages.3.1.transformer.2.attn.qkv.bias\", \"stages.3.1.transformer.2.attn.proj.weight\", \"stages.3.1.transformer.2.attn.proj.bias\", \"stages.3.1.transformer.2.norm2.weight\", \"stages.3.1.transformer.2.norm2.bias\", \"stages.3.1.transformer.2.mlp.fc1.weight\", \"stages.3.1.transformer.2.mlp.fc1.bias\", \"stages.3.1.transformer.2.mlp.fc2.weight\", \"stages.3.1.transformer.2.mlp.fc2.bias\", \"stages.3.1.transformer.3.norm1.weight\", \"stages.3.1.transformer.3.norm1.bias\", \"stages.3.1.transformer.3.attn.qkv.weight\", \"stages.3.1.transformer.3.attn.qkv.bias\", \"stages.3.1.transformer.3.attn.proj.weight\", \"stages.3.1.transformer.3.attn.proj.bias\", \"stages.3.1.transformer.3.norm2.weight\", \"stages.3.1.transformer.3.norm2.bias\", \"stages.3.1.transformer.3.mlp.fc1.weight\", \"stages.3.1.transformer.3.mlp.fc1.bias\", \"stages.3.1.transformer.3.mlp.fc2.weight\", \"stages.3.1.transformer.3.mlp.fc2.bias\", \"stages.3.1.norm.weight\", \"stages.3.1.norm.bias\", \"stages.3.1.conv_proj.conv.weight\", \"stages.3.1.conv_proj.bn.weight\", \"stages.3.1.conv_proj.bn.bias\", \"stages.3.1.conv_proj.bn.running_mean\", \"stages.3.1.conv_proj.bn.running_var\", \"stages.3.1.conv_fusion.conv.weight\", \"stages.3.1.conv_fusion.bn.weight\", \"stages.3.1.conv_fusion.bn.bias\", \"stages.3.1.conv_fusion.bn.running_mean\", \"stages.3.1.conv_fusion.bn.running_var\", \"stages.4.0.conv1_1x1.conv.weight\", \"stages.4.0.conv1_1x1.bn.weight\", \"stages.4.0.conv1_1x1.bn.bias\", \"stages.4.0.conv1_1x1.bn.running_mean\", \"stages.4.0.conv1_1x1.bn.running_var\", \"stages.4.0.conv2_kxk.conv.weight\", \"stages.4.0.conv2_kxk.bn.weight\", \"stages.4.0.conv2_kxk.bn.bias\", \"stages.4.0.conv2_kxk.bn.running_mean\", \"stages.4.0.conv2_kxk.bn.running_var\", \"stages.4.0.conv3_1x1.conv.weight\", \"stages.4.0.conv3_1x1.bn.weight\", \"stages.4.0.conv3_1x1.bn.bias\", \"stages.4.0.conv3_1x1.bn.running_mean\", \"stages.4.0.conv3_1x1.bn.running_var\", \"stages.4.1.conv_kxk.conv.weight\", \"stages.4.1.conv_kxk.bn.weight\", \"stages.4.1.conv_kxk.bn.bias\", \"stages.4.1.conv_kxk.bn.running_mean\", \"stages.4.1.conv_kxk.bn.running_var\", \"stages.4.1.conv_1x1.weight\", \"stages.4.1.transformer.0.norm1.weight\", \"stages.4.1.transformer.0.norm1.bias\", \"stages.4.1.transformer.0.attn.qkv.weight\", \"stages.4.1.transformer.0.attn.qkv.bias\", \"stages.4.1.transformer.0.attn.proj.weight\", \"stages.4.1.transformer.0.attn.proj.bias\", \"stages.4.1.transformer.0.norm2.weight\", \"stages.4.1.transformer.0.norm2.bias\", \"stages.4.1.transformer.0.mlp.fc1.weight\", \"stages.4.1.transformer.0.mlp.fc1.bias\", \"stages.4.1.transformer.0.mlp.fc2.weight\", \"stages.4.1.transformer.0.mlp.fc2.bias\", \"stages.4.1.transformer.1.norm1.weight\", \"stages.4.1.transformer.1.norm1.bias\", \"stages.4.1.transformer.1.attn.qkv.weight\", \"stages.4.1.transformer.1.attn.qkv.bias\", \"stages.4.1.transformer.1.attn.proj.weight\", \"stages.4.1.transformer.1.attn.proj.bias\", \"stages.4.1.transformer.1.norm2.weight\", \"stages.4.1.transformer.1.norm2.bias\", \"stages.4.1.transformer.1.mlp.fc1.weight\", \"stages.4.1.transformer.1.mlp.fc1.bias\", \"stages.4.1.transformer.1.mlp.fc2.weight\", \"stages.4.1.transformer.1.mlp.fc2.bias\", \"stages.4.1.transformer.2.norm1.weight\", \"stages.4.1.transformer.2.norm1.bias\", \"stages.4.1.transformer.2.attn.qkv.weight\", \"stages.4.1.transformer.2.attn.qkv.bias\", \"stages.4.1.transformer.2.attn.proj.weight\", \"stages.4.1.transformer.2.attn.proj.bias\", \"stages.4.1.transformer.2.norm2.weight\", \"stages.4.1.transformer.2.norm2.bias\", \"stages.4.1.transformer.2.mlp.fc1.weight\", \"stages.4.1.transformer.2.mlp.fc1.bias\", \"stages.4.1.transformer.2.mlp.fc2.weight\", \"stages.4.1.transformer.2.mlp.fc2.bias\", \"stages.4.1.norm.weight\", \"stages.4.1.norm.bias\", \"stages.4.1.conv_proj.conv.weight\", \"stages.4.1.conv_proj.bn.weight\", \"stages.4.1.conv_proj.bn.bias\", \"stages.4.1.conv_proj.bn.running_mean\", \"stages.4.1.conv_proj.bn.running_var\", \"stages.4.1.conv_fusion.conv.weight\", \"stages.4.1.conv_fusion.bn.weight\", \"stages.4.1.conv_fusion.bn.bias\", \"stages.4.1.conv_fusion.bn.running_mean\", \"stages.4.1.conv_fusion.bn.running_var\", \"final_conv.conv.weight\", \"final_conv.bn.weight\", \"final_conv.bn.bias\", \"final_conv.bn.running_mean\", \"final_conv.bn.running_var\", \"head.fc.weight\", \"head.fc.bias\". \n\tUnexpected key(s) in state_dict: \"model.stem.conv.weight\", \"model.stem.bn.weight\", \"model.stem.bn.bias\", \"model.stem.bn.running_mean\", \"model.stem.bn.running_var\", \"model.stem.bn.num_batches_tracked\", \"model.stages.0.0.conv1_1x1.conv.weight\", \"model.stages.0.0.conv1_1x1.bn.weight\", \"model.stages.0.0.conv1_1x1.bn.bias\", \"model.stages.0.0.conv1_1x1.bn.running_mean\", \"model.stages.0.0.conv1_1x1.bn.running_var\", \"model.stages.0.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.0.0.conv2_kxk.conv.weight\", \"model.stages.0.0.conv2_kxk.bn.weight\", \"model.stages.0.0.conv2_kxk.bn.bias\", \"model.stages.0.0.conv2_kxk.bn.running_mean\", \"model.stages.0.0.conv2_kxk.bn.running_var\", \"model.stages.0.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.0.0.conv3_1x1.conv.weight\", \"model.stages.0.0.conv3_1x1.bn.weight\", \"model.stages.0.0.conv3_1x1.bn.bias\", \"model.stages.0.0.conv3_1x1.bn.running_mean\", \"model.stages.0.0.conv3_1x1.bn.running_var\", \"model.stages.0.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv1_1x1.conv.weight\", \"model.stages.1.0.conv1_1x1.bn.weight\", \"model.stages.1.0.conv1_1x1.bn.bias\", \"model.stages.1.0.conv1_1x1.bn.running_mean\", \"model.stages.1.0.conv1_1x1.bn.running_var\", \"model.stages.1.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv2_kxk.conv.weight\", \"model.stages.1.0.conv2_kxk.bn.weight\", \"model.stages.1.0.conv2_kxk.bn.bias\", \"model.stages.1.0.conv2_kxk.bn.running_mean\", \"model.stages.1.0.conv2_kxk.bn.running_var\", \"model.stages.1.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.1.0.conv3_1x1.conv.weight\", \"model.stages.1.0.conv3_1x1.bn.weight\", \"model.stages.1.0.conv3_1x1.bn.bias\", \"model.stages.1.0.conv3_1x1.bn.running_mean\", \"model.stages.1.0.conv3_1x1.bn.running_var\", \"model.stages.1.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.1.conv1_1x1.conv.weight\", \"model.stages.1.1.conv1_1x1.bn.weight\", \"model.stages.1.1.conv1_1x1.bn.bias\", \"model.stages.1.1.conv1_1x1.bn.running_mean\", \"model.stages.1.1.conv1_1x1.bn.running_var\", \"model.stages.1.1.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.1.conv2_kxk.conv.weight\", \"model.stages.1.1.conv2_kxk.bn.weight\", \"model.stages.1.1.conv2_kxk.bn.bias\", \"model.stages.1.1.conv2_kxk.bn.running_mean\", \"model.stages.1.1.conv2_kxk.bn.running_var\", \"model.stages.1.1.conv2_kxk.bn.num_batches_tracked\", \"model.stages.1.1.conv3_1x1.conv.weight\", \"model.stages.1.1.conv3_1x1.bn.weight\", \"model.stages.1.1.conv3_1x1.bn.bias\", \"model.stages.1.1.conv3_1x1.bn.running_mean\", \"model.stages.1.1.conv3_1x1.bn.running_var\", \"model.stages.1.1.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.2.conv1_1x1.conv.weight\", \"model.stages.1.2.conv1_1x1.bn.weight\", \"model.stages.1.2.conv1_1x1.bn.bias\", \"model.stages.1.2.conv1_1x1.bn.running_mean\", \"model.stages.1.2.conv1_1x1.bn.running_var\", \"model.stages.1.2.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.2.conv2_kxk.conv.weight\", \"model.stages.1.2.conv2_kxk.bn.weight\", \"model.stages.1.2.conv2_kxk.bn.bias\", \"model.stages.1.2.conv2_kxk.bn.running_mean\", \"model.stages.1.2.conv2_kxk.bn.running_var\", \"model.stages.1.2.conv2_kxk.bn.num_batches_tracked\", \"model.stages.1.2.conv3_1x1.conv.weight\", \"model.stages.1.2.conv3_1x1.bn.weight\", \"model.stages.1.2.conv3_1x1.bn.bias\", \"model.stages.1.2.conv3_1x1.bn.running_mean\", \"model.stages.1.2.conv3_1x1.bn.running_var\", \"model.stages.1.2.conv3_1x1.bn.num_batches_tracked\", \"model.stages.2.0.conv1_1x1.conv.weight\", \"model.stages.2.0.conv1_1x1.bn.weight\", \"model.stages.2.0.conv1_1x1.bn.bias\", \"model.stages.2.0.conv1_1x1.bn.running_mean\", \"model.stages.2.0.conv1_1x1.bn.running_var\", \"model.stages.2.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.2.0.conv2_kxk.conv.weight\", \"model.stages.2.0.conv2_kxk.bn.weight\", \"model.stages.2.0.conv2_kxk.bn.bias\", \"model.stages.2.0.conv2_kxk.bn.running_mean\", \"model.stages.2.0.conv2_kxk.bn.running_var\", \"model.stages.2.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.2.0.conv3_1x1.conv.weight\", \"model.stages.2.0.conv3_1x1.bn.weight\", \"model.stages.2.0.conv3_1x1.bn.bias\", \"model.stages.2.0.conv3_1x1.bn.running_mean\", \"model.stages.2.0.conv3_1x1.bn.running_var\", \"model.stages.2.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.2.1.conv_kxk.conv.weight\", \"model.stages.2.1.conv_kxk.bn.weight\", \"model.stages.2.1.conv_kxk.bn.bias\", \"model.stages.2.1.conv_kxk.bn.running_mean\", \"model.stages.2.1.conv_kxk.bn.running_var\", \"model.stages.2.1.conv_kxk.bn.num_batches_tracked\", \"model.stages.2.1.conv_1x1.weight\", \"model.stages.2.1.transformer.0.norm1.weight\", \"model.stages.2.1.transformer.0.norm1.bias\", \"model.stages.2.1.transformer.0.attn.qkv.weight\", \"model.stages.2.1.transformer.0.attn.qkv.bias\", \"model.stages.2.1.transformer.0.attn.proj.weight\", \"model.stages.2.1.transformer.0.attn.proj.bias\", \"model.stages.2.1.transformer.0.norm2.weight\", \"model.stages.2.1.transformer.0.norm2.bias\", \"model.stages.2.1.transformer.0.mlp.fc1.weight\", \"model.stages.2.1.transformer.0.mlp.fc1.bias\", \"model.stages.2.1.transformer.0.mlp.fc2.weight\", \"model.stages.2.1.transformer.0.mlp.fc2.bias\", \"model.stages.2.1.transformer.1.norm1.weight\", \"model.stages.2.1.transformer.1.norm1.bias\", \"model.stages.2.1.transformer.1.attn.qkv.weight\", \"model.stages.2.1.transformer.1.attn.qkv.bias\", \"model.stages.2.1.transformer.1.attn.proj.weight\", \"model.stages.2.1.transformer.1.attn.proj.bias\", \"model.stages.2.1.transformer.1.norm2.weight\", \"model.stages.2.1.transformer.1.norm2.bias\", \"model.stages.2.1.transformer.1.mlp.fc1.weight\", \"model.stages.2.1.transformer.1.mlp.fc1.bias\", \"model.stages.2.1.transformer.1.mlp.fc2.weight\", \"model.stages.2.1.transformer.1.mlp.fc2.bias\", \"model.stages.2.1.norm.weight\", \"model.stages.2.1.norm.bias\", \"model.stages.2.1.conv_proj.conv.weight\", \"model.stages.2.1.conv_proj.bn.weight\", \"model.stages.2.1.conv_proj.bn.bias\", \"model.stages.2.1.conv_proj.bn.running_mean\", \"model.stages.2.1.conv_proj.bn.running_var\", \"model.stages.2.1.conv_proj.bn.num_batches_tracked\", \"model.stages.2.1.conv_fusion.conv.weight\", \"model.stages.2.1.conv_fusion.bn.weight\", \"model.stages.2.1.conv_fusion.bn.bias\", \"model.stages.2.1.conv_fusion.bn.running_mean\", \"model.stages.2.1.conv_fusion.bn.running_var\", \"model.stages.2.1.conv_fusion.bn.num_batches_tracked\", \"model.stages.3.0.conv1_1x1.conv.weight\", \"model.stages.3.0.conv1_1x1.bn.weight\", \"model.stages.3.0.conv1_1x1.bn.bias\", \"model.stages.3.0.conv1_1x1.bn.running_mean\", \"model.stages.3.0.conv1_1x1.bn.running_var\", \"model.stages.3.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.3.0.conv2_kxk.conv.weight\", \"model.stages.3.0.conv2_kxk.bn.weight\", \"model.stages.3.0.conv2_kxk.bn.bias\", \"model.stages.3.0.conv2_kxk.bn.running_mean\", \"model.stages.3.0.conv2_kxk.bn.running_var\", \"model.stages.3.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.3.0.conv3_1x1.conv.weight\", \"model.stages.3.0.conv3_1x1.bn.weight\", \"model.stages.3.0.conv3_1x1.bn.bias\", \"model.stages.3.0.conv3_1x1.bn.running_mean\", \"model.stages.3.0.conv3_1x1.bn.running_var\", \"model.stages.3.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.3.1.conv_kxk.conv.weight\", \"model.stages.3.1.conv_kxk.bn.weight\", \"model.stages.3.1.conv_kxk.bn.bias\", \"model.stages.3.1.conv_kxk.bn.running_mean\", \"model.stages.3.1.conv_kxk.bn.running_var\", \"model.stages.3.1.conv_kxk.bn.num_batches_tracked\", \"model.stages.3.1.conv_1x1.weight\", \"model.stages.3.1.transformer.0.norm1.weight\", \"model.stages.3.1.transformer.0.norm1.bias\", \"model.stages.3.1.transformer.0.attn.qkv.weight\", \"model.stages.3.1.transformer.0.attn.qkv.bias\", \"model.stages.3.1.transformer.0.attn.proj.weight\", \"model.stages.3.1.transformer.0.attn.proj.bias\", \"model.stages.3.1.transformer.0.norm2.weight\", \"model.stages.3.1.transformer.0.norm2.bias\", \"model.stages.3.1.transformer.0.mlp.fc1.weight\", \"model.stages.3.1.transformer.0.mlp.fc1.bias\", \"model.stages.3.1.transformer.0.mlp.fc2.weight\", \"model.stages.3.1.transformer.0.mlp.fc2.bias\", \"model.stages.3.1.transformer.1.norm1.weight\", \"model.stages.3.1.transformer.1.norm1.bias\", \"model.stages.3.1.transformer.1.attn.qkv.weight\", \"model.stages.3.1.transformer.1.attn.qkv.bias\", \"model.stages.3.1.transformer.1.attn.proj.weight\", \"model.stages.3.1.transformer.1.attn.proj.bias\", \"model.stages.3.1.transformer.1.norm2.weight\", \"model.stages.3.1.transformer.1.norm2.bias\", \"model.stages.3.1.transformer.1.mlp.fc1.weight\", \"model.stages.3.1.transformer.1.mlp.fc1.bias\", \"model.stages.3.1.transformer.1.mlp.fc2.weight\", \"model.stages.3.1.transformer.1.mlp.fc2.bias\", \"model.stages.3.1.transformer.2.norm1.weight\", \"model.stages.3.1.transformer.2.norm1.bias\", \"model.stages.3.1.transformer.2.attn.qkv.weight\", \"model.stages.3.1.transformer.2.attn.qkv.bias\", \"model.stages.3.1.transformer.2.attn.proj.weight\", \"model.stages.3.1.transformer.2.attn.proj.bias\", \"model.stages.3.1.transformer.2.norm2.weight\", \"model.stages.3.1.transformer.2.norm2.bias\", \"model.stages.3.1.transformer.2.mlp.fc1.weight\", \"model.stages.3.1.transformer.2.mlp.fc1.bias\", \"model.stages.3.1.transformer.2.mlp.fc2.weight\", \"model.stages.3.1.transformer.2.mlp.fc2.bias\", \"model.stages.3.1.transformer.3.norm1.weight\", \"model.stages.3.1.transformer.3.norm1.bias\", \"model.stages.3.1.transformer.3.attn.qkv.weight\", \"model.stages.3.1.transformer.3.attn.qkv.bias\", \"model.stages.3.1.transformer.3.attn.proj.weight\", \"model.stages.3.1.transformer.3.attn.proj.bias\", \"model.stages.3.1.transformer.3.norm2.weight\", \"model.stages.3.1.transformer.3.norm2.bias\", \"model.stages.3.1.transformer.3.mlp.fc1.weight\", \"model.stages.3.1.transformer.3.mlp.fc1.bias\", \"model.stages.3.1.transformer.3.mlp.fc2.weight\", \"model.stages.3.1.transformer.3.mlp.fc2.bias\", \"model.stages.3.1.norm.weight\", \"model.stages.3.1.norm.bias\", \"model.stages.3.1.conv_proj.conv.weight\", \"model.stages.3.1.conv_proj.bn.weight\", \"model.stages.3.1.conv_proj.bn.bias\", \"model.stages.3.1.conv_proj.bn.running_mean\", \"model.stages.3.1.conv_proj.bn.running_var\", \"model.stages.3.1.conv_proj.bn.num_batches_tracked\", \"model.stages.3.1.conv_fusion.conv.weight\", \"model.stages.3.1.conv_fusion.bn.weight\", \"model.stages.3.1.conv_fusion.bn.bias\", \"model.stages.3.1.conv_fusion.bn.running_mean\", \"model.stages.3.1.conv_fusion.bn.running_var\", \"model.stages.3.1.conv_fusion.bn.num_batches_tracked\", \"model.stages.4.0.conv1_1x1.conv.weight\", \"model.stages.4.0.conv1_1x1.bn.weight\", \"model.stages.4.0.conv1_1x1.bn.bias\", \"model.stages.4.0.conv1_1x1.bn.running_mean\", \"model.stages.4.0.conv1_1x1.bn.running_var\", \"model.stages.4.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.4.0.conv2_kxk.conv.weight\", \"model.stages.4.0.conv2_kxk.bn.weight\", \"model.stages.4.0.conv2_kxk.bn.bias\", \"model.stages.4.0.conv2_kxk.bn.running_mean\", \"model.stages.4.0.conv2_kxk.bn.running_var\", \"model.stages.4.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.4.0.conv3_1x1.conv.weight\", \"model.stages.4.0.conv3_1x1.bn.weight\", \"model.stages.4.0.conv3_1x1.bn.bias\", \"model.stages.4.0.conv3_1x1.bn.running_mean\", \"model.stages.4.0.conv3_1x1.bn.running_var\", \"model.stages.4.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.4.1.conv_kxk.conv.weight\", \"model.stages.4.1.conv_kxk.bn.weight\", \"model.stages.4.1.conv_kxk.bn.bias\", \"model.stages.4.1.conv_kxk.bn.running_mean\", \"model.stages.4.1.conv_kxk.bn.running_var\", \"model.stages.4.1.conv_kxk.bn.num_batches_tracked\", \"model.stages.4.1.conv_1x1.weight\", \"model.stages.4.1.transformer.0.norm1.weight\", \"model.stages.4.1.transformer.0.norm1.bias\", \"model.stages.4.1.transformer.0.attn.qkv.weight\", \"model.stages.4.1.transformer.0.attn.qkv.bias\", \"model.stages.4.1.transformer.0.attn.proj.weight\", \"model.stages.4.1.transformer.0.attn.proj.bias\", \"model.stages.4.1.transformer.0.norm2.weight\", \"model.stages.4.1.transformer.0.norm2.bias\", \"model.stages.4.1.transformer.0.mlp.fc1.weight\", \"model.stages.4.1.transformer.0.mlp.fc1.bias\", \"model.stages.4.1.transformer.0.mlp.fc2.weight\", \"model.stages.4.1.transformer.0.mlp.fc2.bias\", \"model.stages.4.1.transformer.1.norm1.weight\", \"model.stages.4.1.transformer.1.norm1.bias\", \"model.stages.4.1.transformer.1.attn.qkv.weight\", \"model.stages.4.1.transformer.1.attn.qkv.bias\", \"model.stages.4.1.transformer.1.attn.proj.weight\", \"model.stages.4.1.transformer.1.attn.proj.bias\", \"model.stages.4.1.transformer.1.norm2.weight\", \"model.stages.4.1.transformer.1.norm2.bias\", \"model.stages.4.1.transformer.1.mlp.fc1.weight\", \"model.stages.4.1.transformer.1.mlp.fc1.bias\", \"model.stages.4.1.transformer.1.mlp.fc2.weight\", \"model.stages.4.1.transformer.1.mlp.fc2.bias\", \"model.stages.4.1.transformer.2.norm1.weight\", \"model.stages.4.1.transformer.2.norm1.bias\", \"model.stages.4.1.transformer.2.attn.qkv.weight\", \"model.stages.4.1.transformer.2.attn.qkv.bias\", \"model.stages.4.1.transformer.2.attn.proj.weight\", \"model.stages.4.1.transformer.2.attn.proj.bias\", \"model.stages.4.1.transformer.2.norm2.weight\", \"model.stages.4.1.transformer.2.norm2.bias\", \"model.stages.4.1.transformer.2.mlp.fc1.weight\", \"model.stages.4.1.transformer.2.mlp.fc1.bias\", \"model.stages.4.1.transformer.2.mlp.fc2.weight\", \"model.stages.4.1.transformer.2.mlp.fc2.bias\", \"model.stages.4.1.norm.weight\", \"model.stages.4.1.norm.bias\", \"model.stages.4.1.conv_proj.conv.weight\", \"model.stages.4.1.conv_proj.bn.weight\", \"model.stages.4.1.conv_proj.bn.bias\", \"model.stages.4.1.conv_proj.bn.running_mean\", \"model.stages.4.1.conv_proj.bn.running_var\", \"model.stages.4.1.conv_proj.bn.num_batches_tracked\", \"model.stages.4.1.conv_fusion.conv.weight\", \"model.stages.4.1.conv_fusion.bn.weight\", \"model.stages.4.1.conv_fusion.bn.bias\", \"model.stages.4.1.conv_fusion.bn.running_mean\", \"model.stages.4.1.conv_fusion.bn.running_var\", \"model.stages.4.1.conv_fusion.bn.num_batches_tracked\", \"model.final_conv.conv.weight\", \"model.final_conv.bn.weight\", \"model.final_conv.bn.bias\", \"model.final_conv.bn.running_mean\", \"model.final_conv.bn.running_var\", \"model.final_conv.bn.num_batches_tracked\", \"model.head.fc.weight\", \"model.head.fc.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2b26c40707d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the weights from the 'model_state_dict' key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ByobNet:\n\tMissing key(s) in state_dict: \"stem.conv.weight\", \"stem.bn.weight\", \"stem.bn.bias\", \"stem.bn.running_mean\", \"stem.bn.running_var\", \"stages.0.0.conv1_1x1.conv.weight\", \"stages.0.0.conv1_1x1.bn.weight\", \"stages.0.0.conv1_1x1.bn.bias\", \"stages.0.0.conv1_1x1.bn.running_mean\", \"stages.0.0.conv1_1x1.bn.running_var\", \"stages.0.0.conv2_kxk.conv.weight\", \"stages.0.0.conv2_kxk.bn.weight\", \"stages.0.0.conv2_kxk.bn.bias\", \"stages.0.0.conv2_kxk.bn.running_mean\", \"stages.0.0.conv2_kxk.bn.running_var\", \"stages.0.0.conv3_1x1.conv.weight\", \"stages.0.0.conv3_1x1.bn.weight\", \"stages.0.0.conv3_1x1.bn.bias\", \"stages.0.0.conv3_1x1.bn.running_mean\", \"stages.0.0.conv3_1x1.bn.running_var\", \"stages.1.0.conv1_1x1.conv.weight\", \"stages.1.0.conv1_1x1.bn.weight\", \"stages.1.0.conv1_1x1.bn.bias\", \"stages.1.0.conv1_1x1.bn.running_mean\", \"stages.1.0.conv1_1x1.bn.running_var\", \"stages.1.0.conv2_kxk.conv.weight\", \"stages.1.0.conv2_kxk.bn.weight\", \"stages.1.0.conv2_kxk.bn.bias\", \"stages.1.0.conv2_kxk.bn.running_mean\", \"stages.1.0.conv2_kxk.bn.running_var\", \"stages.1.0.conv3_1x1.conv.weight\", \"stages.1.0.conv3_1x1.bn.weight\", \"stages.1.0.conv3_1x1.bn.bias\", \"stages.1.0.conv3_1x1.bn.running_mean\", \"stages.1.0.conv3_1x1.bn.running_var\", \"stages.1.1.conv1_1x1.conv.weight\", \"stages.1.1.conv1_1x1.bn.weight\", \"stages.1.1.conv1_1x1.bn.bias\", \"stages.1.1.conv1_1x1.bn.running_mean\", \"stages.1.1.conv1_1x1.bn.running_var\", \"stages.1.1.conv2_kxk.conv.weight\", \"stages.1.1.conv2_kxk.bn.weight\", \"stages.1.1.conv2_kxk.bn.bia...\n\tUnexpected key(s) in state_dict: \"model.stem.conv.weight\", \"model.stem.bn.weight\", \"model.stem.bn.bias\", \"model.stem.bn.running_mean\", \"model.stem.bn.running_var\", \"model.stem.bn.num_batches_tracked\", \"model.stages.0.0.conv1_1x1.conv.weight\", \"model.stages.0.0.conv1_1x1.bn.weight\", \"model.stages.0.0.conv1_1x1.bn.bias\", \"model.stages.0.0.conv1_1x1.bn.running_mean\", \"model.stages.0.0.conv1_1x1.bn.running_var\", \"model.stages.0.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.0.0.conv2_kxk.conv.weight\", \"model.stages.0.0.conv2_kxk.bn.weight\", \"model.stages.0.0.conv2_kxk.bn.bias\", \"model.stages.0.0.conv2_kxk.bn.running_mean\", \"model.stages.0.0.conv2_kxk.bn.running_var\", \"model.stages.0.0.conv2_kxk.bn.num_batches_tracked\", \"model.stages.0.0.conv3_1x1.conv.weight\", \"model.stages.0.0.conv3_1x1.bn.weight\", \"model.stages.0.0.conv3_1x1.bn.bias\", \"model.stages.0.0.conv3_1x1.bn.running_mean\", \"model.stages.0.0.conv3_1x1.bn.running_var\", \"model.stages.0.0.conv3_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv1_1x1.conv.weight\", \"model.stages.1.0.conv1_1x1.bn.weight\", \"model.stages.1.0.conv1_1x1.bn.bias\", \"model.stages.1.0.conv1_1x1.bn.running_mean\", \"model.stages.1.0.conv1_1x1.bn.running_var\", \"model.stages.1.0.conv1_1x1.bn.num_batches_tracked\", \"model.stages.1.0.conv2_kxk.conv.weight\", \"model.stages.1.0.conv2_kxk.bn.weight\", \"model.stages.1.0.conv2_kxk.bn.bias\", \"model.stages.1.0.conv2_kxk.bn.running_mean\", \"model.stages.1.0.conv2_kxk.bn.running_var\", \"model.stages.1.0.conv2_kxk...."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2CpbXfYT8MJ",
        "outputId": "d041bb00-6f53-4e17-b8a6-da098df930ab"
      },
      "id": "A2CpbXfYT8MJ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ByobNet(\n",
            "  (stem): ConvNormAct(\n",
            "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNormAct2d(\n",
            "      16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "      (drop): Identity()\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (stages): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Identity()\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (shortcut): Identity()\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (shortcut): Identity()\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): MobileVitBlock(\n",
            "        (conv_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (transformer): Sequential(\n",
            "          (0): Block(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (1): Block(\n",
            "            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (conv_proj): ConvNormAct(\n",
            "          (conv): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_fusion): ConvNormAct(\n",
            "          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): MobileVitBlock(\n",
            "        (conv_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_1x1): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (transformer): Sequential(\n",
            "          (0): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (1): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (2): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (3): Block(\n",
            "            (norm1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=80, out_features=240, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=80, out_features=80, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=80, out_features=160, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=160, out_features=80, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
            "        (conv_proj): ConvNormAct(\n",
            "          (conv): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_fusion): ConvNormAct(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (conv1_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv2b_kxk): Identity()\n",
            "        (attn): Identity()\n",
            "        (conv3_1x1): ConvNormAct(\n",
            "          (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): Identity()\n",
            "          )\n",
            "        )\n",
            "        (attn_last): Identity()\n",
            "        (drop_path): Identity()\n",
            "        (act): Identity()\n",
            "      )\n",
            "      (1): MobileVitBlock(\n",
            "        (conv_kxk): ConvNormAct(\n",
            "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_1x1): Conv2d(80, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (transformer): Sequential(\n",
            "          (0): Block(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (1): Block(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "          (2): Block(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): Attention(\n",
            "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "              (q_norm): Identity()\n",
            "              (k_norm): Identity()\n",
            "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): Identity()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=96, out_features=192, bias=True)\n",
            "              (act): SiLU()\n",
            "              (drop1): Dropout(p=0.0, inplace=False)\n",
            "              (norm): Identity()\n",
            "              (fc2): Linear(in_features=192, out_features=96, bias=True)\n",
            "              (drop2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): Identity()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (conv_proj): ConvNormAct(\n",
            "          (conv): Conv2d(96, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (conv_fusion): ConvNormAct(\n",
            "          (conv): Conv2d(160, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNormAct2d(\n",
            "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "            (drop): Identity()\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final_conv): ConvNormAct(\n",
            "    (conv): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNormAct2d(\n",
            "      320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
            "      (drop): Identity()\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (head): ClassifierHead(\n",
            "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (fc): Linear(in_features=320, out_features=7, bias=True)\n",
            "    (flatten): Identity()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(f\"{artifact_dir}/final_vit_model.pth\")\n",
        "print(checkpoint.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb1GA0r5UYi6",
        "outputId": "14d2a97d-06ad-4ba2-af30-64ba9dc3e8c0"
      },
      "id": "nb1GA0r5UYi6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['model_state_dict', 'optimizer_state_dict', 'test_accuracy', 'config'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = checkpoint['model_state_dict']\n"
      ],
      "metadata": {
        "id": "avAaIsTAUhH2"
      },
      "id": "avAaIsTAUhH2",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = checkpoint['model_state_dict']\n",
        "for key in list(state_dict.keys())[:10]:  # just first 10 keys to peek\n",
        "    print(key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph3SJWfUUmd0",
        "outputId": "3ff245da-f5ed-4874-f173-40995425661b"
      },
      "id": "Ph3SJWfUUmd0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.stem.conv.weight\n",
            "model.stem.bn.weight\n",
            "model.stem.bn.bias\n",
            "model.stem.bn.running_mean\n",
            "model.stem.bn.running_var\n",
            "model.stem.bn.num_batches_tracked\n",
            "model.stages.0.0.conv1_1x1.conv.weight\n",
            "model.stages.0.0.conv1_1x1.bn.weight\n",
            "model.stages.0.0.conv1_1x1.bn.bias\n",
            "model.stages.0.0.conv1_1x1.bn.running_mean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "# Fix the keys\n",
        "fixed_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    new_k = k.replace(\"model.\", \"\", 1)  # Remove only the first 'model.'\n",
        "    fixed_state_dict[new_k] = v\n",
        "\n",
        "# Load it\n",
        "model.load_state_dict(fixed_state_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY8vGQ_9Uqa7",
        "outputId": "fa7de7cf-a911-4029-aa6b-d810173c4fc0"
      },
      "id": "xY8vGQ_9Uqa7",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "fHigAC8ZU9sk"
      },
      "id": "fHigAC8ZU9sk",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        image = np.array(pixels.split(), dtype='uint8')\n",
        "        image = image.reshape(48, 48, 1).astype('float32') / 255.0\n",
        "        image = np.repeat(image, 3, axis=-1)  # Convert to 3 channels for ViT\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image  # no label\n"
      ],
      "metadata": {
        "id": "QbWwTGMlVJxj"
      },
      "id": "QbWwTGMlVJxj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set device\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaN_oMWrV0t6",
        "outputId": "0bfff449-45f4-478e-ef74-3ba3718241b3"
      },
      "id": "ZaN_oMWrV0t6",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "U95wBX9AV3I_"
      },
      "id": "U95wBX9AV3I_",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TestDataset(test_df, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "easUYH7VVZP_"
      },
      "id": "easUYH7VVZP_",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend(preds.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "ZinWozsTVoOi"
      },
      "id": "ZinWozsTVoOi",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = test_df.copy()\n",
        "submission_df['emotion'] = predictions  # or vit_preds or your own blend\n",
        "submission_df = submission_df[['emotion']]  # make sure the format matches what's required\n",
        "\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "dJJRRulxX-F_"
      },
      "id": "dJJRRulxX-F_",
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}