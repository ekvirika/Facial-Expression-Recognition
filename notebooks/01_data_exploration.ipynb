{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1zaoqrgoYwM",
        "outputId": "89031bdc-b601-4245-a195-ffb754ac126a"
      },
      "id": "M1zaoqrgoYwM",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a0755c03",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0755c03",
        "outputId": "e1644349-7726-4424-8544-e758f8ad6f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install wandb torch torchvision pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "# Set up Kaggle API\n",
        "!pip install kaggle\n",
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "x7Af820TpSf9"
      },
      "id": "x7Af820TpSf9",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izzUxmVMpbRB",
        "outputId": "676ea915-c9c7-4704-d44c-1b7a6d6bc722"
      },
      "id": "izzUxmVMpbRB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 99% 282M/285M [00:00<00:00, 522MB/s]\n",
            "100% 285M/285M [00:00<00:00, 511MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBKxyYH_oxmq",
        "outputId": "ffdfb676-41aa-48d7-c2ab-b7c69fd753bf"
      },
      "id": "pBKxyYH_oxmq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "MvtiRSZTqvEI"
      },
      "id": "MvtiRSZTqvEI",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 32\n",
        "        self.learning_rate = 0.001\n",
        "        self.epochs = 50\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.num_classes = 7  # 7 emotions in FER2013\n",
        "        self.image_size = 48\n",
        "        self.seed = 42\n",
        "\n",
        "        # Class names for FER2013\n",
        "        self.class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n"
      ],
      "metadata": {
        "id": "Qz7eZQt-rs8Q"
      },
      "id": "Qz7eZQt-rs8Q",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None, is_train=True):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Extract pixel data\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        emotion = self.data.iloc[idx]['emotion']\n",
        "\n",
        "        # Convert pixel string to numpy array\n",
        "        image = np.array([int(pixel) for pixel in pixels.split()]).reshape(48, 48)\n",
        "        image = Image.fromarray(image.astype('uint8'), mode='L')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, emotion"
      ],
      "metadata": {
        "id": "kyxdXPdKrwpk"
      },
      "id": "kyxdXPdKrwpk",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(is_train=True):\n",
        "    if is_train:\n",
        "        return transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=10),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "        ])"
      ],
      "metadata": {
        "id": "weReEyvErzgC"
      },
      "id": "weReEyvErzgC",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"Baseline simple CNN architecture\"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64 * 12 * 12, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZRoqTZ7MsFvy"
      },
      "id": "ZRoqTZ7MsFvy",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, device, config):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.config = config\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_accuracies = []\n",
        "        self.val_accuracies = []\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(data)\n",
        "            loss = self.criterion(output, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            # Log to wandb every 100 batches\n",
        "            if batch_idx % 100 == 0:\n",
        "                wandb.log({\n",
        "                    'batch_loss': loss.item(),\n",
        "                    'batch_accuracy': 100. * correct / total\n",
        "                })\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100. * correct / total\n",
        "\n",
        "        self.train_losses.append(epoch_loss)\n",
        "        self.train_accuracies.append(epoch_acc)\n",
        "\n",
        "        return epoch_loss, epoch_acc\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                val_loss += self.criterion(output, target).item()\n",
        "\n",
        "                _, predicted = output.max(1)\n",
        "                total += target.size(0)\n",
        "                correct += predicted.eq(target).sum().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = 100. * correct / total\n",
        "\n",
        "        self.val_losses.append(val_loss)\n",
        "        self.val_accuracies.append(val_acc)\n",
        "\n",
        "        return val_loss, val_acc, all_predictions, all_targets\n",
        "\n",
        "    def train(self, train_loader, val_loader):\n",
        "        best_val_acc = 0.0\n",
        "        patience = 10\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(self.config.epochs):\n",
        "            print(f'\\nEpoch {epoch+1}/{self.config.epochs}')\n",
        "            print('-' * 50)\n",
        "\n",
        "            # Training\n",
        "            train_loss, train_acc = self.train_epoch(train_loader)\n",
        "\n",
        "            # Validation\n",
        "            val_loss, val_acc, predictions, targets = self.validate(val_loader)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            self.scheduler.step()\n",
        "\n",
        "            # Print epoch results\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "            # Log to wandb\n",
        "            wandb.log({\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': train_loss,\n",
        "                'train_accuracy': train_acc,\n",
        "                'val_loss': val_loss,\n",
        "                'val_accuracy': val_acc,\n",
        "                'learning_rate': self.optimizer.param_groups[0]['lr']\n",
        "            })\n",
        "\n",
        "            # Early stopping\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                # Save best model\n",
        "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "                wandb.save('best_model.pth')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
        "                break\n",
        "\n",
        "        # Generate final confusion matrix\n",
        "        self.plot_confusion_matrix(targets, predictions, self.config.class_names)\n",
        "\n",
        "        return best_val_acc\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true, y_pred, class_names):\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('confusion_matrix.png')\n",
        "        wandb.log({\"confusion_matrix\": wandb.Image(\"confusion_matrix.png\")})\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "guTi0fw5sGb9"
      },
      "id": "guTi0fw5sGb9",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model_name, model_class, config, train_loader, val_loader):\n",
        "    \"\"\"Run a single experiment with proper logging\"\"\"\n",
        "\n",
        "    # Initialize wandb run\n",
        "    run = wandb.init(\n",
        "        project=\"facial-expression-recognition\",\n",
        "        name=f\"{model_name}_{wandb.util.generate_id()}\",\n",
        "        config={\n",
        "            'model_name': model_name,\n",
        "            'batch_size': config.batch_size,\n",
        "            'learning_rate': config.learning_rate,\n",
        "            'epochs': config.epochs,\n",
        "            'image_size': config.image_size\n",
        "        },\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = model_class(num_classes=config.num_classes)\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"\\n{model_name} Architecture:\")\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "    wandb.log({\n",
        "        'total_parameters': total_params,\n",
        "        'trainable_parameters': trainable_params\n",
        "    })\n",
        "\n",
        "    # Train model\n",
        "    trainer = Trainer(model, config.device, config)\n",
        "    best_acc = trainer.train(train_loader, val_loader)\n",
        "\n",
        "    # Log final metrics\n",
        "    wandb.log({'best_validation_accuracy': best_acc})\n",
        "\n",
        "    # Finish wandb run\n",
        "    wandb.finish()\n",
        "\n",
        "    return best_acc"
      ],
      "metadata": {
        "id": "P7LQMYqJsKlH"
      },
      "id": "P7LQMYqJsKlH",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "config = Config()\n",
        "print(f\"Using device: {config.device}\")\n",
        "\n",
        "# Prepare data loaders\n",
        "train_transform = get_transforms(is_train=True)\n",
        "val_transform = get_transforms(is_train=False)\n",
        "\n",
        "# Load datasets (assuming fer2013.csv is available)\n",
        "# You need to split the data into train/val sets\n",
        "train_dataset = FER2013Dataset('train.csv', transform=train_transform)\n",
        "val_dataset = FER2013Dataset('train.csv', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                        shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.batch_size,\n",
        "                      shuffle=False, num_workers=2)\n",
        "\n",
        "# Run experiments\n",
        "experiments = [\n",
        "    (\"SimpleCNN_Baseline\", SimpleCNN),\n",
        "    # (\"EnhancedCNN_BatchNorm\", EnhancedCNN),\n",
        "    # (\"DeepCNN_Advanced\", DeepCNN)\n",
        "]\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model_class in experiments:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running experiment: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    best_acc = run_experiment(model_name, model_class, config, train_loader, val_loader)\n",
        "    results[model_name] = best_acc\n",
        "\n",
        "    print(f\"{model_name} Best Validation Accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "# Print summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"EXPERIMENT SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.2f}%\")\n",
        "\n",
        "# Find best model\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\nBest performing model: {best_model} ({results[best_model]:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zb3Ft1CVsNba",
        "outputId": "a9904348-d2c6-4b20-9dfa-53f1a4a6889c"
      },
      "id": "Zb3Ft1CVsNba",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "============================================================\n",
            "Running experiment: SimpleCNN_Baseline\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mellekvirikashvili\u001b[0m (\u001b[33mellekvirikashvili-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250526_134850-63w2g1z9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/63w2g1z9' target=\"_blank\">SimpleCNN_Baseline_4jrnecpn</a></strong> to <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/63w2g1z9' target=\"_blank\">https://wandb.ai/ellekvirikashvili-free-university-of-tbilisi-/facial-expression-recognition/runs/63w2g1z9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SimpleCNN_Baseline Architecture:\n",
            "Total parameters: 1,199,495\n",
            "Trainable parameters: 1,199,495\n",
            "\n",
            "Epoch 1/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.7132, Train Acc: 30.57%\n",
            "Val Loss: 1.5427, Val Acc: 40.75%\n",
            "\n",
            "Epoch 2/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.5838, Train Acc: 38.04%\n",
            "Val Loss: 1.4550, Val Acc: 45.71%\n",
            "\n",
            "Epoch 3/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.5229, Train Acc: 40.66%\n",
            "Val Loss: 1.3931, Val Acc: 47.02%\n",
            "\n",
            "Epoch 4/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.4881, Train Acc: 42.28%\n",
            "Val Loss: 1.3560, Val Acc: 48.64%\n",
            "\n",
            "Epoch 5/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.4630, Train Acc: 43.53%\n",
            "Val Loss: 1.3364, Val Acc: 49.76%\n",
            "\n",
            "Epoch 6/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.4423, Train Acc: 44.35%\n",
            "Val Loss: 1.3075, Val Acc: 50.99%\n",
            "\n",
            "Epoch 7/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.4284, Train Acc: 45.22%\n",
            "Val Loss: 1.2727, Val Acc: 51.73%\n",
            "\n",
            "Epoch 8/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.4165, Train Acc: 45.70%\n",
            "Val Loss: 1.2590, Val Acc: 52.32%\n",
            "\n",
            "Epoch 9/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.4059, Train Acc: 45.71%\n",
            "Val Loss: 1.2381, Val Acc: 53.28%\n",
            "\n",
            "Epoch 10/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3973, Train Acc: 46.39%\n",
            "Val Loss: 1.2250, Val Acc: 53.31%\n",
            "\n",
            "Epoch 11/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3867, Train Acc: 46.61%\n",
            "Val Loss: 1.2265, Val Acc: 53.01%\n",
            "\n",
            "Epoch 12/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3759, Train Acc: 47.16%\n",
            "Val Loss: 1.2094, Val Acc: 54.07%\n",
            "\n",
            "Epoch 13/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3705, Train Acc: 47.47%\n",
            "Val Loss: 1.1829, Val Acc: 54.90%\n",
            "\n",
            "Epoch 14/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3666, Train Acc: 47.58%\n",
            "Val Loss: 1.1854, Val Acc: 54.30%\n",
            "\n",
            "Epoch 15/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3560, Train Acc: 47.61%\n",
            "Val Loss: 1.1753, Val Acc: 55.60%\n",
            "\n",
            "Epoch 16/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3525, Train Acc: 48.17%\n",
            "Val Loss: 1.1628, Val Acc: 56.01%\n",
            "\n",
            "Epoch 17/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3456, Train Acc: 48.24%\n",
            "Val Loss: 1.1646, Val Acc: 55.05%\n",
            "\n",
            "Epoch 18/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3377, Train Acc: 48.54%\n",
            "Val Loss: 1.1599, Val Acc: 56.02%\n",
            "\n",
            "Epoch 19/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3320, Train Acc: 49.03%\n",
            "Val Loss: 1.1481, Val Acc: 56.61%\n",
            "\n",
            "Epoch 20/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3366, Train Acc: 48.58%\n",
            "Val Loss: 1.1517, Val Acc: 56.70%\n",
            "\n",
            "Epoch 21/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3141, Train Acc: 49.65%\n",
            "Val Loss: 1.1259, Val Acc: 57.48%\n",
            "\n",
            "Epoch 22/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3107, Train Acc: 49.96%\n",
            "Val Loss: 1.1222, Val Acc: 57.80%\n",
            "\n",
            "Epoch 23/50\n",
            "--------------------------------------------------\n",
            "Train Loss: 1.3078, Train Acc: 49.47%\n",
            "Val Loss: 1.1182, Val Acc: 57.87%\n",
            "\n",
            "Epoch 24/50\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# advanced_architectures.py\n",
        "# Advanced CNN architectures for comprehensive experimentation\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torch.nn import init\n",
        "\n",
        "# 1. Attention-based CNN\n",
        "class AttentionCNN(nn.Module):\n",
        "    \"\"\"CNN with spatial attention mechanism\"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(AttentionCNN, self).__init__()\n",
        "\n",
        "        # Feature extraction layers\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention_conv = nn.Conv2d(256, 1, kernel_size=1)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feature extraction\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        features = F.max_pool2d(x, 2)  # [B, 256, 6, 6]\n",
        "\n",
        "        # Attention mechanism\n",
        "        attention_weights = torch.sigmoid(self.attention_conv(features))  # [B, 1, 6, 6]\n",
        "        attended_features = features * attention_weights  # Element-wise multiplication\n",
        "\n",
        "        # Classification\n",
        "        output = self.classifier(attended_features)\n",
        "        return output\n",
        "\n",
        "# 2. Multi-Scale CNN\n",
        "class MultiScaleCNN(nn.Module):\n",
        "    \"\"\"CNN with multiple scale feature extraction\"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(MultiScaleCNN, self).__init__()\n",
        "\n",
        "        # Different scale branches\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Fusion layers\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv2d(96, 128, kernel_size=3, padding=1),  # 32*3 = 96\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-scale feature extraction\n",
        "        branch1_out = self.branch1(x)\n",
        "        branch2_out = self.branch2(x)\n",
        "        branch3_out = self.branch3(x)\n",
        "\n",
        "        # Concatenate features\n",
        "        fused = torch.cat([branch1_out, branch2_out, branch3_out], dim=1)\n",
        "\n",
        "        # Further processing\n",
        "        features = self.fusion(fused)\n",
        "        output = self.classifier(features)\n",
        "\n",
        "        return output\n",
        "\n",
        "# 3. ResNet-style CNN with residual connections\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                              stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                              stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Shortcut connection\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                         stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        out += self.shortcut(residual)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class CustomResNet(nn.Module):\n",
        "    \"\"\"Custom ResNet for facial expression recognition\"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(CustomResNet, self).__init__()\n",
        "\n",
        "        # Initial convolution\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
        "\n",
        "        # Classifier\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# 4. Transfer Learning Models\n",
        "class TransferLearningModel(nn.Module):\n",
        "    \"\"\"Transfer learning from pre-trained models\"\"\"\n",
        "    def __init__(self, model_name='resnet18', num_classes=7, pretrained=True):\n",
        "        super(TransferLearningModel, self).__init__()\n",
        "\n",
        "        if model_name == 'resnet18':\n",
        "            self.backbone = models.resnet18(pretrained=pretrained)\n",
        "            # Modify first layer for grayscale input\n",
        "            self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2,\n",
        "                                          padding=3, bias=False)\n",
        "            # Modify final layer\n",
        "            self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            self.backbone = models.vgg16(pretrained=pretrained)\n",
        "            # Modify first layer for grayscale input\n",
        "            self.backbone.features[0] = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "            # Modify classifier\n",
        "            self.backbone.classifier[-1] = nn.Linear(4096, num_classes)\n",
        "\n",
        "        # Fine-tuning strategy: freeze early layers\n",
        "        self.freeze_early_layers()\n",
        "\n",
        "    def freeze_early_layers(self):\n",
        "        \"\"\"Freeze early layers for fine-tuning\"\"\"\n",
        "        # Freeze first few layers\n",
        "        ct = 0\n",
        "        for child in self.backbone.children():\n",
        "            ct += 1\n",
        "            if ct < 7:  # Freeze first 6 layers\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# 5. Ensemble Model\n",
        "class EnsembleModel(nn.Module):\n",
        "    \"\"\"Ensemble of different architectures\"\"\"\n",
        "    def __init__(self, models_list, num_classes=7):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.models = nn.ModuleList(models_list)\n",
        "        self.num_models = len(models_list)\n",
        "\n",
        "        # Weighted combination\n",
        "        self.weights = nn.Parameter(torch.ones(self.num_models) / self.num_models)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            outputs.append(model(x))\n",
        "\n",
        "        # Weighted average\n",
        "        weighted_outputs = []\n",
        "        for i, output in enumerate(outputs):\n",
        "            weighted_outputs.append(self.weights[i] * F.softmax(output, dim=1))\n",
        "\n",
        "        ensemble_output = torch.stack(weighted_outputs).sum(dim=0)\n",
        "        return torch.log(ensemble_output + 1e-8)  # Convert back to log-probabilities\n",
        "\n",
        "# 6. Advanced Training Strategies\n",
        "class AdvancedTrainer:\n",
        "    \"\"\"Enhanced trainer with advanced techniques\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, config):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.config = config\n",
        "\n",
        "        # Advanced loss functions\n",
        "        self.criterion = self.get_loss_function()\n",
        "\n",
        "        # Advanced optimizers\n",
        "        self.optimizer = self.get_optimizer()\n",
        "\n",
        "        # Advanced schedulers\n",
        "        self.scheduler = self.get_scheduler()\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.metrics = {\n",
        "            'train_losses': [], 'val_losses': [],\n",
        "            'train_accuracies': [], 'val_accuracies': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "\n",
        "    def get_loss_function(self):\n",
        "        \"\"\"Select appropriate loss function\"\"\"\n",
        "        if hasattr(self.config, 'loss_type'):\n",
        "            if self.config.loss_type == 'focal':\n",
        "                return FocalLoss(alpha=1, gamma=2)\n",
        "            elif self.config.loss_type == 'label_smoothing':\n",
        "                return LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "        return nn.CrossEntropyLoss()\n",
        "\n",
        "    def get_optimizer(self):\n",
        "        \"\"\"Select optimizer based on config\"\"\"\n",
        "        if hasattr(self.config, 'optimizer_type'):\n",
        "            if self.config.optimizer_type == 'adamw':\n",
        "                return torch.optim.AdamW(self.model.parameters(),\n",
        "                                       lr=self.config.learning_rate,\n",
        "                                       weight_decay=0.01)\n",
        "            elif self.config.optimizer_type == 'sgd':\n",
        "                return torch.optim.SGD(self.model.parameters(),\n",
        "                                     lr=self.config.learning_rate,\n",
        "                                     momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "        return torch.optim.Adam(self.model.parameters(), lr=self.config.learning_rate)\n",
        "\n",
        "    def get_scheduler(self):\n",
        "        \"\"\"Advanced learning rate scheduling\"\"\"\n",
        "        if hasattr(self.config, 'scheduler_type'):\n",
        "            if self.config.scheduler_type == 'cosine':\n",
        "                return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "                    self.optimizer, T_max=self.config.epochs)\n",
        "            elif self.config.scheduler_type == 'plateau':\n",
        "                return torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                    self.optimizer, mode='min', patience=5, factor=0.5)\n",
        "\n",
        "        return torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "# 7. Custom Loss Functions\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss for handling class imbalance\"\"\"\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    \"\"\"Label smoothing cross entropy loss\"\"\"\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        confidence = 1. - self.smoothing\n",
        "        logprobs = F.log_softmax(x, dim=-1)\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = confidence * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# 8. Advanced Data Augmentation\n",
        "class AdvancedTransforms:\n",
        "    \"\"\"Advanced data augmentation strategies\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_strong_augmentation():\n",
        "        return transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=15),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "            transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "            transforms.RandomErasing(p=0.2, scale=(0.02, 0.08)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_mixup_cutmix():\n",
        "        \"\"\"Implement MixUp and CutMix augmentation\"\"\"\n",
        "        # This would require additional implementation\n",
        "        pass\n",
        "\n",
        "# 9. Model Analysis Tools\n",
        "class ModelAnalyzer:\n",
        "    \"\"\"Tools for analyzing model behavior\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def analyze_layer_gradients(model):\n",
        "        \"\"\"Analyze gradient flow through layers\"\"\"\n",
        "        gradients = []\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                gradients.append({\n",
        "                    'layer': name,\n",
        "                    'grad_norm': param.grad.norm().item(),\n",
        "                    'param_norm': param.norm().item(),\n",
        "                    'grad_param_ratio': (param.grad.norm() / param.norm()).item()\n",
        "                })\n",
        "        return gradients\n",
        "\n",
        "    @staticmethod\n",
        "    def get_model_complexity(model):\n",
        "        \"\"\"Calculate model complexity metrics\"\"\"\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "        # Calculate FLOPs (approximate)\n",
        "        # This is a simplified calculation\n",
        "        flops = 0\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                flops += module.in_channels * module.out_channels * \\\n",
        "                        module.kernel_size[0] * module.kernel_size[1]\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                flops += module.in_features * module.out_features\n",
        "\n",
        "        return {\n",
        "            'total_parameters': total_params,\n",
        "            'trainable_parameters': trainable_params,\n",
        "            'approximate_flops': flops,\n",
        "            'model_size_mb': total_params * 4 / (1024 * 1024)  # Assuming float32\n",
        "        }\n",
        "\n",
        "# 10. Experiment Configuration\n",
        "class ExperimentConfig:\n",
        "    \"\"\"Advanced configuration for experiments\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Basic config\n",
        "        self.batch_size = 32\n",
        "        self.learning_rate = 0.001\n",
        "        self.epochs = 100\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.num_classes = 7\n",
        "        self.image_size = 48\n",
        "        self.seed = 42\n",
        "\n",
        "        # Advanced config\n",
        "        self.optimizer_type = 'adam'  # 'adam', 'adamw', 'sgd'\n",
        "        self.scheduler_type = 'step'  # 'step', 'cosine', 'plateau'\n",
        "        self.loss_type = 'cross_entropy'  # 'cross_entropy', 'focal', 'label_smoothing'\n",
        "\n",
        "        # Regularization\n",
        "        self.dropout_rate = 0.5\n",
        "        self.weight_decay = 0.0001\n",
        "\n",
        "        # Early stopping\n",
        "        self.patience = 15\n",
        "        self.min_delta = 0.001\n",
        "\n",
        "        # Data augmentation\n",
        "        self.augmentation_strength = 'medium'  # 'light', 'medium', 'strong'\n",
        "\n",
        "        # Logging\n",
        "        self.log_interval = 100\n",
        "        self.save_interval = 10\n",
        "\n",
        "# Example usage for comprehensive experiments\n",
        "def run_comprehensive_experiments():\n",
        "    \"\"\"Run all experiments systematically\"\"\"\n",
        "\n",
        "    config = ExperimentConfig()\n",
        "\n",
        "    experiments = [\n",
        "        # Basic architectures\n",
        "        (\"SimpleCNN_Baseline\", SimpleCNN),\n",
        "        (\"EnhancedCNN_BatchNorm\", EnhancedCNN),\n",
        "        (\"DeepCNN_Advanced\", DeepCNN),\n",
        "\n",
        "        # Advanced architectures\n",
        "        (\"AttentionCNN\", AttentionCNN),\n",
        "        (\"MultiScaleCNN\", MultiScaleCNN),\n",
        "        (\"CustomResNet\", CustomResNet),\n",
        "\n",
        "        # Transfer learning\n",
        "        (\"ResNet18_Transfer\", lambda nc: TransferLearningModel('resnet18', nc, True)),\n",
        "        (\"VGG16_Transfer\", lambda nc: TransferLearningModel('vgg16', nc, True)),\n",
        "    ]\n",
        "\n",
        "    # Different configurations to test\n",
        "    configs_to_test = [\n",
        "        {'optimizer_type': 'adam', 'scheduler_type': 'step'},\n",
        "        {'optimizer_type': 'adamw', 'scheduler_type': 'cosine'},\n",
        "        {'optimizer_type': 'sgd', 'scheduler_type': 'plateau'},\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for model_name, model_class in experiments:\n",
        "        for i, config_params in enumerate(configs_to_test):\n",
        "            experiment_name = f\"{model_name}_config_{i+1}\"\n",
        "\n",
        "            # Update config\n",
        "            for key, value in config_params.items():\n",
        "                setattr(config, key, value)\n",
        "\n",
        "            print(f\"Running: {experiment_name}\")\n",
        "            # Run experiment here...\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "b488tLyKFztB"
      },
      "id": "b488tLyKFztB",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Comprehensive Experimental Plan for Facial Expression Recognition\n",
        "Implementation of all phases with proper logging and analysis\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import wandb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING AND PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "class FERDataset(Dataset):\n",
        "    \"\"\"Custom dataset for facial expression recognition\"\"\"\n",
        "\n",
        "    def __init__(self, data_path, transform=None, split='train'):\n",
        "        self.data_path = Path(data_path)\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "        self.samples = []\n",
        "        self.labels = []\n",
        "        self.emotion_map = {\n",
        "            'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3,\n",
        "            'neutral': 4, 'sad': 5, 'surprise': 6\n",
        "        }\n",
        "        self.class_names = list(self.emotion_map.keys())\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Load data from directory structure or CSV file\"\"\"\n",
        "        # This is a placeholder - adapt based on your actual data format\n",
        "        # For demonstration, we'll create synthetic data\n",
        "        num_samples = 1000 if self.split == 'train' else 200\n",
        "        for i in range(num_samples):\n",
        "            # Create synthetic 48x48 grayscale images\n",
        "            img = torch.randn(48, 48)\n",
        "            label = np.random.randint(0, 7)\n",
        "            self.samples.append(img)\n",
        "            self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.samples[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def get_class_distribution(self):\n",
        "        \"\"\"Get class distribution for analysis\"\"\"\n",
        "        unique, counts = np.unique(self.labels, return_counts=True)\n",
        "        return dict(zip(unique, counts))\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL ARCHITECTURES\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"Simple baseline CNN\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 12 * 12)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class EnhancedCNN(nn.Module):\n",
        "    \"\"\"Enhanced CNN with BatchNorm\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(EnhancedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class DeepCNN(nn.Module):\n",
        "    \"\"\"Deeper CNN with skip connections\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(DeepCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # Skip connection layers\n",
        "        self.skip1 = nn.Conv2d(32, 128, 1)\n",
        "        self.skip2 = nn.Conv2d(64, 256, 1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((3, 3))\n",
        "        self.fc1 = nn.Linear(256 * 3 * 3, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First block\n",
        "        x1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x2 = self.pool(F.relu(self.bn2(self.conv2(x1))))\n",
        "\n",
        "        # Second block with skip connection\n",
        "        x3 = self.pool(F.relu(self.bn3(self.conv3(x2))))\n",
        "        skip1 = self.pool(self.pool(self.skip1(x1)))\n",
        "        x3 = x3 + skip1\n",
        "\n",
        "        x4 = F.relu(self.bn4(self.conv4(x3)))\n",
        "        skip2 = self.skip2(x2)\n",
        "        x4 = x4 + skip2\n",
        "\n",
        "        x = self.adaptive_pool(x4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class AttentionCNN(nn.Module):\n",
        "    \"\"\"CNN with spatial attention mechanism\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(AttentionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention_conv = nn.Conv2d(256, 1, 1)\n",
        "        self.attention_sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Apply attention\n",
        "        attention = self.attention_sigmoid(self.attention_conv(x))\n",
        "        x = x * attention\n",
        "\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x, attention\n",
        "\n",
        "class MultiScaleCNN(nn.Module):\n",
        "    \"\"\"CNN with multi-scale feature extraction\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(MultiScaleCNN, self).__init__()\n",
        "        # Multi-scale convolutions\n",
        "        self.conv3x3 = nn.Conv2d(1, 64, 3, padding=1)\n",
        "        self.conv5x5 = nn.Conv2d(1, 64, 5, padding=2)\n",
        "        self.conv7x7 = nn.Conv2d(1, 64, 7, padding=3)\n",
        "\n",
        "        # Combine features\n",
        "        self.combine_conv = nn.Conv2d(192, 128, 1)\n",
        "        self.conv2 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-scale feature extraction\n",
        "        x3 = F.relu(self.conv3x3(x))\n",
        "        x5 = F.relu(self.conv5x5(x))\n",
        "        x7 = F.relu(self.conv7x7(x))\n",
        "\n",
        "        # Combine features\n",
        "        x = torch.cat([x3, x5, x7], dim=1)\n",
        "        x = self.pool(F.relu(self.combine_conv(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ============================================================================\n",
        "# LOSS FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss for addressing class imbalance\"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    \"\"\"Label smoothing cross-entropy loss\"\"\"\n",
        "\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        log_prob = F.log_softmax(inputs, dim=-1)\n",
        "        weight = inputs.new_ones(inputs.size()) * self.smoothing / (inputs.size(-1) - 1.)\n",
        "        weight.scatter_(-1, targets.unsqueeze(-1), (1. - self.smoothing))\n",
        "        loss = (-weight * log_prob).sum(dim=-1).mean()\n",
        "        return loss\n",
        "\n",
        "# ============================================================================\n",
        "# TRAINING AND EVALUATION\n",
        "# ============================================================================\n",
        "\n",
        "class ExperimentTracker:\n",
        "    \"\"\"Track experiments and detect overfitting/underfitting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.experiments = {}\n",
        "        self.current_exp = None\n",
        "\n",
        "    def start_experiment(self, name, config):\n",
        "        \"\"\"Start a new experiment\"\"\"\n",
        "        self.current_exp = name\n",
        "        self.experiments[name] = {\n",
        "            'config': config,\n",
        "            'metrics': [],\n",
        "            'analysis': {}\n",
        "        }\n",
        "\n",
        "    def log_metrics(self, epoch, metrics):\n",
        "        \"\"\"Log metrics for current experiment\"\"\"\n",
        "        if self.current_exp:\n",
        "            self.experiments[self.current_exp]['metrics'].append({\n",
        "                'epoch': epoch,\n",
        "                **metrics\n",
        "            })\n",
        "\n",
        "    def analyze_experiment(self, name):\n",
        "        \"\"\"Analyze experiment for overfitting/underfitting\"\"\"\n",
        "        if name not in self.experiments:\n",
        "            return {}\n",
        "\n",
        "        metrics = self.experiments[name]['metrics']\n",
        "        if len(metrics) < 5:\n",
        "            return {}\n",
        "\n",
        "        # Get final metrics\n",
        "        final_metrics = metrics[-1]\n",
        "        train_loss = final_metrics.get('train_loss', 0)\n",
        "        val_loss = final_metrics.get('val_loss', 0)\n",
        "        train_acc = final_metrics.get('train_accuracy', 0)\n",
        "        val_acc = final_metrics.get('val_accuracy', 0)\n",
        "\n",
        "        # Calculate gaps\n",
        "        loss_gap = train_loss - val_loss\n",
        "        acc_gap = train_acc - val_acc\n",
        "\n",
        "        # Overfitting score\n",
        "        overfitting_score = 0\n",
        "        if loss_gap < -0.3:\n",
        "            overfitting_score += 2\n",
        "        if acc_gap > 15:\n",
        "            overfitting_score += 2\n",
        "\n",
        "        # Check if validation loss is increasing\n",
        "        val_losses = [m['val_loss'] for m in metrics[-5:]]\n",
        "        if len(val_losses) >= 3 and val_losses[-1] > val_losses[0]:\n",
        "            overfitting_score += 1\n",
        "\n",
        "        # Underfitting score\n",
        "        underfitting_score = 0\n",
        "        if train_acc < 65:\n",
        "            underfitting_score += 2\n",
        "        if abs(acc_gap) < 3:\n",
        "            underfitting_score += 1\n",
        "\n",
        "        analysis = {\n",
        "            'train_val_loss_gap': loss_gap,\n",
        "            'train_val_acc_gap': acc_gap,\n",
        "            'overfitting_score': overfitting_score,\n",
        "            'underfitting_score': underfitting_score,\n",
        "            'final_train_acc': train_acc,\n",
        "            'final_val_acc': val_acc,\n",
        "            'best_val_acc': max([m['val_accuracy'] for m in metrics])\n",
        "        }\n",
        "\n",
        "        self.experiments[name]['analysis'] = analysis\n",
        "        return analysis\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"Main training class\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, num_classes=7):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "        self.tracker = ExperimentTracker()\n",
        "\n",
        "    def train_epoch(self, train_loader, optimizer, criterion):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = self.model(data)\n",
        "\n",
        "            # Handle attention models\n",
        "            if isinstance(output, tuple):\n",
        "                output, _ = output\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "        return total_loss / len(train_loader), 100. * correct / total\n",
        "\n",
        "    def evaluate(self, test_loader, criterion):\n",
        "        \"\"\"Evaluate model\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "\n",
        "                # Handle attention models\n",
        "                if isinstance(output, tuple):\n",
        "                    output, _ = output\n",
        "\n",
        "                loss = criterion(output, target)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                total += target.size(0)\n",
        "\n",
        "                all_preds.extend(pred.cpu().numpy().flatten())\n",
        "                all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "        accuracy = 100. * correct / total\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        # Calculate F1 scores\n",
        "        f1_scores = f1_score(all_targets, all_preds, average=None)\n",
        "        f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
        "\n",
        "        return avg_loss, accuracy, f1_scores, f1_macro, all_preds, all_targets\n",
        "\n",
        "    def run_experiment(self, experiment_name, config, train_loader, val_loader, epochs=50):\n",
        "        \"\"\"Run a complete experiment\"\"\"\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Starting Experiment: {experiment_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Initialize wandb\n",
        "        wandb.init(\n",
        "            project=\"facial-expression-recognition\",\n",
        "            name=experiment_name,\n",
        "            config=config,\n",
        "            reinit=True\n",
        "        )\n",
        "\n",
        "        # Setup optimizer\n",
        "        if config['optimizer'] == 'adam':\n",
        "            optimizer = optim.Adam(self.model.parameters(), lr=config['learning_rate'])\n",
        "        elif config['optimizer'] == 'adamw':\n",
        "            optimizer = optim.AdamW(self.model.parameters(), lr=config['learning_rate'],\n",
        "                                  weight_decay=config.get('weight_decay', 0.01))\n",
        "        else:  # SGD\n",
        "            optimizer = optim.SGD(self.model.parameters(), lr=config['learning_rate'],\n",
        "                                momentum=config.get('momentum', 0.9))\n",
        "\n",
        "        # Setup scheduler\n",
        "        if config.get('scheduler') == 'step':\n",
        "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "        elif config.get('scheduler') == 'cosine':\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "        elif config.get('scheduler') == 'plateau':\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
        "        else:\n",
        "            scheduler = None\n",
        "\n",
        "        # Setup loss function\n",
        "        if config.get('loss_function') == 'focal':\n",
        "            criterion = FocalLoss()\n",
        "        elif config.get('loss_function') == 'label_smoothing':\n",
        "            criterion = LabelSmoothingLoss(smoothing=config.get('label_smoothing', 0.1))\n",
        "        else:\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Start tracking\n",
        "        self.tracker.start_experiment(experiment_name, config)\n",
        "\n",
        "        best_val_acc = 0\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, optimizer, criterion)\n",
        "\n",
        "            # Validation\n",
        "            val_loss, val_acc, val_f1_scores, val_f1_macro, _, _ = self.evaluate(val_loader, criterion)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            if scheduler:\n",
        "                if config.get('scheduler') == 'plateau':\n",
        "                    scheduler.step(val_loss)\n",
        "                else:\n",
        "                    scheduler.step()\n",
        "\n",
        "            # Get current learning rate\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Calculate analysis metrics\n",
        "            train_val_loss_gap = train_loss - val_loss\n",
        "            train_val_acc_gap = train_acc - val_acc\n",
        "\n",
        "            # Log metrics\n",
        "            metrics = {\n",
        "                'train_loss': train_loss,\n",
        "                'train_accuracy': train_acc,\n",
        "                'val_loss': val_loss,\n",
        "                'val_accuracy': val_acc,\n",
        "                'val_f1_macro': val_f1_macro,\n",
        "                'learning_rate': current_lr,\n",
        "                'train_val_loss_gap': train_val_loss_gap,\n",
        "                'train_val_acc_gap': train_val_acc_gap,\n",
        "            }\n",
        "\n",
        "            # Add per-class F1 scores\n",
        "            for i, f1 in enumerate(val_f1_scores):\n",
        "                metrics[f'class_{i}_f1'] = f1\n",
        "\n",
        "            # Log to wandb\n",
        "            wandb.log(metrics, step=epoch)\n",
        "\n",
        "            # Track locally\n",
        "            self.tracker.log_metrics(epoch, metrics)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                # Save best model\n",
        "                torch.save(self.model.state_dict(), f'{experiment_name}_best_model.pth')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            # Print progress\n",
        "            if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "                print(f'Epoch {epoch:3d}: Train Acc: {train_acc:6.2f}%, '\n",
        "                      f'Val Acc: {val_acc:6.2f}%, Val F1: {val_f1_macro:.4f}')\n",
        "\n",
        "        # Final analysis\n",
        "        analysis = self.tracker.analyze_experiment(experiment_name)\n",
        "        print(f\"\\nExperiment Analysis:\")\n",
        "        print(f\"Best Validation Accuracy: {analysis.get('best_val_acc', 0):.2f}%\")\n",
        "        print(f\"Overfitting Score: {analysis.get('overfitting_score', 0)}\")\n",
        "        print(f\"Underfitting Score: {analysis.get('underfitting_score', 0)}\")\n",
        "\n",
        "        # Generate final plots\n",
        "        self.generate_plots(experiment_name)\n",
        "\n",
        "        wandb.finish()\n",
        "        return analysis\n",
        "\n",
        "    def generate_plots(self, experiment_name):\n",
        "        \"\"\"Generate analysis plots\"\"\"\n",
        "        if experiment_name not in self.tracker.experiments:\n",
        "            return\n",
        "\n",
        "        metrics = self.tracker.experiments[experiment_name]['metrics']\n",
        "        epochs = [m['epoch'] for m in metrics]\n",
        "        train_losses = [m['train_loss'] for m in metrics]\n",
        "        val_losses = [m['val_loss'] for m in metrics]\n",
        "        train_accs = [m['train_accuracy'] for m in metrics]\n",
        "        val_accs = [m['val_accuracy'] for m in metrics]\n",
        "\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # Loss curves\n",
        "        ax1.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
        "        ax1.plot(epochs, val_losses, label='Val Loss', color='red')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        # Accuracy curves\n",
        "        ax2.plot(epochs, train_accs, label='Train Acc', color='blue')\n",
        "        ax2.plot(epochs, val_accs, label='Val Acc', color='red')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Accuracy (%)')\n",
        "        ax2.set_title('Training and Validation Accuracy')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        # Loss gap\n",
        "        loss_gaps = [train_losses[i] - val_losses[i] for i in range(len(epochs))]\n",
        "        ax3.plot(epochs, loss_gaps, color='purple')\n",
        "        ax3.set_xlabel('Epoch')\n",
        "        ax3.set_ylabel('Train Loss - Val Loss')\n",
        "        ax3.set_title('Loss Gap (Overfitting Indicator)')\n",
        "        ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "        ax3.grid(True)\n",
        "\n",
        "        # Accuracy gap\n",
        "        acc_gaps = [train_accs[i] - val_accs[i] for i in range(len(epochs))]\n",
        "        ax4.plot(epochs, acc_gaps, color='orange')\n",
        "        ax4.set_xlabel('Epoch')\n",
        "        ax4.set_ylabel('Train Acc - Val Acc (%)')\n",
        "        ax4.set_title('Accuracy Gap (Overfitting Indicator)')\n",
        "        ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "        ax4.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{experiment_name}_analysis.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "        # Log to wandb\n",
        "        wandb.log({\"training_analysis\": wandb.Image(f'{experiment_name}_analysis.png')})\n",
        "        plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# EXPERIMENTAL PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def get_data_transforms(augmentation_level='medium'):\n",
        "    \"\"\"Get data transforms based on augmentation level\"\"\"\n",
        "\n",
        "    if augmentation_level == 'light':\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(0.3),\n",
        "            transforms.RandomRotation(5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    elif augmentation_level == 'medium':\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(0.5),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    elif augmentation_level == 'strong':\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(0.5),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.RandomAffine(0, translate=(0.15, 0.15), scale=(0.9, 1.1)),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    else:  # No augmentation\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform\n",
        "\n",
        "def run_all_experiments():\n",
        "    \"\"\"Run all experiments from the plan\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Data loading\n",
        "    train_transform, val_transform = get_data_transforms('medium')\n",
        "\n",
        "    # Create datasets (replace with your actual data loading)\n",
        "    train_dataset = FERDataset('data/train', transform=train_transform, split='train')\n",
        "    val_dataset = FERDataset('data/val', transform=val_transform, split='val')\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Print dataset info\n",
        "    print(f\"Train samples: {len(train_dataset)}\")\n",
        "    print(f\"Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"Class distribution (train): {train_dataset.get_class_distribution()}\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # PHASE 1: Baseline and Data Understanding\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 1: BASELINE AND DATA UNDERSTANDING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Experiment 1.2: Simple Baseline\n",
        "    model = SimpleCNN(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config = {\n",
        "        'model_name': 'SimpleCNN',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'optimizer': 'adam',\n",
        "        'epochs': 30,\n",
        "        'dropout_rate': 0.3,\n",
        "        'augmentation_strength': 'medium'\n",
        "    }\n",
        "    results['baseline_simple_cnn'] = trainer.run_experiment(\n",
        "        'baseline_simple_cnn', config, train_loader, val_loader, epochs=30\n",
        "    )\n",
        "\n",
        "    # PHASE 2: Architecture Progression\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 2: ARCHITECTURE PROGRESSION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Experiment 2.1: Enhanced CNN\n",
        "    model = EnhancedCNN(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'EnhancedCNN',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "        'dropout_rate': 0.5\n",
        "    })\n",
        "    results['enhanced_cnn_batchnorm'] = trainer.run_experiment(\n",
        "        'enhanced_cnn_batchnorm', config, train_loader, val_loader, epochs=40\n",
        "    )\n",
        "\n",
        "    # Experiment 2.2: Deeper CNN\n",
        "    model = DeepCNN(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'DeepCNN',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "        'architecture_depth': 4\n",
        "    })\n",
        "    results['deep_cnn_v1'] = trainer.run_experiment(\n",
        "        'deep_cnn_v1', config, train_loader, val_loader, epochs=40\n",
        "    )\n",
        "\n",
        "    # Experiment 2.3: Regularization Focus\n",
        "    model = DeepCNN(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'DeepCNN_Regularized',\n",
        "        'dropout_rate': 0.7,\n",
        "        'weight_decay': 0.001,\n",
        "        'augmentation_strength': 'strong'\n",
        "    })\n",
        "    # Use strong augmentation for this experiment\n",
        "    strong_train_transform, _ = get_data_transforms('strong')\n",
        "    train_dataset_strong = FERDataset('data/train', transform=strong_train_transform, split='train')\n",
        "    train_loader_strong = DataLoader(train_dataset_strong, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    results['deep_cnn_regularized'] = trainer.run_experiment(\n",
        "        'deep_cnn_regularized', config, train_loader_strong, val_loader, epochs=40\n",
        "    )\n",
        "\n",
        "    # PHASE 3: Advanced Architectures\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 3: ADVANCED ARCHITECTURES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Experiment 3.1: Attention Mechanism\n",
        "    model = AttentionCNN(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'AttentionCNN',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "        'dropout_rate': 0.5,\n",
        "        'weight_decay': 0.0001,\n",
        "        'augmentation_strength': 'medium'\n",
        "    })\n",
        "    results['attention_cnn_v1'] = trainer.run_experiment(\n",
        "        'attention_cnn_v1', config, train_loader, val_loader, epochs=40\n",
        "    )\n",
        "\n",
        "    # Experiment 3.2: Multi-Scale Features\n",
        "    model = MultiScaleCNN(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'MultiScaleCNN',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters())\n",
        "    })\n",
        "    results['multiscale_cnn_v1'] = trainer.run_experiment(\n",
        "        'multiscale_cnn_v1', config, train_loader, val_loader, epochs=40\n",
        "    )\n",
        "\n",
        "    # PHASE 4: Transfer Learning\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 4: TRANSFER LEARNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Experiment 4.1: ResNet18 Transfer (Frozen)\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "\n",
        "    # Freeze early layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.fc.parameters():\n",
        "        param.requires_grad = True\n",
        "    for param in model.layer4.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'ResNet18_Transfer_Frozen',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "        'transfer_learning': True,\n",
        "        'frozen_layers': True\n",
        "    })\n",
        "    results['resnet18_transfer_frozen'] = trainer.run_experiment(\n",
        "        'resnet18_transfer_frozen', config, train_loader, val_loader, epochs=30\n",
        "    )\n",
        "\n",
        "    # Experiment 4.2: ResNet18 Fine-tuning\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'ResNet18_Transfer_Finetune',\n",
        "        'total_parameters': sum(p.numel() for p in model.parameters()),\n",
        "        'frozen_layers': False\n",
        "    })\n",
        "    results['resnet18_transfer_finetune'] = trainer.run_experiment(\n",
        "        'resnet18_transfer_finetune', config, train_loader, val_loader, epochs=30\n",
        "    )\n",
        "\n",
        "    # PHASE 5: Optimization Strategies\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 5: OPTIMIZATION STRATEGIES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Use the best architecture from previous phases for optimizer comparison\n",
        "    best_model_class = EnhancedCNN  # This would be determined from results\n",
        "\n",
        "    # Experiment 5.1: Optimizer Comparison - Adam\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'model_name': 'Enhanced_CNN_Adam',\n",
        "        'optimizer': 'adam',\n",
        "        'learning_rate': 0.001\n",
        "    })\n",
        "    results['optimizer_adam'] = trainer.run_experiment(\n",
        "        'optimizer_adam', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    # Experiment 5.1: Optimizer Comparison - AdamW\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'optimizer': 'adamw',\n",
        "        'weight_decay': 0.01\n",
        "    })\n",
        "    results['optimizer_adamw'] = trainer.run_experiment(\n",
        "        'optimizer_adamw', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    # Experiment 5.1: Optimizer Comparison - SGD\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'optimizer': 'sgd',\n",
        "        'learning_rate': 0.01,\n",
        "        'momentum': 0.9\n",
        "    })\n",
        "    results['optimizer_sgd'] = trainer.run_experiment(\n",
        "        'optimizer_sgd', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    # Experiment 5.2: Learning Rate Scheduling\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'optimizer': 'adam',  # Use best optimizer from above\n",
        "        'learning_rate': 0.001,\n",
        "        'scheduler': 'step'\n",
        "    })\n",
        "    results['scheduler_step'] = trainer.run_experiment(\n",
        "        'scheduler_step', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({'scheduler': 'cosine'})\n",
        "    results['scheduler_cosine'] = trainer.run_experiment(\n",
        "        'scheduler_cosine', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({'scheduler': 'plateau'})\n",
        "    results['scheduler_plateau'] = trainer.run_experiment(\n",
        "        'scheduler_plateau', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    # Experiment 5.3: Advanced Loss Functions\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'scheduler': 'cosine',  # Use best scheduler\n",
        "        'loss_function': 'focal'\n",
        "    })\n",
        "    results['focal_loss'] = trainer.run_experiment(\n",
        "        'focal_loss', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    model = best_model_class(num_classes=7)\n",
        "    trainer = Trainer(model, device)\n",
        "    config.update({\n",
        "        'loss_function': 'label_smoothing',\n",
        "        'label_smoothing': 0.1\n",
        "    })\n",
        "    results['label_smoothing'] = trainer.run_experiment(\n",
        "        'label_smoothing', config, train_loader, val_loader, epochs=35\n",
        "    )\n",
        "\n",
        "    # PHASE 6: Advanced Techniques\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PHASE 6: ADVANCED TECHNIQUES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Experiment 6.1: Data Augmentation Study\n",
        "    augmentation_levels = ['light', 'medium', 'strong']\n",
        "    for aug_level in augmentation_levels:\n",
        "        aug_train_transform, _ = get_data_transforms(aug_level)\n",
        "        aug_train_dataset = FERDataset('data/train', transform=aug_train_transform, split='train')\n",
        "        aug_train_loader = DataLoader(aug_train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "        model = best_model_class(num_classes=7)\n",
        "        trainer = Trainer(model, device)\n",
        "        config.update({\n",
        "            'augmentation_strength': aug_level,\n",
        "            'loss_function': 'cross_entropy'  # Reset to standard\n",
        "        })\n",
        "        results[f'augment_{aug_level}'] = trainer.run_experiment(\n",
        "            f'augment_{aug_level}', config, aug_train_loader, val_loader, epochs=35\n",
        "        )\n",
        "\n",
        "    # FINAL ANALYSIS AND REPORTING\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPREHENSIVE RESULTS ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    generate_final_report(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_final_report(results):\n",
        "    \"\"\"Generate comprehensive analysis report\"\"\"\n",
        "\n",
        "    print(\"\\nEXPERIMENT RESULTS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Sort results by best validation accuracy\n",
        "    sorted_results = sorted(\n",
        "        results.items(),\n",
        "        key=lambda x: x[1].get('best_val_acc', 0),\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    print(f\"{'Rank':<4} {'Experiment':<25} {'Best Val Acc':<12} {'Overfitting':<12} {'Underfitting':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for rank, (exp_name, analysis) in enumerate(sorted_results, 1):\n",
        "        best_acc = analysis.get('best_val_acc', 0)\n",
        "        overfitting = analysis.get('overfitting_score', 0)\n",
        "        underfitting = analysis.get('underfitting_score', 0)\n",
        "\n",
        "        print(f\"{rank:<4} {exp_name:<25} {best_acc:<12.2f} {overfitting:<12} {underfitting:<12}\")\n",
        "\n",
        "    # Phase-wise analysis\n",
        "    phases = {\n",
        "        'Baseline': ['baseline_simple_cnn'],\n",
        "        'Architecture': ['enhanced_cnn_batchnorm', 'deep_cnn_v1', 'deep_cnn_regularized'],\n",
        "        'Advanced': ['attention_cnn_v1', 'multiscale_cnn_v1'],\n",
        "        'Transfer': ['resnet18_transfer_frozen', 'resnet18_transfer_finetune'],\n",
        "        'Optimization': ['optimizer_adam', 'optimizer_adamw', 'optimizer_sgd',\n",
        "                        'scheduler_step', 'scheduler_cosine', 'scheduler_plateau',\n",
        "                        'focal_loss', 'label_smoothing'],\n",
        "        'Augmentation': ['augment_light', 'augment_medium', 'augment_strong']\n",
        "    }\n",
        "\n",
        "    print(f\"\\nPHASE-WISE BEST PERFORMERS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for phase_name, experiments in phases.items():\n",
        "        phase_results = [(exp, results[exp]) for exp in experiments if exp in results]\n",
        "        if phase_results:\n",
        "            best_exp, best_result = max(phase_results, key=lambda x: x[1].get('best_val_acc', 0))\n",
        "            print(f\"{phase_name:<15}: {best_exp:<25} ({best_result.get('best_val_acc', 0):.2f}%)\")\n",
        "\n",
        "    # Key insights\n",
        "    print(f\"\\nKEY INSIGHTS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Find experiments with high overfitting\n",
        "    high_overfitting = [exp for exp, res in results.items()\n",
        "                       if res.get('overfitting_score', 0) >= 3]\n",
        "    if high_overfitting:\n",
        "        print(f\"High Overfitting: {', '.join(high_overfitting)}\")\n",
        "\n",
        "    # Find experiments with high underfitting\n",
        "    high_underfitting = [exp for exp, res in results.items()\n",
        "                        if res.get('underfitting_score', 0) >= 3]\n",
        "    if high_underfitting:\n",
        "        print(f\"High Underfitting: {', '.join(high_underfitting)}\")\n",
        "\n",
        "    # Best overall configuration\n",
        "    best_exp, best_result = sorted_results[0]\n",
        "    print(f\"\\nBEST OVERALL CONFIGURATION: {best_exp}\")\n",
        "    print(f\"Validation Accuracy: {best_result.get('best_val_acc', 0):.2f}%\")\n",
        "    print(f\"Train-Val Gap: {best_result.get('train_val_acc_gap', 0):.2f}%\")\n",
        "\n",
        "    # Save detailed report\n",
        "    report_data = {\n",
        "        'experiment_results': results,\n",
        "        'rankings': sorted_results,\n",
        "        'phase_winners': {phase: max([(exp, results[exp]) for exp in experiments if exp in results],\n",
        "                                   key=lambda x: x[1].get('best_val_acc', 0))[0]\n",
        "                         for phase, experiments in phases.items()\n",
        "                         if any(exp in results for exp in experiments)},\n",
        "        'best_overall': best_exp\n",
        "    }\n",
        "\n",
        "    with open('comprehensive_experiment_report.json', 'w') as f:\n",
        "        json.dump(report_data, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"\\nDetailed report saved to: comprehensive_experiment_report.json\")\n",
        "\n",
        "# ============================================================================\n",
        "# ENSEMBLE AND ADVANCED ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "class EnsembleModel(nn.Module):\n",
        "    \"\"\"Ensemble of multiple models\"\"\"\n",
        "\n",
        "    def __init__(self, models, weights=None):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.models = nn.ModuleList(models)\n",
        "        self.weights = weights if weights else [1.0] * len(models)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            output = model(x)\n",
        "            if isinstance(output, tuple):\n",
        "                output = output[0]  # Handle attention models\n",
        "            outputs.append(output)\n",
        "\n",
        "        # Weighted average\n",
        "        weighted_output = sum(w * out for w, out in zip(self.weights, outputs))\n",
        "        return weighted_output / sum(self.weights)\n",
        "\n",
        "def run_ensemble_experiment(results, device, val_loader):\n",
        "    \"\"\"Run ensemble experiment with top performing models\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ENSEMBLE EXPERIMENT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get top 3 experiments\n",
        "    top_experiments = sorted(\n",
        "        results.items(),\n",
        "        key=lambda x: x[1].get('best_val_acc', 0),\n",
        "        reverse=True\n",
        "    )[:3]\n",
        "\n",
        "    print(\"Top 3 experiments for ensemble:\")\n",
        "    for i, (exp_name, result) in enumerate(top_experiments, 1):\n",
        "        print(f\"{i}. {exp_name}: {result.get('best_val_acc', 0):.2f}%\")\n",
        "\n",
        "    # Load the best models (this is conceptual - you'd need to save/load actual models)\n",
        "    models = []\n",
        "    for exp_name, _ in top_experiments:\n",
        "        if 'resnet' in exp_name.lower():\n",
        "            model = models.resnet18(pretrained=False)\n",
        "            model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "        elif 'attention' in exp_name.lower():\n",
        "            model = AttentionCNN(num_classes=7)\n",
        "        elif 'multiscale' in exp_name.lower():\n",
        "            model = MultiScaleCNN(num_classes=7)\n",
        "        elif 'deep' in exp_name.lower():\n",
        "            model = DeepCNN(num_classes=7)\n",
        "        else:\n",
        "            model = EnhancedCNN(num_classes=7)\n",
        "\n",
        "        # Load saved weights (conceptual)\n",
        "        try:\n",
        "            model.load_state_dict(torch.load(f'{exp_name}_best_model.pth'))\n",
        "        except:\n",
        "            print(f\"Warning: Could not load weights for {exp_name}\")\n",
        "\n",
        "        model.to(device)\n",
        "        models.append(model)\n",
        "\n",
        "    # Create ensemble\n",
        "    ensemble = EnsembleModel(models)\n",
        "    trainer = Trainer(ensemble, device)\n",
        "\n",
        "    # Evaluate ensemble\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    val_loss, val_acc, val_f1_scores, val_f1_macro, preds, targets = trainer.evaluate(val_loader, criterion)\n",
        "\n",
        "    print(f\"\\nEnsemble Results:\")\n",
        "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
        "    print(f\"Validation F1 (macro): {val_f1_macro:.4f}\")\n",
        "\n",
        "    # Compare with individual models\n",
        "    print(f\"\\nComparison with individual models:\")\n",
        "    for i, (exp_name, result) in enumerate(top_experiments):\n",
        "        individual_acc = result.get('best_val_acc', 0)\n",
        "        improvement = val_acc - individual_acc\n",
        "        print(f\"{exp_name}: {individual_acc:.2f}% (Δ: {improvement:+.2f}%)\")\n",
        "\n",
        "    return val_acc, val_f1_macro\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZATION AND ANALYSIS TOOLS\n",
        "# ============================================================================\n",
        "\n",
        "def visualize_attention_maps(model, data_loader, device, num_samples=4):\n",
        "    \"\"\"Visualize attention maps for attention-based models\"\"\"\n",
        "    if not isinstance(model, AttentionCNN):\n",
        "        print(\"Model does not support attention visualization\")\n",
        "        return\n",
        "\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 8))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "\n",
        "            data = data.to(device)\n",
        "            output, attention = model(data)\n",
        "\n",
        "            # Original image\n",
        "            img = data[0].cpu().squeeze().numpy()\n",
        "            axes[0, i].imshow(img, cmap='gray')\n",
        "            axes[0, i].set_title(f'Original (Class: {target[0].item()})')\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "            # Attention map\n",
        "            att_map = attention[0].cpu().squeeze().numpy()\n",
        "            att_map = np.interp(att_map, (att_map.min(), att_map.max()), (0, 1))\n",
        "            axes[1, i].imshow(att_map, cmap='hot', alpha=0.7)\n",
        "            axes[1, i].imshow(img, cmap='gray', alpha=0.3)\n",
        "            axes[1, i].set_title('Attention Map')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('attention_visualization.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def analyze_class_performance(results):\n",
        "    \"\"\"Analyze per-class performance across experiments\"\"\"\n",
        "    class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "    # Extract F1 scores for each class across experiments\n",
        "    class_performance = defaultdict(list)\n",
        "    experiment_names = []\n",
        "\n",
        "    for exp_name, result in results.items():\n",
        "        if 'metrics' in result:\n",
        "            # Get the last epoch's metrics\n",
        "            last_metrics = result['metrics'][-1] if result['metrics'] else {}\n",
        "            experiment_names.append(exp_name)\n",
        "\n",
        "            for i in range(7):  # 7 emotion classes\n",
        "                f1_key = f'class_{i}_f1'\n",
        "                f1_score = last_metrics.get(f1_key, 0)\n",
        "                class_performance[class_names[i]].append(f1_score)\n",
        "\n",
        "    # Create heatmap\n",
        "    if experiment_names and class_performance:\n",
        "        performance_matrix = []\n",
        "        for class_name in class_names:\n",
        "            performance_matrix.append(class_performance[class_name])\n",
        "\n",
        "        performance_matrix = np.array(performance_matrix)\n",
        "\n",
        "        plt.figure(figsize=(15, 8))\n",
        "        sns.heatmap(performance_matrix,\n",
        "                   xticklabels=experiment_names,\n",
        "                   yticklabels=class_names,\n",
        "                   annot=True, fmt='.3f', cmap='viridis')\n",
        "        plt.title('Per-Class F1 Scores Across Experiments')\n",
        "        plt.xlabel('Experiments')\n",
        "        plt.ylabel('Emotion Classes')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('class_performance_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Initialize wandb project\n",
        "    import os\n",
        "    os.environ['WANDB_PROJECT'] = 'facial-expression-recognition'\n",
        "\n",
        "    print(\"Starting Comprehensive Facial Expression Recognition Experiments\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Run all experiments\n",
        "    results = run_all_experiments()\n",
        "\n",
        "    # Run ensemble experiment\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Create validation loader for ensemble\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    val_dataset = FERDataset('data/val', transform=val_transform, split='val')\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    try:\n",
        "        ensemble_acc, ensemble_f1 = run_ensemble_experiment(results, device, val_loader)\n",
        "        results['ensemble_top3'] = {\n",
        "            'best_val_acc': ensemble_acc,\n",
        "            'val_f1_macro': ensemble_f1,\n",
        "            'overfitting_score': 0,  # Ensembles typically don't overfit\n",
        "            'underfitting_score': 0\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Ensemble experiment failed: {e}\")\n",
        "\n",
        "    # Additional analysis\n",
        "    analyze_class_performance(results)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nKey deliverables generated:\")\n",
        "    print(\"1. comprehensive_experiment_report.json - Detailed results\")\n",
        "    print(\"2. Individual experiment plots and analysis\")\n",
        "    print(\"3. Class performance heatmap\")\n",
        "    print(\"4. Attention visualizations (if applicable)\")\n",
        "    print(\"5. All model checkpoints saved\")\n",
        "\n",
        "    # Final recommendations\n",
        "    best_exp = max(results.items(), key=lambda x: x[1].get('best_val_acc', 0))\n",
        "    print(f\"\\nRECOMMENDED CONFIGURATION: {best_exp[0]}\")\n",
        "    print(f\"Expected Performance: {best_exp[1].get('best_val_acc', 0):.2f}% validation accuracy\")\n",
        "\n",
        "    if best_exp[1].get('overfitting_score', 0) > 2:\n",
        "        print(\"⚠️  Warning: High overfitting detected. Consider more regularization.\")\n",
        "    if best_exp[1].get('underfitting_score', 0) > 2:\n",
        "        print(\"⚠️  Warning: High underfitting detected. Consider increasing model capacity.\")\n",
        "\n",
        "    print(\"\\nExperiment framework completed. Check wandb dashboard for detailed training curves.\")"
      ],
      "metadata": {
        "id": "eXmiqAUIF2ub",
        "outputId": "0a23bbb4-c6bf-4a3c-ce34-6bbf59b64c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "id": "eXmiqAUIF2ub",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cd3b7157b565>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ordered_set\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mCeilToInt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         GroebnerBasis, poly)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from .polyfuncs import (symmetrize, horner, interpolate,\n\u001b[0m\u001b[1;32m     80\u001b[0m         rational_interpolate, viete)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/polys/polyfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from sympy.polys.specialpolys import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     symmetric_poly, interpolating_poly)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/polys/specialpolys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# A few useful polynomials from Wang's paper ('78).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_f_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/polys/rings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m from sympy.polys.polyutils import (expr_from_dict, _dict_reorder,\n\u001b[1;32m     29\u001b[0m                                    _parallel_dict_from_expr)\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPrinting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/printing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_ccode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/printing/pycode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodePrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m _kw = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrPrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRECEDENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sympy/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         chebyshevt_root, laguerre, assoc_laguerre, gegenbauer, jacobi, jacobi_normalized)\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspherical_harmonics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYnm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYnm_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZnm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m from sympy.functions.special.elliptic_integrals import (elliptic_k,\n\u001b[0m\u001b[1;32m     48\u001b[0m         elliptic_f, elliptic_e, elliptic_pi)\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetainc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetainc_regularized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zsx00aeVLOgj"
      },
      "id": "Zsx00aeVLOgj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}